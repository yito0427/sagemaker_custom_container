{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bc2cccb",
   "metadata": {},
   "source": [
    "# LightGBMをカスタムコンテナで利用する手順を学び、SageMakerの動作を理解します\n",
    "\n",
    "2hを想定\n",
    "\n",
    "コンテンツ\n",
    "* カスタムコンテナ(ローカル学習、ローカル推論、学習ジョブ、推論ジョブ）\n",
    "* SageMaker Training Toolkit導入（コードを外出しにする）：ローカル学習、ローカル推論\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee60d4",
   "metadata": {},
   "source": [
    "## 実行環境\n",
    "本ノートブックは、SageMakerノートブックインスタンス上で動作確認しています。\n",
    "* インスタンスタイプ：ml.t3.medium\n",
    "* カーネル：conda_python3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d3100",
   "metadata": {},
   "source": [
    "## コンテンツ\n",
    "\n",
    "* LightGBM入りのカスタムコンテナを作る（パターン3:https://aws.amazon.com/jp/blogs/news/sagemaker-custom-containers-pattern-training/）\n",
    "    *\n",
    "    * SageMakerノートブックインスタンス上で作成する\n",
    "    * 中に入って確かめてみる\n",
    "    * ECRに登録\n",
    "\n",
    "* SageMaker学習ジョブを実行する\n",
    "    * trainに記載されている、SageMakerのお作法の解説\n",
    "    * ローカルモードで動かす\n",
    "        * ローカル推論\n",
    "    * 学習ジョブで動かす(waitなし)\n",
    "        * 推論エンドポイント構築。推論(とばす）\n",
    "    * 【課題】train.py を外出しで指定して、学習ジョブを動かす（ローカルモード）\n",
    "        * パターン２：Training Toolkitを入れたカスタムコンテナを作る(trainをCOPYしない。Toolkitをpip install）\n",
    "        * パラメータを指定【エラー】trainが実行されてしまう（調査中）\n",
    "        * 試しに train.sh を実行する\n",
    "        * train.pyをローカルモードで学習\n",
    "        * ローカル推論\n",
    "* LightGBM + SageMaker Toolkit 入りのカスタムコンテナを作る（応用編）\n",
    "    * ローカルモードで動かす\n",
    "    * 学習ジョブで動かす\n",
    "    * 出力の違いを観察\n",
    "* （おまけ）パターン1ビルトインコンテナのrequirements.txt の紹介（→ カスタムコンテナでないので、パターン0でした）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace7dba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:59:51) \\n[GCC 9.4.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "#Pythonのバージョン情報\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e6acd4",
   "metadata": {},
   "source": [
    "'3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:59:51) \\n[GCC 9.4.0]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f06a8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.12\n"
     ]
    }
   ],
   "source": [
    "# Pythonのバージョン確認 (システムコマンド使用\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a818a3",
   "metadata": {},
   "source": [
    "Python 3.8.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75b71cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current SageMaker Python SDK Version =2.109.0\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "print('Current SageMaker Python SDK Version ={0}'.format(sagemaker.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042b6516-451c-4a50-a005-92f4b2629b38",
   "metadata": {},
   "source": [
    "Current SageMaker Python SDK Version =2.109.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc9d83b",
   "metadata": {},
   "source": [
    "## ライブラリインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4ed1729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sample Python program that trains a simple LightGBM Regression model, and then performs inference.\n",
    "# This implementation will work on your local computer.\n",
    "#\n",
    "# Prerequisites:\n",
    "#   1. Install required Python packages:\n",
    "#       pip install boto3 sagemaker pandas scikit-learn\n",
    "#       pip install 'sagemaker[local]'\n",
    "#   2. Docker Desktop has to be installed on your computer, and running.\n",
    "#   3. Open terminal and run the following commands:\n",
    "#       docker build  -t sagemaker-lightgbm-regression-local container/.\n",
    "########################################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f70ee0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.local import LocalSession\n",
    "from sagemaker.predictor import csv_serializer\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae4b14aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = LocalSession()\n",
    "sagemaker_session.config = {'local': {'local_code': True}}\n",
    "\n",
    "# For local training a dummy role will be sufficient\n",
    "role = 'arn:aws:iam::111111111111:role/service-role/AmazonSageMaker-ExecutionRole-20200101T000001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144f01da-ade7-4afb-8c6b-99f4f0ce39bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bf8c7f4",
   "metadata": {},
   "source": [
    "# 1.データ準備\n",
    "\n",
    "ボストンの住宅価格データセットを利用します。\n",
    "\n",
    "https://github.com/aws-samples/amazon-sagemaker-local-mode/blob/main/lightgbm_bring_your_own_container_local_training_and_serving/lightgbm_bring_your_own_container_local_training_and_serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a1c34ac-0e6d-4f3d-961a-51a86e3f7045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1b0a104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data = load_boston()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=45)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=45)\n",
    "\n",
    "trainX = pd.DataFrame(X_train, columns=data.feature_names)\n",
    "trainX['target'] = y_train\n",
    "\n",
    "valX = pd.DataFrame(X_val, columns=data.feature_names)\n",
    "valX['target'] = y_val\n",
    "\n",
    "testX = pd.DataFrame(X_test, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15ecd623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path('./data/train').mkdir(parents=True, exist_ok=True)\n",
    "Path('./data/valid').mkdir(parents=True, exist_ok=True)\n",
    "Path('./data/test').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cef1dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_train = './data/train/boston_train.csv'\n",
    "local_valid = './data/valid/boston_valid.csv'\n",
    "local_test = './data/test/boston_test.csv'\n",
    "\n",
    "trainX.to_csv(local_train, header=None, index=False)\n",
    "valX.to_csv(local_valid, header=None, index=False)\n",
    "testX.to_csv(local_test, header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe02532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31ee68a5",
   "metadata": {},
   "source": [
    "# 2.カスタムコンテナ作成\n",
    "\n",
    "https://aws.amazon.com/jp/blogs/news/sagemaker-custom-containers-pattern-training/\n",
    "\n",
    "SageMakerカスタムコンテナパターン3の形式\n",
    "\n",
    "containerディレクトリに資材が格納されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e43fc-0d39-4f5f-8a51-7ce9c028ca61",
   "metadata": {},
   "source": [
    "## 資材の解説\n",
    "\n",
    "* Dockerfile : コンテナ作成\n",
    "* 学習用ファイル\n",
    "    * train: 学習時に実行されるスクリプトファイル\n",
    "* 推論用ファイル\n",
    "    * serve: デプロイ時に実行されるスクリプトファイル\n",
    "    * nginx.conf: Webサーバのnginxの設定ファイル\n",
    "    * wsgi.py: ninxの立ち上げ時に利用？\n",
    "    * predictor.py: 推論のための関数を定義したファイル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19610197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon   25.6kB\n",
      "Step 1/10 : FROM ubuntu:16.04\n",
      " ---> b6f507652425\n",
      "Step 2/10 : MAINTAINER Amazon AI <sage-learner@amazon.com>\n",
      " ---> Using cache\n",
      " ---> c5602b2d98e4\n",
      "Step 3/10 : ARG CONDA_DIR=/opt/conda\n",
      " ---> Using cache\n",
      " ---> 618227bc5218\n",
      "Step 4/10 : ENV PATH $CONDA_DIR/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> f0165591799f\n",
      "Step 5/10 : RUN apt-get update &&     apt-get install -y --no-install-recommends         ca-certificates         cmake         build-essential         gcc         g++         git         nginx         wget &&     wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh &&     /bin/bash Miniconda3-latest-Linux-x86_64.sh -f -b -p $CONDA_DIR &&     export PATH=\"$CONDA_DIR/bin:$PATH\" &&     conda config --set always_yes yes --set changeps1 no &&     conda install -q -y numpy scipy scikit-learn pandas flask gevent gunicorn &&     git clone --recursive --branch stable --depth 1 https://github.com/Microsoft/LightGBM &&     cd LightGBM/python-package && python setup.py install &&     apt-get autoremove -y && apt-get clean &&     conda clean -a -y &&     rm -rf /usr/local/src/*\n",
      " ---> Using cache\n",
      " ---> 99c43eb4621f\n",
      "Step 6/10 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> dc6222c249df\n",
      "Step 7/10 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> be12e73d2688\n",
      "Step 8/10 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 878673fa1725\n",
      "Step 9/10 : COPY lightgbm_regression /opt/program\n",
      " ---> Using cache\n",
      " ---> cbdaa0ed0b11\n",
      "Step 10/10 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 2f30998b46bb\n",
      "Successfully built 2f30998b46bb\n",
      "Successfully tagged sagemaker-lightgbm-regression:latest\n",
      "The push refers to repository [021345128571.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-lightgbm-regression]\n",
      "2d4f2d4fb08a: Preparing\n",
      "11dfd6aa9089: Preparing\n",
      "1251204ef8fc: Preparing\n",
      "47ef83afae74: Preparing\n",
      "df54c846128d: Preparing\n",
      "be96a3f634de: Preparing\n",
      "be96a3f634de: Waiting\n",
      "11dfd6aa9089: Layer already exists\n",
      "2d4f2d4fb08a: Layer already exists\n",
      "1251204ef8fc: Layer already exists\n",
      "47ef83afae74: Layer already exists\n",
      "df54c846128d: Layer already exists\n",
      "be96a3f634de: Layer already exists\n",
      "latest: digest: sha256:ca99c5b5451d39e2f0ddff3f19650c62211d0d85e0dcf4c2909a4822dd059769 size: 1571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-lightgbm-regression\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x lightgbm_regression/train\n",
    "chmod +x lightgbm_regression/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26059847-ea1e-455d-925c-fc465170fa9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "360cb231",
   "metadata": {},
   "source": [
    "# ECRでpushしたコンテナのURIを確認\n",
    "\n",
    "AWSコンソールでECRに移動し、作成したコンテナがあることを確認します。\n",
    "\n",
    "image URIを取得し、以下にはりつけます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1abb9a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = 'sagemaker-lightgbm-regression-local'\n",
    "#image = '805433377179.dkr.ecr.us-west-2.amazonaws.com/sagemaker-lightgbm-regression:latest' # ビルドしたイメージのURI\n",
    "image = '021345128571.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-lightgbm-regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5546250a-f28d-457e-919a-abd94bb08a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_location = 'file://'+local_train\n",
    "valid_location = 'file://'+local_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdd5962c-a015-4891-9b2a-294b037a8dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file://./data/train/boston_train.csv\n",
      "file://./data/valid/boston_valid.csv\n"
     ]
    }
   ],
   "source": [
    "print(train_location)\n",
    "print(valid_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc813b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "719b3866",
   "metadata": {},
   "source": [
    "# ローカル学習\n",
    "ECRからビルドしたイメージを持ってきて、ローカルのdockerでビルドして、実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f0c241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_lightgbm = Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"local\",\n",
    "    hyperparameters={'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52a7b5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 0c9r493w5l-algo-1-0z4o6 ... \n",
      "Creating 0c9r493w5l-algo-1-0z4o6 ... done\n",
      "Attaching to 0c9r493w5l-algo-1-0z4o6\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m Starting the training.\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m Reading hyperparameters data: /opt/ml/input/config/hyperparameters.json\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m hyperparameters_data: {'boosting_type': 'gbdt', 'objective': 'regression', 'num_leaves': '31', 'learning_rate': '0.05', 'feature_fraction': '0.9', 'bagging_fraction': '0.8', 'bagging_freq': '5', 'verbose': '0'}\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m Found train files: ['/opt/ml/input/data/train/boston_train.csv']\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m Found validation files: ['/opt/ml/input/data/validation/boston_valid.csv']\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m building training and validation datasets\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m Starting training...\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m /opt/conda/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m   _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m You can set `force_col_wise=true` to remove the overhead.\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [1]\tvalid_0's l2: 84.4849\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m Training until validation scores don't improve for 5 rounds\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [2]\tvalid_0's l2: 78.6995\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [3]\tvalid_0's l2: 73.3733\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [4]\tvalid_0's l2: 68.4066\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [5]\tvalid_0's l2: 63.9675\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [6]\tvalid_0's l2: 60.4495\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [7]\tvalid_0's l2: 57.2702\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [8]\tvalid_0's l2: 54.3096\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [9]\tvalid_0's l2: 51.6438\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [10]\tvalid_0's l2: 49.4106\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [11]\tvalid_0's l2: 46.871\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [12]\tvalid_0's l2: 44.4878\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [13]\tvalid_0's l2: 42.2348\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [14]\tvalid_0's l2: 40.2703\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [15]\tvalid_0's l2: 38.4195\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [16]\tvalid_0's l2: 36.6089\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [17]\tvalid_0's l2: 34.9745\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [18]\tvalid_0's l2: 33.5774\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [19]\tvalid_0's l2: 32.1331\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [20]\tvalid_0's l2: 30.8945\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m Did not meet early stopping. Best iteration is:\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m [20]\tvalid_0's l2: 30.8945\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m saving model file to /opt/ml/model/lightgbm-regression-model.txt\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 |\u001b[0m Training complete.\n",
      "\u001b[36m0c9r493w5l-algo-1-0z4o6 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "local_lightgbm.fit({'train':train_location, 'validation': valid_location}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538774a7",
   "metadata": {},
   "source": [
    "ローカルモードの学習結果は\n",
    "\n",
    "Amazon S3\n",
    "Buckets\n",
    "sagemaker-us-west-2-805433377179\n",
    "sagemaker-lightgbm-regression-2022-10-03-06-17-32-054/\n",
    "\n",
    "に出力されます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30169b22",
   "metadata": {},
   "source": [
    "### ローカルサービング\n",
    "\n",
    "serializer : インプットデータの形式を指定します。\n",
    "https://sagemaker.readthedocs.io/en/stable/v2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e932e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to jioo7o4vps-algo-1-9ktq9\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m Starting the inference server with 16 workers.\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:19 +0000] [10] [INFO] Starting gunicorn 20.1.0\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:19 +0000] [10] [INFO] Listening at: unix:/tmp/gunicorn.sock (10)\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:19 +0000] [10] [INFO] Using worker: gevent\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:19 +0000] [12] [INFO] Booting worker with pid: 12\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:19 +0000] [13] [INFO] Booting worker with pid: 13\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:19 +0000] [14] [INFO] Booting worker with pid: 14\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:19 +0000] [15] [INFO] Booting worker with pid: 15\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:19 +0000] [16] [INFO] Booting worker with pid: 16\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:19 +0000] [17] [INFO] Booting worker with pid: 17\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:19 +0000] [18] [INFO] Booting worker with pid: 18\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:19 +0000] [19] [INFO] Booting worker with pid: 19\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:19 +0000] [20] [INFO] Booting worker with pid: 20\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:19 +0000] [29] [INFO] Booting worker with pid: 29\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:19 +0000] [54] [INFO] Booting worker with pid: 54\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:19 +0000] [55] [INFO] Booting worker with pid: 55\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:19 +0000] [56] [INFO] Booting worker with pid: 56\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:20 +0000] [65] [INFO] Booting worker with pid: 65\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:20 +0000] [66] [INFO] Booting worker with pid: 66\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:23:20 +0000] [67] [INFO] Booting worker with pid: 67\n",
      "!\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m 172.18.0.1 - - [13/Oct/2022:03:23:23 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"python-urllib3/1.26.8\"\n"
     ]
    }
   ],
   "source": [
    "local_predictor = local_lightgbm.deploy(1, 'local', serializer=sagemaker.serializers.CSVSerializer()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90104b4c-3acb-4cd2-a021-215074c71fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                                                                             COMMAND   CREATED         STATUS         PORTS                                       NAMES\n",
      "69350c1f4475   021345128571.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-lightgbm-regression   \"serve\"   3 minutes ago   Up 3 minutes   0.0.0.0:8080->8080/tcp, :::8080->8080/tcp   98mgw9t4v0-algo-1-lepex\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "243d3d14-892f-4a99-81f0-c3ec814bc98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m98mgw9t4v0-algo-1-lepex |\u001b[0m [2022-10-13 03:23:12 +0000] [10] [INFO] Handling signal: term\n",
      "\u001b[36m98mgw9t4v0-algo-1-lepex exited with code 0\n",
      "69350c1f4475\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    }
   ],
   "source": [
    "!docker stop 69350c1f4475"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02567390-11a4-4640-bbed-8618d4c5f452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9b62680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m Invoked with 102 records\n",
      "====================\n",
      "19.95642073217597\n",
      "27.844891841022335\n",
      "23.747437427003455\n",
      "21.961517177305176\n",
      "33.70952263893306\n",
      "16.546899933876215\n",
      "20.7577247308279\n",
      "21.58941351302627\n",
      "28.44096446328559\n",
      "21.573610198594977\n",
      "16.520022349295115\n",
      "18.56239893242527\n",
      "33.70952263893306\n",
      "21.66404760045202\n",
      "18.839854556333133\n",
      "20.524517944865078\n",
      "23.512192914502315\n",
      "19.720552829648888\n",
      "14.831841119971708\n",
      "25.48273874904075\n",
      "24.232639474441545\n",
      "21.624005932843115\n",
      "24.961489794296718\n",
      "31.737194191676068\n",
      "21.634052928440624\n",
      "28.40721160777621\n",
      "21.408363849719503\n",
      "14.831841119971708\n",
      "22.218594550645975\n",
      "21.174456098551236\n",
      "21.78791955089051\n",
      "14.831841119971708\n",
      "29.996695633096042\n",
      "22.44097524661187\n",
      "33.83316205414468\n",
      "26.41403196992683\n",
      "33.70952263893306\n",
      "17.366188662166092\n",
      "27.56686070285819\n",
      "30.785697489113854\n",
      "19.36938873496206\n",
      "20.70626548555591\n",
      "17.759853567831996\n",
      "27.888269821752413\n",
      "20.521395163186774\n",
      "14.831841119971708\n",
      "24.776417537973362\n",
      "24.965857100129327\n",
      "19.649289821764185\n",
      "21.026797620813866\n",
      "33.70952263893306\n",
      "22.770867837558004\n",
      "25.12436361101226\n",
      "32.04499227317663\n",
      "20.300871717805446\n",
      "25.993751032745912\n",
      "14.831841119971708\n",
      "17.55319877077615\n",
      "21.070286538617665\n",
      "21.122413297289743\n",
      "16.377053075082987\n",
      "15.568373592583868\n",
      "33.70952263893306\n",
      "27.61154020402463\n",
      "19.342761095149218\n",
      "17.9509721146777\n",
      "33.70952263893306\n",
      "33.83316205414468\n",
      "25.48273874904075\n",
      "20.660796015624964\n",
      "30.699461095863427\n",
      "21.035390723179418\n",
      "22.185819485247606\n",
      "19.29909952861762\n",
      "16.5747000607082\n",
      "23.912684065447934\n",
      "28.57571329880843\n",
      "16.236339853147257\n",
      "27.50109599287484\n",
      "15.753943396426372\n",
      "17.4887323059089\n",
      "16.546899933876215\n",
      "27.601367949672184\n",
      "27.83102844560462\n",
      "23.566264337152624\n",
      "27.50109599287484\n",
      "21.643847857886936\n",
      "18.787237415866525\n",
      "17.9186752451325\n",
      "14.831841119971708\n",
      "22.735042390270507\n",
      "18.93446150698524\n",
      "20.78281339932023\n",
      "15.124660622321342\n",
      "26.580072090826267\n",
      "33.83316205414468\n",
      "22.241689637239144\n",
      "18.003487732270226\n",
      "26.120941030113585\n",
      "21.857620352091608\n",
      "23.067030809188566\n",
      "31.381458114994132\n",
      "\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m 172.18.0.1 - - [13/Oct/2022:03:23:53 +0000] \"POST /invocations HTTP/1.1\" 200 1894 \"-\" \"python-urllib3/1.26.8\"\n"
     ]
    }
   ],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = local_predictor.predict(payload).decode('utf-8')\n",
    "print('=' * 20)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafe8b28",
   "metadata": {},
   "source": [
    "# 学習ジョブを発行\n",
    "次は、ローカルモードではなく、\n",
    "同じカスタムコンテナで、学習ジョブを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b36f6cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850f7a52-0745-4aa5-a138-c4a35369c449",
   "metadata": {},
   "source": [
    "## S3bucket作成して、格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6d147a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "bucket_name = '<bucket_name>' # input your bucket name\n",
    "bucket_name = 'demo-lgbm-container'\n",
    "\n",
    "train_s3 = sagemaker.s3.S3Uploader.upload('./data/train/boston_train.csv', f's3://{bucket_name}/demo_lightgbm/train')\n",
    "valid_s3 = sagemaker.s3.S3Uploader.upload('./data/valid/boston_valid.csv', f's3://{bucket_name}/demo_lightgbm/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d5017de",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_lightgbm = Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.2xlarge\",\n",
    "    hyperparameters={'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e6d2200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-13 03:26:10 Starting - Starting the training job...\n",
      "2022-10-13 03:26:34 Starting - Preparing the instances for trainingProfilerReport-1665631570: InProgress\n",
      ".........\n",
      "2022-10-13 03:28:05 Downloading - Downloading input data...\n",
      "2022-10-13 03:28:35 Training - Downloading the training image...\n",
      "2022-10-13 03:29:11 Uploading - Uploading generated training model.\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mReading hyperparameters data: /opt/ml/input/config/hyperparameters.json\u001b[0m\n",
      "\u001b[34mhyperparameters_data: {'bagging_fraction': '0.8', 'bagging_freq': '5', 'boosting_type': 'gbdt', 'feature_fraction': '0.9', 'learning_rate': '0.05', 'num_leaves': '31', 'objective': 'regression', 'verbose': '0'}\u001b[0m\n",
      "\u001b[34mFound train files: ['/opt/ml/input/data/train/boston_train.csv']\u001b[0m\n",
      "\u001b[34mFound validation files: ['/opt/ml/input/data/validation/boston_valid.csv']\u001b[0m\n",
      "\u001b[34mbuilding training and validation datasets\u001b[0m\n",
      "\u001b[34mStarting training...\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003933 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_row_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34mAnd if memory is not enough, you can set `force_col_wise=true`.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[1]#011valid_0's l2: 84.4849\u001b[0m\n",
      "\u001b[34mTraining until validation scores don't improve for 5 rounds\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[2]#011valid_0's l2: 78.6995\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[3]#011valid_0's l2: 73.3733\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[4]#011valid_0's l2: 68.4066\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[5]#011valid_0's l2: 63.9675\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[6]#011valid_0's l2: 60.4495\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[7]#011valid_0's l2: 57.2702\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[8]#011valid_0's l2: 54.3096\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[9]#011valid_0's l2: 51.6438\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[10]#011valid_0's l2: 49.4106\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[11]#011valid_0's l2: 46.871\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[12]#011valid_0's l2: 44.4878\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[13]#011valid_0's l2: 42.2348\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[14]#011valid_0's l2: 40.2703\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[15]#011valid_0's l2: 38.4195\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[16]#011valid_0's l2: 36.6089\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[17]#011valid_0's l2: 34.9745\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[18]#011valid_0's l2: 33.5774\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[19]#011valid_0's l2: 32.1331\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[20]#011valid_0's l2: 30.8945\u001b[0m\n",
      "\u001b[34mDid not meet early stopping. Best iteration is:\u001b[0m\n",
      "\u001b[34m[20]#011valid_0's l2: 30.8945\u001b[0m\n",
      "\u001b[34msaving model file to /opt/ml/model/lightgbm-regression-model.txt\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2022-10-13 03:29:35 Completed - Training job completed\n",
      "Training seconds: 77\n",
      "Billable seconds: 77\n"
     ]
    }
   ],
   "source": [
    "est_lightgbm.fit({'train':train_s3, 'validation': valid_s3}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1539bace-be94-42c7-9712-0ad2f015c523",
   "metadata": {},
   "source": [
    "学習には3分ほど時間がかかります。\n",
    "\n",
    "課金されるのは75秒ほどです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6106c1",
   "metadata": {},
   "source": [
    "## エンドポイントにデプロイ\n",
    "waitしない-> する\n",
    "\n",
    "waitの間に解説\n",
    "\n",
    "デプロイすると、\n",
    "SageMaker は docker run <image> serveを実行します。\n",
    "    serveスクリプトには、xxxxx\n",
    "    webサーバ：nginx\n",
    "    appサーバ：gunicorn\n",
    "    が起動し、Flaskを使ったアプリケーションpredict.pyを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e18b4179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "#predictor = est_lightgbm.deploy(1, 'ml.m4.xlarge', serializer=csv_serializer, wait=False)\n",
    "#predictor = est_lightgbm.deploy(1, 'ml.m4.xlarge', serializer=csv_serializer, wait=False)\n",
    "predictor = est_lightgbm.deploy(1, 'ml.m4.xlarge', serializer=csv_serializer, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b93441",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = predictor.predict(payload).decode('utf-8')\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda0d7d1-4229-461b-9095-60945b253876",
   "metadata": {},
   "source": [
    "# 2. 実行ファイルを外部から指定する\n",
    "\n",
    "Part1 ではカスタムコンテナ内に学習起動スクリプトtrainを配置しましたが、\n",
    "ソースコードを修正するごとにコンテナを作り替える必要があります。\n",
    "\n",
    "保守性を上げるには、コンテナ（環境）とソースコードを分けた方がいい場合もあります。\n",
    "以下では外部からスクリプトファイルを指定する方法を紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c414e08-68d0-422e-bec5-5442d87d10cb",
   "metadata": {},
   "source": [
    "## SageMaker Training Toolkit\n",
    "外部からスクリプトを指定するためには、SageMaker Training Toolkitを導入します。\n",
    "\n",
    "https://github.com/aws/sagemaker-training-toolkit\n",
    "\n",
    "\n",
    "trainコマンドが\n",
    "/conca/bin/train\n",
    "にインストールされます。\n",
    "\n",
    "\n",
    "先程のdockerfileに追記します。\n",
    "資材からは、trainを除外しておきます。trainを含んだままだと、\n",
    "docker run <image> train\n",
    "を実行したときに、カレントディレクトリのtrainスクリプトが実行されてしまい、training toolkitが導入した　trainコマンドが実行できないためです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abecdc90",
   "metadata": {},
   "source": [
    "### 学習スクリプトをローカルに保存して実行\n",
    "GitHubから実行したい場合も。\n",
    "\n",
    "SageMaker Training Toolkitが必要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31273a0",
   "metadata": {},
   "source": [
    "### カスタムコンテナ作成\n",
    "trainは含めないように注意しましょう。\n",
    "\n",
    "Dockerfileにて、\n",
    "・train を /opt/program/train と配置\n",
    "・カレントディレクトリを /opt/program に設定\n",
    "・SageMaker Training Toolkit が /opt/conda/bin/train にインストールされる\n",
    "・train を実行すると、カレントにある /opt/program/train が実行されてしまう。\n",
    "解決するには、\n",
    "・カレントディレクトリを 持ち込みのtrainがある場所にしない\n",
    "・train をそもそもコンテナに入れない（確実）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c0f63c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  19.97kB\n",
      "Step 1/14 : FROM ubuntu:16.04\n",
      " ---> b6f507652425\n",
      "Step 2/14 : MAINTAINER Amazon AI <sage-learner@amazon.com>\n",
      " ---> Using cache\n",
      " ---> c5602b2d98e4\n",
      "Step 3/14 : ARG CONDA_DIR=/opt/conda\n",
      " ---> Using cache\n",
      " ---> 618227bc5218\n",
      "Step 4/14 : ENV PATH $CONDA_DIR/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> f0165591799f\n",
      "Step 5/14 : RUN apt-get update &&     apt-get install -y --no-install-recommends         ca-certificates         cmake         build-essential         gcc         g++         git         nginx         wget &&     wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh &&     /bin/bash Miniconda3-latest-Linux-x86_64.sh -f -b -p $CONDA_DIR &&     export PATH=\"$CONDA_DIR/bin:$PATH\" &&     conda config --set always_yes yes --set changeps1 no &&     conda install -q -y numpy scipy scikit-learn pandas flask gevent gunicorn &&     git clone --recursive --branch stable --depth 1 https://github.com/Microsoft/LightGBM &&     cd LightGBM/python-package && python setup.py install &&     apt-get autoremove -y && apt-get clean &&     conda clean -a -y &&     rm -rf /usr/local/src/*\n",
      " ---> Using cache\n",
      " ---> 99c43eb4621f\n",
      "Step 6/14 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> dc6222c249df\n",
      "Step 7/14 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> be12e73d2688\n",
      "Step 8/14 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 878673fa1725\n",
      "Step 9/14 : COPY lightgbm_regression /opt/program\n",
      " ---> Using cache\n",
      " ---> 147e653f3666\n",
      "Step 10/14 : ARG PIP=pip3\n",
      " ---> Using cache\n",
      " ---> 3bc6992cce42\n",
      "Step 11/14 : RUN ${PIP} --no-cache-dir install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 82196b2d6ac0\n",
      "Step 12/14 : RUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n",
      " ---> Using cache\n",
      " ---> 9043ca1cc9d4\n",
      "Step 13/14 : RUN ${PIP} install --no-cache --upgrade     sagemaker-training\n",
      " ---> Using cache\n",
      " ---> 0830ace4985f\n",
      "Step 14/14 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 30cb95954efd\n",
      "Successfully built 30cb95954efd\n",
      "Successfully tagged sagemaker-toolkit:latest\n",
      "The push refers to repository [021345128571.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-toolkit]\n",
      "111015558fc5: Preparing\n",
      "093dc73ad893: Preparing\n",
      "b12d66f62e5d: Preparing\n",
      "89132137133b: Preparing\n",
      "11dfd6aa9089: Preparing\n",
      "1251204ef8fc: Preparing\n",
      "47ef83afae74: Preparing\n",
      "df54c846128d: Preparing\n",
      "be96a3f634de: Preparing\n",
      "47ef83afae74: Waiting\n",
      "df54c846128d: Waiting\n",
      "1251204ef8fc: Waiting\n",
      "be96a3f634de: Waiting\n",
      "11dfd6aa9089: Layer already exists\n",
      "111015558fc5: Layer already exists\n",
      "093dc73ad893: Layer already exists\n",
      "b12d66f62e5d: Layer already exists\n",
      "89132137133b: Layer already exists\n",
      "1251204ef8fc: Layer already exists\n",
      "df54c846128d: Layer already exists\n",
      "be96a3f634de: Layer already exists\n",
      "47ef83afae74: Layer already exists\n",
      "latest: digest: sha256:5a4fa1b6d79cfa40e4208f24804921aeee4595633809668bb5d7ec410d84f1b1 size: 2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-toolkit\n",
    "\n",
    "#cd container\n",
    "cd container_smtrtoolkit ### 変更点\n",
    "\n",
    "#chmod +x lightgbm_regression/train\n",
    "chmod +x lightgbm_regression/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b485b8",
   "metadata": {},
   "source": [
    "## 学習(ローカル)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b633e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = '805433377179.dkr.ecr.us-west-2.amazonaws.com/sagemaker-lightgbm-toolkit:latest'\n",
    "image = '021345128571.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-toolkit'\n",
    "#image = <input your own image URI>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "03b2a101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating n9nwn2rft8-algo-1-l0xvv ... \n",
      "Creating n9nwn2rft8-algo-1-l0xvv ... done\n",
      "Attaching to n9nwn2rft8-algo-1-l0xvv\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m 2022-10-13 03:45:55,344 botocore.credentials INFO     Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m 2022-10-13 03:45:55,545 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m 2022-10-13 03:45:55,546 sagemaker-training-toolkit INFO     Failed to parse hyperparameter boosting_type value gbdt to Json.\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m Returning the value itself\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m 2022-10-13 03:45:55,546 sagemaker-training-toolkit INFO     Failed to parse hyperparameter objective value regression to Json.\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m Returning the value itself\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m 2022-10-13 03:45:55,555 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m 2022-10-13 03:45:55,557 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m 2022-10-13 03:45:55,558 sagemaker-training-toolkit INFO     Failed to parse hyperparameter boosting_type value gbdt to Json.\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m Returning the value itself\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m 2022-10-13 03:45:55,558 sagemaker-training-toolkit INFO     Failed to parse hyperparameter objective value regression to Json.\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m Returning the value itself\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m 2022-10-13 03:45:55,565 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m 2022-10-13 03:45:55,567 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m 2022-10-13 03:45:55,568 sagemaker-training-toolkit INFO     Failed to parse hyperparameter boosting_type value gbdt to Json.\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m Returning the value itself\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m 2022-10-13 03:45:55,568 sagemaker-training-toolkit INFO     Failed to parse hyperparameter objective value regression to Json.\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m Returning the value itself\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m 2022-10-13 03:45:55,575 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m 2022-10-13 03:45:55,576 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m \n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m Training Env:\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m \n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m {\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\"\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     },\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"current_host\": \"algo-1-l0xvv\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"current_instance_group\": \"homogeneousCluster\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"current_instance_group_hosts\": [],\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"current_instance_type\": \"local\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"distribution_hosts\": [\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         \"algo-1-l0xvv\"\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     ],\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"distribution_instance_groups\": [],\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"framework_module\": null,\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         \"algo-1-l0xvv\"\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     ],\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         \"boosting_type\": \"gbdt\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         \"objective\": \"regression\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         \"num_leaves\": 31,\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         \"learning_rate\": 0.05,\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         \"feature_fraction\": 0.9,\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         \"bagging_fraction\": 0.8,\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         \"bagging_freq\": 5,\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         \"verbose\": 0\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     },\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         \"train\": {\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         },\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         \"validation\": {\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         }\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     },\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"instance_groups\": [],\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"instance_groups_dict\": {},\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"is_hetero\": false,\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"is_modelparallel_enabled\": null,\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"job_name\": \"sagemaker-toolkit-2022-10-13-03-45-53-316\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"master_hostname\": \"algo-1-l0xvv\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-1-021345128571/sagemaker-toolkit-2022-10-13-03-45-53-316/source/sourcedir.tar.gz\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"module_name\": \"train_practice\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"num_cpus\": 16,\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         \"current_host\": \"algo-1-l0xvv\",\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m             \"algo-1-l0xvv\"\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m         ]\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     },\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m     \"user_entry_point\": \"train_practice.py\"\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m }\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m \n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m Environment variables:\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m \n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_HOSTS=[\"algo-1-l0xvv\"]\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_HPS={\"bagging_fraction\":0.8,\"bagging_freq\":5,\"boosting_type\":\"gbdt\",\"feature_fraction\":0.9,\"learning_rate\":0.05,\"num_leaves\":31,\"objective\":\"regression\",\"verbose\":0}\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_USER_ENTRY_POINT=train_practice.py\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-l0xvv\",\"hosts\":[\"algo-1-l0xvv\"]}\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_CHANNELS=[\"train\",\"validation\"]\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_CURRENT_HOST=algo-1-l0xvv\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_CURRENT_INSTANCE_TYPE=local\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_CURRENT_INSTANCE_GROUP_HOSTS=[]\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_INSTANCE_GROUPS=[]\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_INSTANCE_GROUPS_DICT={}\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_IS_HETERO=false\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_MODULE_NAME=train_practice\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_FRAMEWORK_MODULE=\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_NUM_CPUS=16\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-1-021345128571/sagemaker-toolkit-2022-10-13-03-45-53-316/source/sourcedir.tar.gz\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-l0xvv\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[],\"current_instance_type\":\"local\",\"distribution_hosts\":[\"algo-1-l0xvv\"],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1-l0xvv\"],\"hyperparameters\":{\"bagging_fraction\":0.8,\"bagging_freq\":5,\"boosting_type\":\"gbdt\",\"feature_fraction\":0.9,\"learning_rate\":0.05,\"num_leaves\":31,\"objective\":\"regression\",\"verbose\":0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[],\"instance_groups_dict\":{},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"sagemaker-toolkit-2022-10-13-03-45-53-316\",\"log_level\":20,\"master_hostname\":\"algo-1-l0xvv\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-1-021345128571/sagemaker-toolkit-2022-10-13-03-45-53-316/source/sourcedir.tar.gz\",\"module_name\":\"train_practice\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-l0xvv\",\"hosts\":[\"algo-1-l0xvv\"]},\"user_entry_point\":\"train_practice.py\"}\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_USER_ARGS=[\"--bagging_fraction\",\"0.8\",\"--bagging_freq\",\"5\",\"--boosting_type\",\"gbdt\",\"--feature_fraction\",\"0.9\",\"--learning_rate\",\"0.05\",\"--num_leaves\",\"31\",\"--objective\",\"regression\",\"--verbose\",\"0\"]\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_HP_BOOSTING_TYPE=gbdt\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_HP_OBJECTIVE=regression\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_HP_NUM_LEAVES=31\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_HP_LEARNING_RATE=0.05\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_HP_FEATURE_FRACTION=0.9\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_HP_BAGGING_FRACTION=0.8\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_HP_BAGGING_FREQ=5\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m SM_HP_VERBOSE=0\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m \n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m \n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m /opt/conda/bin/python train_practice.py --bagging_fraction 0.8 --bagging_freq 5 --boosting_type gbdt --feature_fraction 0.9 --learning_rate 0.05 --num_leaves 31 --objective regression --verbose 0\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m \n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m \n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m 2022-10-13 03:45:55,576 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m ===== congraturations! You understand how SageMaker Training Job Works!!! =====\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m Starting the training.\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m Reading hyperparameters data: /opt/ml/input/config/hyperparameters.json\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m hyperparameters_data: {'boosting_type': 'gbdt', 'objective': 'regression', 'num_leaves': '31', 'learning_rate': '0.05', 'feature_fraction': '0.9', 'bagging_fraction': '0.8', 'bagging_freq': '5', 'verbose': '0', 'sagemaker_submit_directory': '\"s3://sagemaker-ap-northeast-1-021345128571/sagemaker-toolkit-2022-10-13-03-45-53-316/source/sourcedir.tar.gz\"', 'sagemaker_program': '\"train_practice.py\"', 'sagemaker_container_log_level': '20', 'sagemaker_job_name': '\"sagemaker-toolkit-2022-10-13-03-45-53-316\"', 'sagemaker_region': '\"ap-northeast-1\"'}\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m Found train files: ['/opt/ml/input/data/train/boston_train.csv']\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m Found validation files: ['/opt/ml/input/data/validation/boston_valid.csv']\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m building training and validation datasets\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m Starting training...\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m /opt/conda/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m   _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m You can set `force_col_wise=true` to remove the overhead.\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [1]\tvalid_0's l2: 84.4849\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m Training until validation scores don't improve for 5 rounds\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [2]\tvalid_0's l2: 78.6995\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [3]\tvalid_0's l2: 73.3733\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [4]\tvalid_0's l2: 68.4066\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [5]\tvalid_0's l2: 63.9675\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [6]\tvalid_0's l2: 60.4495\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [7]\tvalid_0's l2: 57.2702\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [8]\tvalid_0's l2: 54.3096\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [9]\tvalid_0's l2: 51.6438\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [10]\tvalid_0's l2: 49.4106\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [11]\tvalid_0's l2: 46.871\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [12]\tvalid_0's l2: 44.4878\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [13]\tvalid_0's l2: 42.2348\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [14]\tvalid_0's l2: 40.2703\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [15]\tvalid_0's l2: 38.4195\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [16]\tvalid_0's l2: 36.6089\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [17]\tvalid_0's l2: 34.9745\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [18]\tvalid_0's l2: 33.5774\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [19]\tvalid_0's l2: 32.1331\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [20]\tvalid_0's l2: 30.8945\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m Did not meet early stopping. Best iteration is:\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m [20]\tvalid_0's l2: 30.8945\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m saving model file to /opt/ml/model/lightgbm-regression-model.txt\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m Training complete.\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv |\u001b[0m 2022-10-13 03:45:56,552 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mn9nwn2rft8-algo-1-l0xvv exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "est_lightgbm3 = Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    #instance_type=\"ml.m4.2xlarge\",\n",
    "    instance_type=\"local\",\n",
    "    hyperparameters={'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0},\n",
    "    #source_dir='./practice_src',\n",
    "    entry_point='./src/train_practice.py'\n",
    "    #entry_point='./practice_src/train_practice.sh'\n",
    "    )\n",
    "est_lightgbm3.fit({'train':train_s3, 'validation': valid_s3}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09d6b18",
   "metadata": {},
   "source": [
    "## デプロイローカル\n",
    "\n",
    "デプロイは割愛します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa69d352-1528-40b6-94b9-818b743b268c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                                                                             COMMAND   CREATED          STATUS          PORTS                                       NAMES\n",
      "020337809d76   021345128571.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-lightgbm-regression   \"serve\"   23 minutes ago   Up 23 minutes   0.0.0.0:8080->8080/tcp, :::8080->8080/tcp   jioo7o4vps-algo-1-9ktq9\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "03885f8b-b97b-4bf8-b3cb-5dbe7f8c6e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 |\u001b[0m [2022-10-13 03:46:55 +0000] [10] [INFO] Handling signal: term\n",
      "\u001b[36mjioo7o4vps-algo-1-9ktq9 exited with code 0\n",
      "020337809d76\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    }
   ],
   "source": [
    "!docker stop 020337809d76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2971a55-1b48-449c-95c4-ea7b131d86d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1befe0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to b791gxyeqr-algo-1-ndhry\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m Starting the inference server with 16 workers.\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:02 +0000] [10] [INFO] Starting gunicorn 20.1.0\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:02 +0000] [10] [INFO] Listening at: unix:/tmp/gunicorn.sock (10)\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:02 +0000] [10] [INFO] Using worker: gevent\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:02 +0000] [12] [INFO] Booting worker with pid: 12\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:02 +0000] [13] [INFO] Booting worker with pid: 13\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:02 +0000] [14] [INFO] Booting worker with pid: 14\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:02 +0000] [15] [INFO] Booting worker with pid: 15\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:02 +0000] [16] [INFO] Booting worker with pid: 16\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:02 +0000] [17] [INFO] Booting worker with pid: 17\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:02 +0000] [18] [INFO] Booting worker with pid: 18\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:02 +0000] [19] [INFO] Booting worker with pid: 19\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:02 +0000] [20] [INFO] Booting worker with pid: 20\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:02 +0000] [21] [INFO] Booting worker with pid: 21\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:02 +0000] [30] [INFO] Booting worker with pid: 30\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:02 +0000] [31] [INFO] Booting worker with pid: 31\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:02 +0000] [32] [INFO] Booting worker with pid: 32\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:03 +0000] [33] [INFO] Booting worker with pid: 33\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:03 +0000] [50] [INFO] Booting worker with pid: 50\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m [2022-10-13 03:47:03 +0000] [51] [INFO] Booting worker with pid: 51\n",
      "!\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m 172.18.0.1 - - [13/Oct/2022:03:47:06 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"python-urllib3/1.26.8\"\n"
     ]
    }
   ],
   "source": [
    "predictor3 = est_lightgbm3.deploy(1, 'local', serializer=csv_serializer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e0200272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m Invoked with 102 records\n",
      "19.95642073217597\n",
      "27.844891841022335\n",
      "23.747437427003455\n",
      "21.961517177305176\n",
      "33.70952263893306\n",
      "16.546899933876215\n",
      "20.7577247308279\n",
      "21.58941351302627\n",
      "28.44096446328559\n",
      "21.573610198594977\n",
      "16.520022349295115\n",
      "18.56239893242527\n",
      "33.70952263893306\n",
      "21.66404760045202\n",
      "18.839854556333133\n",
      "20.524517944865078\n",
      "23.512192914502315\n",
      "19.720552829648888\n",
      "14.831841119971708\n",
      "25.48273874904075\n",
      "24.232639474441545\n",
      "21.624005932843115\n",
      "24.961489794296718\n",
      "31.737194191676068\n",
      "21.634052928440624\n",
      "28.40721160777621\n",
      "21.408363849719503\n",
      "14.831841119971708\n",
      "22.218594550645975\n",
      "21.174456098551236\n",
      "21.78791955089051\n",
      "14.831841119971708\n",
      "29.996695633096042\n",
      "22.44097524661187\n",
      "33.83316205414468\n",
      "26.41403196992683\n",
      "33.70952263893306\n",
      "17.366188662166092\n",
      "27.56686070285819\n",
      "30.785697489113854\n",
      "19.36938873496206\n",
      "20.70626548555591\n",
      "17.759853567831996\n",
      "27.888269821752413\n",
      "20.521395163186774\n",
      "14.831841119971708\n",
      "24.776417537973362\n",
      "24.965857100129327\n",
      "19.649289821764185\n",
      "21.026797620813866\n",
      "33.70952263893306\n",
      "22.770867837558004\n",
      "25.12436361101226\n",
      "32.04499227317663\n",
      "20.300871717805446\n",
      "25.993751032745912\n",
      "14.831841119971708\n",
      "17.55319877077615\n",
      "21.070286538617665\n",
      "21.122413297289743\n",
      "16.377053075082987\n",
      "15.568373592583868\n",
      "33.70952263893306\n",
      "27.61154020402463\n",
      "19.342761095149218\n",
      "17.9509721146777\n",
      "33.70952263893306\n",
      "33.83316205414468\n",
      "25.48273874904075\n",
      "20.660796015624964\n",
      "30.699461095863427\n",
      "21.035390723179418\n",
      "22.185819485247606\n",
      "19.29909952861762\n",
      "16.5747000607082\n",
      "23.912684065447934\n",
      "28.57571329880843\n",
      "16.236339853147257\n",
      "27.50109599287484\n",
      "15.753943396426372\n",
      "17.4887323059089\n",
      "16.546899933876215\n",
      "27.601367949672184\n",
      "27.83102844560462\n",
      "23.566264337152624\n",
      "27.50109599287484\n",
      "21.643847857886936\n",
      "18.787237415866525\n",
      "17.9186752451325\n",
      "14.831841119971708\n",
      "22.735042390270507\n",
      "18.93446150698524\n",
      "20.78281339932023\n",
      "15.124660622321342\n",
      "26.580072090826267\n",
      "33.83316205414468\n",
      "22.241689637239144\n",
      "18.003487732270226\n",
      "26.120941030113585\n",
      "21.857620352091608\n",
      "23.067030809188566\n",
      "31.381458114994132\n",
      "\u001b[36mb791gxyeqr-algo-1-ndhry |\u001b[0m 172.18.0.1 - - [13/Oct/2022:03:47:08 +0000] \"POST /invocations HTTP/1.1\" 200 1894 \"-\" \"python-urllib3/1.26.8\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = predictor3.predict(payload).decode('utf-8')\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf4f134-53d5-453d-af94-b52bdf237e04",
   "metadata": {},
   "source": [
    "## シェルスクリプトを実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb00d1ba-4b95-41d2-b464-74ef32124c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sijzljjfxk-algo-1-ff6u8 ... \n",
      "Creating sijzljjfxk-algo-1-ff6u8 ... done\n",
      "Attaching to sijzljjfxk-algo-1-ff6u8\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m 2022-10-13 03:55:07,951 botocore.credentials INFO     Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m 2022-10-13 03:55:08,131 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m 2022-10-13 03:55:08,131 sagemaker-training-toolkit INFO     Failed to parse hyperparameter boosting_type value gbdt to Json.\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m Returning the value itself\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m 2022-10-13 03:55:08,131 sagemaker-training-toolkit INFO     Failed to parse hyperparameter objective value regression to Json.\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m Returning the value itself\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m 2022-10-13 03:55:08,141 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m 2022-10-13 03:55:08,143 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m 2022-10-13 03:55:08,144 sagemaker-training-toolkit INFO     Failed to parse hyperparameter boosting_type value gbdt to Json.\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m Returning the value itself\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m 2022-10-13 03:55:08,144 sagemaker-training-toolkit INFO     Failed to parse hyperparameter objective value regression to Json.\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m Returning the value itself\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m 2022-10-13 03:55:08,151 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m 2022-10-13 03:55:08,153 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m 2022-10-13 03:55:08,154 sagemaker-training-toolkit INFO     Failed to parse hyperparameter boosting_type value gbdt to Json.\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m Returning the value itself\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m 2022-10-13 03:55:08,154 sagemaker-training-toolkit INFO     Failed to parse hyperparameter objective value regression to Json.\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m Returning the value itself\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m 2022-10-13 03:55:08,161 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m 2022-10-13 03:55:08,161 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m \n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m Training Env:\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m \n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m {\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\"\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     },\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"current_host\": \"algo-1-ff6u8\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"current_instance_group\": \"homogeneousCluster\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"current_instance_group_hosts\": [],\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"current_instance_type\": \"local\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"distribution_hosts\": [\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         \"algo-1-ff6u8\"\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     ],\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"distribution_instance_groups\": [],\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"framework_module\": null,\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         \"algo-1-ff6u8\"\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     ],\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         \"boosting_type\": \"gbdt\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         \"objective\": \"regression\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         \"num_leaves\": 31,\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         \"learning_rate\": 0.05,\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         \"feature_fraction\": 0.9,\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         \"bagging_fraction\": 0.8,\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         \"bagging_freq\": 5,\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         \"verbose\": 0\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     },\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         \"train\": {\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         },\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         \"validation\": {\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         }\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     },\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"instance_groups\": [],\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"instance_groups_dict\": {},\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"is_hetero\": false,\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"is_modelparallel_enabled\": null,\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"job_name\": \"sagemaker-toolkit-2022-10-13-03-55-06-039\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"master_hostname\": \"algo-1-ff6u8\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-1-021345128571/sagemaker-toolkit-2022-10-13-03-55-06-039/source/sourcedir.tar.gz\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"module_name\": \"train_practice.sh\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"num_cpus\": 16,\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         \"current_host\": \"algo-1-ff6u8\",\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m             \"algo-1-ff6u8\"\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m         ]\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     },\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m     \"user_entry_point\": \"train_practice.sh\"\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m }\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m \n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m Environment variables:\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m \n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_HOSTS=[\"algo-1-ff6u8\"]\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_HPS={\"bagging_fraction\":0.8,\"bagging_freq\":5,\"boosting_type\":\"gbdt\",\"feature_fraction\":0.9,\"learning_rate\":0.05,\"num_leaves\":31,\"objective\":\"regression\",\"verbose\":0}\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_USER_ENTRY_POINT=train_practice.sh\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-ff6u8\",\"hosts\":[\"algo-1-ff6u8\"]}\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_CHANNELS=[\"train\",\"validation\"]\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_CURRENT_HOST=algo-1-ff6u8\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_CURRENT_INSTANCE_TYPE=local\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_CURRENT_INSTANCE_GROUP_HOSTS=[]\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_INSTANCE_GROUPS=[]\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_INSTANCE_GROUPS_DICT={}\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_IS_HETERO=false\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_MODULE_NAME=train_practice.sh\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_FRAMEWORK_MODULE=\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_NUM_CPUS=16\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-1-021345128571/sagemaker-toolkit-2022-10-13-03-55-06-039/source/sourcedir.tar.gz\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-ff6u8\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[],\"current_instance_type\":\"local\",\"distribution_hosts\":[\"algo-1-ff6u8\"],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1-ff6u8\"],\"hyperparameters\":{\"bagging_fraction\":0.8,\"bagging_freq\":5,\"boosting_type\":\"gbdt\",\"feature_fraction\":0.9,\"learning_rate\":0.05,\"num_leaves\":31,\"objective\":\"regression\",\"verbose\":0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[],\"instance_groups_dict\":{},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"sagemaker-toolkit-2022-10-13-03-55-06-039\",\"log_level\":20,\"master_hostname\":\"algo-1-ff6u8\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-1-021345128571/sagemaker-toolkit-2022-10-13-03-55-06-039/source/sourcedir.tar.gz\",\"module_name\":\"train_practice.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-ff6u8\",\"hosts\":[\"algo-1-ff6u8\"]},\"user_entry_point\":\"train_practice.sh\"}\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_USER_ARGS=[\"--bagging_fraction\",\"0.8\",\"--bagging_freq\",\"5\",\"--boosting_type\",\"gbdt\",\"--feature_fraction\",\"0.9\",\"--learning_rate\",\"0.05\",\"--num_leaves\",\"31\",\"--objective\",\"regression\",\"--verbose\",\"0\"]\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_HP_BOOSTING_TYPE=gbdt\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_HP_OBJECTIVE=regression\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_HP_NUM_LEAVES=31\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_HP_LEARNING_RATE=0.05\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_HP_FEATURE_FRACTION=0.9\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_HP_BAGGING_FRACTION=0.8\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_HP_BAGGING_FREQ=5\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m SM_HP_VERBOSE=0\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m \n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m \n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m /bin/sh -c \"./train_practice.sh --bagging_fraction 0.8 --bagging_freq 5 --boosting_type gbdt --feature_fraction 0.9 --learning_rate 0.05 --num_leaves 31 --objective regression --verbose 0\"\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m \n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m \n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m 2022-10-13 03:55:08,162 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m This is external file!!!!!!!!!\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m /opt/ml/code\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m train_practice.sh\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m /opt/conda/bin/train\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 |\u001b[0m 2022-10-13 03:55:08,167 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36msijzljjfxk-algo-1-ff6u8 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "est_lightgbm3 = Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    #instance_type=\"ml.m4.2xlarge\",\n",
    "    instance_type=\"local\",\n",
    "    hyperparameters={'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0},\n",
    "    #source_dir='./practice_src',\n",
    "    entry_point='./src/train_practice.sh'\n",
    "    #entry_point='./practice_src/train_practice.sh'\n",
    "    )\n",
    "est_lightgbm3.fit({'train':train_s3, 'validation': valid_s3}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc89bff",
   "metadata": {},
   "source": [
    "# 参考\n",
    "\n",
    "\n",
    "SageMaker-Pytorth training Toolkit\n",
    "https://github.com/aws/sagemaker-pytorch-training-toolkit/\n",
    "\n",
    "\n",
    "SageMaker-Pytorch Inference Toolkit\n",
    "\n",
    "https://github.com/aws/sagemaker-pytorch-inference-toolkit\n",
    "\n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/73694705/what-is-the-difference-between-sagemaker-pytorch-training-toolkit-and-sagemaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47199dec",
   "metadata": {},
   "source": [
    "## 参考\n",
    "SageMaker のtrainingジョブを理解する\n",
    "\n",
    "https://github.com/aws-samples/aws-ml-jp/tree/main/sagemaker/sagemaker-traning/tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79693e98",
   "metadata": {},
   "source": [
    "# Toolkitを入れず、train からtrain.shを実行\n",
    "\n",
    "ソースをS3に配置しなればならない\n",
    "\n",
    "\n",
    "fit()について\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase.fit\n",
    "\n",
    "datasetの指定は、S3のパスか、ローカルモードならfile://　つまりGitHubは不可"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b82954",
   "metadata": {},
   "source": [
    "### SageMaker Traiing Toolkitについて\n",
    "\n",
    "https://github.com/aws/sagemaker-training-toolkit/blob/master/README.md\n",
    "\n",
    "inference toolkitもある。\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/amazon-sagemaker-toolkits.html\n",
    "\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f7cdfc",
   "metadata": {},
   "source": [
    "## （おまけ）カスタムコンテナを使わず、built-inコンテナのrequirement.txtにlightgbmを記載して実行する\n",
    "\n",
    "\n",
    "\n",
    "過去バージョン（1.3-3, 1.2-2, 1.2-1, 1.0-1)はこちら\n",
    "\n",
    "https://github.com/aws/sagemaker-xgboost-container/releases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "752de206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"1.5-1\")\n",
    "#container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fa8f683e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'354813040037.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-xgboost:1.5-1'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd47aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_lightgbm5 = Estimator(\n",
    "    #image,\n",
    "    container, # xgboostのbuilt-inコンテナ\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    #instance_type=\"ml.m4.2xlarge\",\n",
    "    instance_type=\"local\",\n",
    "    hyperparameters={'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0},\n",
    "    source_dir='./src_builtin_container',\n",
    "    entry_point='train_practice.py'\n",
    "    #entry_point='./practice_src/train_practice.sh'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e495abe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 1cbefdrksy-algo-1-3cmae ... \n",
      "Creating 1cbefdrksy-algo-1-3cmae ... done\n",
      "Attaching to 1cbefdrksy-algo-1-3cmae\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [2022-10-13 03:47:30.133 bb2b5d82f97f:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [2022-10-13:03:47:30:INFO] Imported framework sagemaker_xgboost_container.training\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [2022-10-13:03:47:30:INFO] Failed to parse hyperparameter boosting_type value gbdt to Json.\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Returning the value itself\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [2022-10-13:03:47:30:INFO] Failed to parse hyperparameter objective value regression to Json.\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Returning the value itself\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [2022-10-13:03:47:30:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [2022-10-13:03:47:30:INFO] Invoking user training script.\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [2022-10-13:03:47:30:INFO] Module train_practice does not provide a setup.py. \n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Generating setup.py\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [2022-10-13:03:47:30:INFO] Generating setup.cfg\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [2022-10-13:03:47:30:INFO] Generating MANIFEST.in\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [2022-10-13:03:47:30:INFO] Installing module with the following command:\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m /miniconda3/bin/python3 -m pip install . -r requirements.txt\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m \u001b[?25hCollecting lightgbm\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m   Downloading lightgbm-3.3.3-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m \u001b[?25hRequirement already satisfied: numpy in /miniconda3/lib/python3.8/site-packages (from lightgbm->-r requirements.txt (line 1)) (1.19.2)\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Requirement already satisfied: wheel in /miniconda3/lib/python3.8/site-packages (from lightgbm->-r requirements.txt (line 1)) (0.36.2)\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Requirement already satisfied: scikit-learn!=0.22.0 in /miniconda3/lib/python3.8/site-packages (from lightgbm->-r requirements.txt (line 1)) (0.24.1)\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Requirement already satisfied: scipy in /miniconda3/lib/python3.8/site-packages (from lightgbm->-r requirements.txt (line 1)) (1.6.2)\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Requirement already satisfied: joblib>=0.11 in /miniconda3/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm->-r requirements.txt (line 1)) (1.2.0)\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Requirement already satisfied: threadpoolctl>=2.0.0 in /miniconda3/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm->-r requirements.txt (line 1)) (3.1.0)\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Building wheels for collected packages: train-practice\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m   Building wheel for train-practice (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m \u001b[?25h  Created wheel for train-practice: filename=train_practice-1.0.0-py2.py3-none-any.whl size=8147 sha256=fb95c225fd6834d71e59c2a476f289969842fb0616feb5398b3a99fa705c8024\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-fyszxg7m/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Successfully built train-practice\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Installing collected packages: train-practice, lightgbm\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Successfully installed lightgbm-3.3.3 train-practice-1.0.0\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m \u001b[0m[2022-10-13:03:47:32:INFO] Failed to parse hyperparameter boosting_type value gbdt to Json.\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Returning the value itself\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [2022-10-13:03:47:32:INFO] Failed to parse hyperparameter objective value regression to Json.\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Returning the value itself\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [2022-10-13:03:47:32:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [2022-10-13:03:47:32:INFO] Invoking user script\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m \n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Training Env:\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m \n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m {\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\"\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     },\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"current_host\": \"algo-1-3cmae\",\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         \"algo-1-3cmae\"\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     ],\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         \"boosting_type\": \"gbdt\",\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         \"objective\": \"regression\",\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         \"num_leaves\": 31,\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         \"learning_rate\": 0.05,\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         \"feature_fraction\": 0.9,\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         \"bagging_fraction\": 0.8,\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         \"bagging_freq\": 5,\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         \"verbose\": 0\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     },\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         \"train\": {\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         },\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         \"validation\": {\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         }\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     },\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"job_name\": \"sagemaker-xgboost-2022-10-13-03-47-27-253\",\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"master_hostname\": \"algo-1-3cmae\",\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-1-021345128571/sagemaker-xgboost-2022-10-13-03-47-27-253/source/sourcedir.tar.gz\",\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"module_name\": \"train_practice\",\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"num_cpus\": 16,\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         \"current_host\": \"algo-1-3cmae\",\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m             \"algo-1-3cmae\"\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m         ]\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     },\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m     \"user_entry_point\": \"train_practice.py\"\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m }\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m \n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Environment variables:\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m \n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_HOSTS=[\"algo-1-3cmae\"]\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_HPS={\"bagging_fraction\":0.8,\"bagging_freq\":5,\"boosting_type\":\"gbdt\",\"feature_fraction\":0.9,\"learning_rate\":0.05,\"num_leaves\":31,\"objective\":\"regression\",\"verbose\":0}\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_USER_ENTRY_POINT=train_practice.py\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-3cmae\",\"hosts\":[\"algo-1-3cmae\"]}\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_CHANNELS=[\"train\",\"validation\"]\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_CURRENT_HOST=algo-1-3cmae\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_MODULE_NAME=train_practice\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_NUM_CPUS=16\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-1-021345128571/sagemaker-xgboost-2022-10-13-03-47-27-253/source/sourcedir.tar.gz\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-3cmae\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1-3cmae\"],\"hyperparameters\":{\"bagging_fraction\":0.8,\"bagging_freq\":5,\"boosting_type\":\"gbdt\",\"feature_fraction\":0.9,\"learning_rate\":0.05,\"num_leaves\":31,\"objective\":\"regression\",\"verbose\":0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2022-10-13-03-47-27-253\",\"log_level\":20,\"master_hostname\":\"algo-1-3cmae\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-1-021345128571/sagemaker-xgboost-2022-10-13-03-47-27-253/source/sourcedir.tar.gz\",\"module_name\":\"train_practice\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-3cmae\",\"hosts\":[\"algo-1-3cmae\"]},\"user_entry_point\":\"train_practice.py\"}\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_USER_ARGS=[\"--bagging_fraction\",\"0.8\",\"--bagging_freq\",\"5\",\"--boosting_type\",\"gbdt\",\"--feature_fraction\",\"0.9\",\"--learning_rate\",\"0.05\",\"--num_leaves\",\"31\",\"--objective\",\"regression\",\"--verbose\",\"0\"]\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_HP_BOOSTING_TYPE=gbdt\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_HP_OBJECTIVE=regression\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_HP_NUM_LEAVES=31\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_HP_LEARNING_RATE=0.05\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_HP_FEATURE_FRACTION=0.9\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_HP_BAGGING_FRACTION=0.8\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_HP_BAGGING_FREQ=5\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m SM_HP_VERBOSE=0\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m PYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m \n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m \n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m /miniconda3/bin/python3 -m train_practice --bagging_fraction 0.8 --bagging_freq 5 --boosting_type gbdt --feature_fraction 0.9 --learning_rate 0.05 --num_leaves 31 --objective regression --verbose 0\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m \n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m \n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m ===== congraturations! You understand how SageMaker Training Job Works!!! =====\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Starting the training.\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Reading hyperparameters data: /opt/ml/input/config/hyperparameters.json\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m hyperparameters_data: {'boosting_type': 'gbdt', 'objective': 'regression', 'num_leaves': '31', 'learning_rate': '0.05', 'feature_fraction': '0.9', 'bagging_fraction': '0.8', 'bagging_freq': '5', 'verbose': '0', 'sagemaker_submit_directory': '\"s3://sagemaker-ap-northeast-1-021345128571/sagemaker-xgboost-2022-10-13-03-47-27-253/source/sourcedir.tar.gz\"', 'sagemaker_program': '\"train_practice.py\"', 'sagemaker_container_log_level': '20', 'sagemaker_job_name': '\"sagemaker-xgboost-2022-10-13-03-47-27-253\"', 'sagemaker_region': '\"ap-northeast-1\"'}\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Found train files: ['/opt/ml/input/data/train/boston_train.csv']\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Found validation files: ['/opt/ml/input/data/validation/boston_valid.csv']\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m building training and validation datasets\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Starting training...\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m /miniconda3/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m   _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m You can set `force_col_wise=true` to remove the overhead.\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [1]\tvalid_0's l2: 84.4849\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Training until validation scores don't improve for 5 rounds\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [2]\tvalid_0's l2: 78.6995\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [3]\tvalid_0's l2: 73.3733\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [4]\tvalid_0's l2: 68.4066\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [5]\tvalid_0's l2: 63.9675\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [6]\tvalid_0's l2: 60.4495\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [7]\tvalid_0's l2: 57.2702\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [8]\tvalid_0's l2: 54.3096\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [9]\tvalid_0's l2: 51.6438\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [10]\tvalid_0's l2: 49.4106\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [11]\tvalid_0's l2: 46.871\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [12]\tvalid_0's l2: 44.4878\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [13]\tvalid_0's l2: 42.2348\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [14]\tvalid_0's l2: 40.2703\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [15]\tvalid_0's l2: 38.4195\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [16]\tvalid_0's l2: 36.6089\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [17]\tvalid_0's l2: 34.9745\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [18]\tvalid_0's l2: 33.5774\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [19]\tvalid_0's l2: 32.1331\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [20]\tvalid_0's l2: 30.8945\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Did not meet early stopping. Best iteration is:\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m [20]\tvalid_0's l2: 30.8945\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m saving model file to /opt/ml/model/lightgbm-regression-model.txt\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae |\u001b[0m Training complete.\n",
      "\u001b[36m1cbefdrksy-algo-1-3cmae exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "est_lightgbm5.fit({'train':train_s3, 'validation': valid_s3}, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6da068df-5c0e-40ba-91ed-96b3119b69cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 968s2db7vl-algo-1-pu2lq ... \n",
      "Creating 968s2db7vl-algo-1-pu2lq ... done\n",
      "Attaching to 968s2db7vl-algo-1-pu2lq\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m [2022-10-13 03:48:39.027 146ca5e7942d:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m [2022-10-13:03:48:39:INFO] Imported framework sagemaker_xgboost_container.training\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m [2022-10-13:03:48:39:INFO] Failed to parse hyperparameter boosting_type value gbdt to Json.\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m Returning the value itself\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m [2022-10-13:03:48:39:INFO] Failed to parse hyperparameter objective value regression to Json.\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m Returning the value itself\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m [2022-10-13:03:48:39:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m [2022-10-13:03:48:39:INFO] Invoking user training script.\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m [2022-10-13:03:48:39:INFO] Module train_practice does not provide a setup.py. \n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m Generating setup.py\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m [2022-10-13:03:48:39:INFO] Generating setup.cfg\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m [2022-10-13:03:48:39:INFO] Generating MANIFEST.in\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m [2022-10-13:03:48:39:INFO] Installing module with the following command:\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m /miniconda3/bin/python3 -m pip install . \n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m \u001b[?25hBuilding wheels for collected packages: train-practice\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m   Building wheel for train-practice (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m \u001b[?25h  Created wheel for train-practice: filename=train_practice-1.0.0-py2.py3-none-any.whl size=7966 sha256=0775dd0fda6500db4385ce61a78e11e665a95a1903eb7bdefe8ccc923c146f15\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-r3dd4t7l/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m Successfully built train-practice\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m Installing collected packages: train-practice\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m Successfully installed train-practice-1.0.0\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m \u001b[0m[2022-10-13:03:48:40:INFO] Failed to parse hyperparameter boosting_type value gbdt to Json.\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m Returning the value itself\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m [2022-10-13:03:48:40:INFO] Failed to parse hyperparameter objective value regression to Json.\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m Returning the value itself\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m [2022-10-13:03:48:40:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m [2022-10-13:03:48:40:INFO] Invoking user script\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m \n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m Training Env:\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m \n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m {\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\"\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     },\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"current_host\": \"algo-1-pu2lq\",\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         \"algo-1-pu2lq\"\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     ],\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         \"boosting_type\": \"gbdt\",\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         \"objective\": \"regression\",\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         \"num_leaves\": 31,\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         \"learning_rate\": 0.05,\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         \"feature_fraction\": 0.9,\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         \"bagging_fraction\": 0.8,\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         \"bagging_freq\": 5,\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         \"verbose\": 0\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     },\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         \"train\": {\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         },\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         \"validation\": {\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         }\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     },\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"job_name\": \"sagemaker-xgboost-2022-10-13-03-48-36-314\",\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"master_hostname\": \"algo-1-pu2lq\",\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-1-021345128571/sagemaker-xgboost-2022-10-13-03-48-36-314/source/sourcedir.tar.gz\",\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"module_name\": \"train_practice\",\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"num_cpus\": 16,\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         \"current_host\": \"algo-1-pu2lq\",\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m             \"algo-1-pu2lq\"\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m         ]\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     },\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     \"user_entry_point\": \"train_practice.py\"\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m }\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m \n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m Environment variables:\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m \n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_HOSTS=[\"algo-1-pu2lq\"]\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_HPS={\"bagging_fraction\":0.8,\"bagging_freq\":5,\"boosting_type\":\"gbdt\",\"feature_fraction\":0.9,\"learning_rate\":0.05,\"num_leaves\":31,\"objective\":\"regression\",\"verbose\":0}\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_USER_ENTRY_POINT=train_practice.py\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-pu2lq\",\"hosts\":[\"algo-1-pu2lq\"]}\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_CHANNELS=[\"train\",\"validation\"]\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_CURRENT_HOST=algo-1-pu2lq\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_MODULE_NAME=train_practice\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_NUM_CPUS=16\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-1-021345128571/sagemaker-xgboost-2022-10-13-03-48-36-314/source/sourcedir.tar.gz\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-pu2lq\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1-pu2lq\"],\"hyperparameters\":{\"bagging_fraction\":0.8,\"bagging_freq\":5,\"boosting_type\":\"gbdt\",\"feature_fraction\":0.9,\"learning_rate\":0.05,\"num_leaves\":31,\"objective\":\"regression\",\"verbose\":0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2022-10-13-03-48-36-314\",\"log_level\":20,\"master_hostname\":\"algo-1-pu2lq\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-1-021345128571/sagemaker-xgboost-2022-10-13-03-48-36-314/source/sourcedir.tar.gz\",\"module_name\":\"train_practice\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-pu2lq\",\"hosts\":[\"algo-1-pu2lq\"]},\"user_entry_point\":\"train_practice.py\"}\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_USER_ARGS=[\"--bagging_fraction\",\"0.8\",\"--bagging_freq\",\"5\",\"--boosting_type\",\"gbdt\",\"--feature_fraction\",\"0.9\",\"--learning_rate\",\"0.05\",\"--num_leaves\",\"31\",\"--objective\",\"regression\",\"--verbose\",\"0\"]\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_HP_BOOSTING_TYPE=gbdt\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_HP_OBJECTIVE=regression\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_HP_NUM_LEAVES=31\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_HP_LEARNING_RATE=0.05\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_HP_FEATURE_FRACTION=0.9\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_HP_BAGGING_FRACTION=0.8\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_HP_BAGGING_FREQ=5\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m SM_HP_VERBOSE=0\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m PYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m \n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m \n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m /miniconda3/bin/python3 -m train_practice --bagging_fraction 0.8 --bagging_freq 5 --boosting_type gbdt --feature_fraction 0.9 --learning_rate 0.05 --num_leaves 31 --objective regression --verbose 0\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m \n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m \n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m   File \"/miniconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     return _run_code(code, main_globals, None,\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m   File \"/miniconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     exec(code, run_globals)\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m   File \"/opt/ml/code/train_practice.py\", line 13, in <module>\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m     import lightgbm as lgb\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m ModuleNotFoundError: No module named 'lightgbm'\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m [2022-10-13:03:48:40:ERROR] ExecuteUserScriptError:\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq |\u001b[0m Command \"/miniconda3/bin/python3 -m train_practice --bagging_fraction 0.8 --bagging_freq 5 --boosting_type gbdt --feature_fraction 0.9 --learning_rate 0.05 --num_leaves 31 --objective regression --verbose 0\"\n",
      "\u001b[36m968s2db7vl-algo-1-pu2lq exited with code 1\n",
      "\u001b[0m1\n",
      "Aborting on container exit...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run: ['docker-compose', '-f', '/tmp/tmpyjfbk2z0/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, environment, job_name)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0m_stream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_stream_output\u001b[0;34m(process)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexit_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Process exited with code: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mexit_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Process exited with code: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23719/2742019680.py\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mest_lightgbm6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_s3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalid_s3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0mtrain_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config, environment, retry_strategy)\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intercept_create_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     def _get_train_request(  # noqa: C901\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_intercept_create_request\u001b[0;34m(self, request, create, func_name)\u001b[0m\n\u001b[1;32m   4303\u001b[0m             \u001b[0mfunc_name\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mname\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mneeded\u001b[0m \u001b[0mintercepting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4304\u001b[0m         \"\"\"\n\u001b[0;32m-> 4305\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m    609\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intercept_create_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, Environment, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HyperParameters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"HyperParameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training job\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         training_job.start(\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mInputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingJobName\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, environment, job_name)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         self.model_artifacts = self.container.train(\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0minput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, environment, job_name)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;31m# which contains the exit code and append the command line to it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Failed to run: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcompose_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0martifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompose_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run: ['docker-compose', '-f', '/tmp/tmpyjfbk2z0/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1"
     ]
    }
   ],
   "source": [
    "est_lightgbm6 = Estimator(\n",
    "    #image,\n",
    "    container, # xgboostのbuilt-inコンテナ\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    #instance_type=\"ml.m4.2xlarge\",\n",
    "    instance_type=\"local\",\n",
    "    hyperparameters={'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0},\n",
    "    source_dir='./src_builtin_container_no_lgbm',\n",
    "    entry_point='train_practice.py'\n",
    "    #entry_point='./practice_src/train_practice.sh'\n",
    "    )\n",
    "\n",
    "est_lightgbm6.fit({'train':train_s3, 'validation': valid_s3}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb42ba66-5044-482f-8d39-18e896d93569",
   "metadata": {},
   "source": [
    "lightgbmモジュールが存在しないため、エラーとなります\n",
    "\n",
    "File \"/opt/ml/code/train_practice.py\", line 13, in <module>  \n",
    "import lightgbm as lgb  \n",
    "ModuleNotFoundError: No module named 'lightgbm'  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c763f51-d7d5-4382-bd60-5530eb7c2c46",
   "metadata": {},
   "source": [
    "# 後片付け\n",
    "\n",
    "* ECR\n",
    "* S3\n",
    "* SageMakerノートブックインスタンス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e500d4-7fc7-4e63-b101-718f052a3227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6ec827-00c4-477c-9417-91860841699e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b595625-a78e-4b84-8211-e08c2af13577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25e1bff7",
   "metadata": {},
   "source": [
    "XGBoostビルトインコンテナでは、LGBMの推論を実行できないので、独自にserveを指定する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dd12bc",
   "metadata": {},
   "source": [
    "SageMaker Python SDK  \n",
    "https://github.com/aws/sagemaker-python-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47f7f4f",
   "metadata": {},
   "source": [
    "## 実験\n",
    "Sagemaker.model.Model()でコード指定できる？\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/inference/model.html\n",
    "\n",
    "\n",
    "そのモデルを指定してエンドポイントを作る？\n",
    "\n",
    "それでビルトインコンテナを使いつつ、LGBM推論ができる？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe9075c",
   "metadata": {},
   "source": [
    "# XGBビルトインコンテナでLGBM推論を実施するには\n",
    "\n",
    "ライブラリのインポート\n",
    "/opt/ml/model/code/requirement.txt\n",
    "を配置する必要があります。\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit/blob/master/src/sagemaker_inference/model_server.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4d235c",
   "metadata": {},
   "source": [
    "既存モデルをSageMakerエンドポイントにデプロイする場合\n",
    "\n",
    "https://dev.classmethod.jp/articles/amazon-sagemaker-deploy_existing_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc2dc75",
   "metadata": {},
   "source": [
    "作成したモデルインスタンスをデプロイします\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3cb7f6",
   "metadata": {},
   "source": [
    "## 参考\n",
    "エンドポイントのインスタンス\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html#sagemaker.predictor.Predictor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
