{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08f98df",
   "metadata": {},
   "source": [
    "# LightGBMの推論用カスタムコンテナを構築し、SageMakerによる推論の仕組みを深く理解する\n",
    "\n",
    "このノートブックでは、LightGBMがインストールされたカスタムコンテナ構築し、SageMaker Trainingジョブで学習後、推論を行います。\n",
    "カスタムコンテナの挙動を観察し、SageMakerの推論動作について理解を深めます。\n",
    "\n",
    "ノートブックは20分程度で実行できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60e0add",
   "metadata": {},
   "source": [
    "# 0.実行環境確認\n",
    "本ノートブックは、SageMakerノートブックインスタンス上で動作確認しています。\n",
    "* インスタンスタイプ：ml.t3.medium\n",
    "* カーネル：conda_python3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dae758",
   "metadata": {},
   "source": [
    "## 0-1.pythonバージョン確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa29e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pythonのバージョン情報\n",
    "import sys\n",
    "sys.version # 3.8.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9334e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pythonのバージョン確認 (システムコマンド使用）\n",
    "!python -V # 3.8.12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532a17f",
   "metadata": {},
   "source": [
    "## 0-2.SageMakerSDKバージョン確認\n",
    "\n",
    "Amazon SageMaker Python SDKは、Amazon SageMaker上で機械学習されたモデルをトレーニングおよびデプロイするためのオープンソースライブラリです。\n",
    "\n",
    "このSDKを使用すると、一般的な深層学習フレームワーク、Amazonが提供するアルゴリズム、またはSageMaker互換のDockerイメージに組み込まれた独自のアルゴリズムを使ってモデルをトレーニングおよびデプロイすることができます。\n",
    "\n",
    "* ドキュメント : https://sagemaker.readthedocs.io/en/stable/\n",
    "* GitHub : https://github.com/aws/sagemaker-python-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec73091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMakerSDK のバージョン確認\n",
    "import sagemaker\n",
    "print('Current SageMaker Python SDK Version ={0}'.format(sagemaker.__version__)) # 2.110.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3ca0a4",
   "metadata": {},
   "source": [
    "# 1.データ準備\n",
    "\n",
    "学習、推論で利用するデータを準備します。\n",
    "\n",
    "scikit-learn付属の、ボストン住宅価格データセットを利用します。(注：バージョン1.2から除外されます）  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html\n",
    "\n",
    "以下のスクリプトを参考にしています。\n",
    "\n",
    "https://github.com/aws-samples/amazon-sagemaker-local-mode/blob/main/lightgbm_bring_your_own_container_local_training_and_serving/lightgbm_bring_your_own_container_local_training_and_serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__ # 1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8176e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.__version__ # 1.3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470272a",
   "metadata": {},
   "source": [
    "## 1-1. データロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62ae8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston() # 1.2でデータセットがなくすという警告が出ますが動作に影響ありません"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610d8634",
   "metadata": {},
   "source": [
    "## 1-2. 特徴量生成（Feature Engineering）\n",
    "本ノートブックでは実施しません。そのままデータを利用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38345705",
   "metadata": {},
   "source": [
    "## 1-3. データ分割\n",
    "学習用（train）、評価用（validation）、テスト用（test）にデータを分割します。  \n",
    "train:val:test = 3(60%):1(20%):1(20%)に分割します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfbc922",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=45)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=45)\n",
    "\n",
    "trainX = pd.DataFrame(X_train, columns=data.feature_names)\n",
    "trainX['target'] = y_train\n",
    "\n",
    "valX = pd.DataFrame(X_val, columns=data.feature_names)\n",
    "valX['target'] = y_val\n",
    "\n",
    "testX = pd.DataFrame(X_test, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70ba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "print(trainX.shape)\n",
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f19880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "print(valX.shape)\n",
    "valX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291effee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "print(testX.shape)\n",
    "testX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c9ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "y_test[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7fadc6",
   "metadata": {},
   "source": [
    "## 1-4.データ保存\n",
    "ローカル、S3それぞれにデータを保存します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55c5370",
   "metadata": {},
   "source": [
    "### 1-4-1.ローカルへ保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c409f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリ作成\n",
    "from pathlib import Path\n",
    "\n",
    "Path('./data/train').mkdir(parents=True, exist_ok=True)\n",
    "Path('./data/valid').mkdir(parents=True, exist_ok=True)\n",
    "Path('./data/test').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb27642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ローカルへ保存\n",
    "local_train = './data/train/boston_train.csv'\n",
    "local_valid = './data/valid/boston_valid.csv'\n",
    "local_test = './data/test/boston_test.csv'\n",
    "\n",
    "trainX.to_csv(local_train, header=None, index=False)\n",
    "valX.to_csv(local_valid, header=None, index=False)\n",
    "testX.to_csv(local_test, header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff142a99",
   "metadata": {},
   "source": [
    "### 1-4-2.S3へ保存\n",
    "\n",
    "一意のバケット作成のために、sgemaker.Session().default_bucket()を利用します。\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/utility/session.html#sagemaker.session.Session\n",
    "\n",
    "Session().default_bucket()を実行することで、\n",
    "\n",
    "sagemaker-\\<リージョン名>-\\<アカウントID> という名称のバケットが作成されます。\n",
    "\n",
    "https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/session.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afde018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "region_name = sagemaker.Session().boto_region_name\n",
    "account_id =  sagemaker.Session().account_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9299f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "print(bucket_name)\n",
    "print(region_name)\n",
    "print(account_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed7cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# バケット作成(SageMakerSDKのインポート時作成されています。他のバケット作成時に利用ください)\n",
    "#import boto3\n",
    "\n",
    "#s3_resource = boto3.resource('s3')\n",
    "#s3_resource.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': region_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4370382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3へ保存\n",
    "train_s3 = sagemaker.s3.S3Uploader.upload('./data/train/boston_train.csv', f's3://{bucket_name}/demo_lightgbm/train')\n",
    "valid_s3 = sagemaker.s3.S3Uploader.upload('./data/valid/boston_valid.csv', f's3://{bucket_name}/demo_lightgbm/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2756a73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認:格納したS3のURIが返されています\n",
    "print(train_s3)\n",
    "print(valid_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b4334d",
   "metadata": {},
   "source": [
    "# 2.LightGBMカスタムコンテナの構築\n",
    "推論用のカスタムコンテナの作成には大きく分けて4つのパターンがあります。詳細は以下のブログを参考ください。\n",
    "\n",
    "https://aws.amazon.com/jp/blogs/news/sagemaker-custom-containers-pattern-inference/\n",
    "\n",
    "\n",
    "\\<参考>学習用カスタムコンテナの作成\n",
    "\n",
    "https://aws.amazon.com/jp/blogs/news/sagemaker-custom-containers-pattern-training/\n",
    "\n",
    "今回は、学習編で作成した、学習（パターン3）+推論（パターン4）用のカスタムコンテナを利用します。\n",
    "\n",
    "ベースイメージ(ubuntu:16.04) の他は、カスタマイズします。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41a4289",
   "metadata": {},
   "source": [
    "## 2-1. Dockerfileの確認\n",
    "\n",
    "資材はこちらのノートブックを参考に準備しています。\n",
    "\n",
    "https://github.com/aws-samples/amazon-sagemaker-local-mode/tree/main/lightgbm_bring_your_own_container_local_training_and_serving/container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f654ed",
   "metadata": {},
   "source": [
    "まずは、Dockerfileを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09884923",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./container/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2191d15",
   "metadata": {},
   "source": [
    "### 解説：推論エンドポイント構築時のSageMakerの動作\n",
    "SageMakerの推論エンドポイントのデプロイは、SageMaker SDKでは、deploy()メソッドで実行します。\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html\n",
    "\n",
    "その際に、SageMakerは以下のコマンドを実行します。\n",
    "\n",
    "docker run \\<Docker image> server\n",
    "\n",
    "今回のカスタムコンテナでは、 /opt/program に配置した serve スクリプトが実行されます。\n",
    "\n",
    "serveスクリプトを確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21faae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize -l py ./container/lightgbm_regression/serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ccc885",
   "metadata": {},
   "source": [
    "初めに、末尾の start_server() が実行され、start_server()では以下が行われます。\n",
    "\n",
    "* nginxの起動（Webサーバ/リバースプロキシの役割）\n",
    "    * nginx.confを読み込みます。\n",
    "* gunicornの起動（Applicationサーバの役割）\n",
    "    * gunicornの起動コマンド引数に'wsgi:app'とあるように、wsgiモジュールwsgi.pyの、appアプリケーションを読み込みます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a7e70d",
   "metadata": {},
   "source": [
    "nginx.confを確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df86676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./container/lightgbm_regression/nginx.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d891aaac",
   "metadata": {},
   "source": [
    "SageMakerから受け取った /ping と /invocations リクエストを上記で設定したgunicornに渡します。\n",
    "以下に記載があるように、ポート8080を利用する必要があります。\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html\n",
    "\n",
    "How Containers Serve Requests  \n",
    "Containers need to implement a web server that responds to /invocations and /ping on port 8080."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5033fd03",
   "metadata": {},
   "source": [
    "次に、gunicornへのアプリケーションのキック用に使われるファイル wsgi.pyを確認します。\n",
    "\n",
    "predictor.py の、appを読み込んでいることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691898ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./container/lightgbm_regression/wsgi.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d3ea8c",
   "metadata": {},
   "source": [
    "predictor.py を確認します。\n",
    "\n",
    "flaskフレームワークを用いて、/ping、 /invocations に対する処理を実装していることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45d4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./container/lightgbm_regression/predictor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cdbcc5",
   "metadata": {},
   "source": [
    "## 2-2. dockerイメージの build & push\n",
    "上記で確認したカスタムコンテナをビルドします。\n",
    "\n",
    "build & pushには7分ほどかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a022706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-lightgbm-regression\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x lightgbm_regression/train\n",
    "chmod +x lightgbm_regression/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to ap-northeast-1 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-ap-northeast-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1925510e",
   "metadata": {},
   "source": [
    "## 2-3. 学習前設定\n",
    "AWSコンソールでECRに移動し、作成したコンテナがあることを確認します。\n",
    "\n",
    "image URIを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a42d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "print(bucket_name)\n",
    "print(region_name)\n",
    "print(account_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f137ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imageURLの設定\n",
    "image_uri = f'{account_id}.dkr.ecr.{region_name}.amazonaws.com/sagemaker-lightgbm-regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eefe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c73405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習で指定するLightGBMのハイパーパラメータを設定します。\n",
    "hyperparameters={'boosting_type': 'gbdt',\n",
    "                 'objective': 'regression',\n",
    "                 'num_leaves': 31,\n",
    "                 'learning_rate': 0.05,\n",
    "                 'feature_fraction': 0.9,\n",
    "                 'bagging_fraction': 0.8,\n",
    "                 'bagging_freq': 5,\n",
    "                 'verbose': 0\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137cd35f",
   "metadata": {},
   "source": [
    "## 2-4.ローカル学習の実行\n",
    "まずはローカルモードでモデルの学習を行います。\n",
    "ローカルモードを利用することで、コンテナイメージのダウンロードや展開の手間を省くことができる、デバッグを行う場合に便利です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6992ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ローカルファイルのパスを設定（S3パス指定も可）\n",
    "train_location = 'file://'+local_train\n",
    "valid_location = 'file://'+local_valid\n",
    "\n",
    "print(train_location)\n",
    "print(valid_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1612711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b11a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb41d36",
   "metadata": {},
   "source": [
    "SageMakerのEstimatorを作成します。\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605ae243",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_lightgbm = Estimator(image_uri,\n",
    "                           role,\n",
    "                           instance_count=1,\n",
    "                           instance_type=\"local\",\n",
    "                           hyperparameters=hyperparameters\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea035c8",
   "metadata": {},
   "source": [
    "fitメソッドで学習ジョブを発行します\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35727446",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_lightgbm.fit({'train':train_location, 'validation': valid_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb77a2c",
   "metadata": {},
   "source": [
    "ローカルモードの学習結果についてもS3に保管されます。\n",
    "\n",
    "s3://sagemaker-< リージョン名 >-< アカウントID >/sagemaker-lightgbm-regression-yyyy-MM-dd-HH-mm-ss-fff/\n",
    "\n",
    "* model.tar.gz\n",
    "* output.tar.gz\n",
    "\n",
    "SageMaker Trainingジョブの詳細については、BlackBeltの解説もご参照ください。\n",
    "https://www.youtube.com/watch?v=byEawTm4O4E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4758ac53",
   "metadata": {},
   "source": [
    "## 2-5.ローカルデプロイ\n",
    "\n",
    "インプットデータの形式を指定するSerializerは、CSVSerializerとします。\n",
    "SerializerとDeserializerについて学ぶ場合は、study_serializer_deserializer.ipynb を参考にしてください。\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/v2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事前準備：全コンテナ停止\n",
    "!docker stop $(docker ps -q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20efcd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936d12bf",
   "metadata": {},
   "source": [
    "起動中のコンテナイメージがないことを確認し、ローカルデプロイを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a9adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_predictor = local_lightgbm.deploy(1, 'local', serializer=sagemaker.serializers.CSVSerializer()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e112b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e608da",
   "metadata": {},
   "source": [
    "ローカルにコンテナイメージが展開されていることが確認できました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e60474",
   "metadata": {},
   "source": [
    "## 2-6.ローカルエンドポイントで推論実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = local_predictor.predict(payload).decode('utf-8')\n",
    "print('=' * 20)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb50cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10a74f8",
   "metadata": {},
   "source": [
    "## 2-7.学習ジョブを発行\n",
    "次は、ローカルモードではなく、\n",
    "同じカスタムコンテナで、学習ジョブを実行します。\n",
    "\n",
    "Estimatorの引数instance_typeにインスタンスタイプを指定することで、学習ジョブが発行されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abf659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "print(train_s3)\n",
    "print(valid_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_lightgbm = Estimator(image_uri,\n",
    "                         role,\n",
    "                         instance_count=1,\n",
    "                         instance_type=\"ml.m4.2xlarge\", # インスタンスタイプを指定\n",
    "                         hyperparameters=hyperparameters\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa29dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_lightgbm.fit({'train':train_s3, 'validation': valid_s3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce918e4e",
   "metadata": {},
   "source": [
    "学習には3分ほど時間がかかります。\n",
    "\n",
    "Billable seconds: \\<秒数>\n",
    "が課金対象の時間となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a25a3f",
   "metadata": {},
   "source": [
    "## 2-8.エンドポイントにデプロイ\n",
    "\n",
    "学習ジョブで構築されたモデルをデプロイします。\n",
    "デプロイ時にSageMaker は \n",
    "\n",
    "docker run \\<image> serve\n",
    "\n",
    "を実行します。\n",
    "\n",
    "    \n",
    "デプロイには3分ほどかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c9f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sagemaker.predictor import csv_serializer # SageMaker SDK v1以前の使い方\n",
    "# https://sagemaker.readthedocs.io/en/stable/v2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9bf22a",
   "metadata": {},
   "source": [
    "deployメソッドで、推論エンドポイントをデプロイします。\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase.deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878bdcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor = est_lightgbm.deploy(1, 'ml.m4.xlarge', serializer=csv_serializer, wait=True) # SageMaker SDK v1以前の使い方\n",
    "predictor = est_lightgbm.deploy(1, 'ml.m4.xlarge', serializer=sagemaker.serializers.CSVSerializer(), wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb6757",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = predictor.predict(payload).decode('utf-8')\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338cdff2",
   "metadata": {},
   "source": [
    "# 3.推論コードを外部ファイルとして指定できるようにする\n",
    "推論コードを外部から指定するために、SageMaker Inference Toolkitを導入します。以下のブログのパターン2に該当します。\n",
    "\n",
    "https://aws.amazon.com/jp/blogs/news/sagemaker-custom-containers-pattern-inference/\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit\n",
    "\n",
    "SageMaker Inference Toolkitは、MMS(Multi Model Server)の利用を前提としているため、MMSも導入します。\n",
    "\n",
    "前セクションではnginx, gunicorn, flaskで推論仕組みを構築しましたが、モデルサービングの仕組みはMMSを利用します。\n",
    "\n",
    "https://github.com/awslabs/multi-model-server/tree/master/docker\n",
    "\n",
    "* SageMaker-Inference-Toolkitと、Multi Model Serverを導入する\n",
    "* ビルトインコンテナ + requirements.txt, inference.pyを利用する\n",
    "\n",
    "MMSの利用については、以下のサンプルコードも参照ください。\n",
    "\n",
    "https://github.com/aws/amazon-sagemaker-examples/tree/main/advanced_functionality/multi_model_bring_your_own\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cabee3",
   "metadata": {},
   "source": [
    "## 3-1.Dockerfileの確認"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53722545",
   "metadata": {},
   "source": [
    "まずは、利用するDockerfileを確認します。\n",
    "MMSに必要なJavaをインストールし、MMSとinference-toolkitをインストールしています。\n",
    "\n",
    "LightGBMはrequirements.txtでインストールを試みるため、Dockerfileには記載していません。（前セクションのようにDockerfileに記載することも可能）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044879d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./container_sminftoolkit/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9275ac",
   "metadata": {},
   "source": [
    "## 3-2.エントリポイントを確認\n",
    "\n",
    "SageMakerSDKにてdeploy()を実行した際の\n",
    "\n",
    "docker run \\<image> server\n",
    "\n",
    "で実行される、ENTRYPOINTを確認します。\n",
    "\n",
    "dockerd-entrypoint.py が実行されることがわかります。このファイルを確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaaa809",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./container_sminftoolkit/dockerd-entrypoint.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ab4340",
   "metadata": {},
   "source": [
    "これは、以下に該当する model_server.py の、start_model_server()が実行されます。\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit/blob/master/src/sagemaker_inference/model_server.py\n",
    "\n",
    "その後の処理の流れはノートブックの末尾に記載します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6abef78",
   "metadata": {},
   "source": [
    "では、このDockerfileをbuildします。\n",
    "\n",
    "build&pushには3分ほどかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42294963",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "#algorithm_name=demo-sagemaker-multimodel\n",
    "algorithm_name=demo-sagemaker-inftoolkit\n",
    "\n",
    "#cd container\n",
    "cd container_sminftoolkit\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -q -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e3f6f3",
   "metadata": {},
   "source": [
    "## 3-3.ローカルにエンドポイントをデプロイ\n",
    "モデルは前のセクションで作成したLightGBMのモデルを利用します。\n",
    "\n",
    "* 推論ロジックを記載したファイル inference.py を指定する\n",
    "* LightGBMライブラリはrequirements.txtでインストールする"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df37660a",
   "metadata": {},
   "source": [
    "推論ロジックを記載した inference.py を確認します。\n",
    "\n",
    "* model_fn : deploy()実行時にモデルロードのため利用されます\n",
    "* input_fn : 推論時に実行され、前処理を行います。\n",
    "* predict_fn : 推論時に実行され、推論を行います。\n",
    "* output_fn : 推論時に実行され、後処理を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c468fbb",
   "metadata": {},
   "source": [
    "model_fnにおいて、LightGBMのモデルが.txt形式なので、lgb.Booster(model_file='.txt')でモデルをロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf39ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./src_builtin_container_serve/inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01876aa9",
   "metadata": {},
   "source": [
    "次に requirements.txt を確認します。インストールする lightgbm のみ記載しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8099c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./src_builtin_container_serve/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4939e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_uri = f'{account_id}.dkr.ecr.{region_name}.amazonaws.com/demo-sagemaker-inftoolkit:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7021544",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4410791",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.8の学習ジョブで構築したモデルを利用する\n",
    "#est_lightgbm.model_data\n",
    "\n",
    "### ローカル学習で構築したモデルを利用する場合\n",
    "model_data=local_lightgbm.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f4dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d024f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#全コンテナ停止\n",
    "!docker stop $(docker ps -q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570aedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b44b11",
   "metadata": {},
   "source": [
    "predictor_clsには、SageMaker SDK v2のPredictorクラスを利用\n",
    "\n",
    "SageMaker SDK v1.72.0\n",
    "https://sagemaker.readthedocs.io/en/v1.72.0/api/inference/predictors.html\n",
    "\n",
    "SageMaker SDK v2.115\n",
    "https://sagemaker.readthedocs.io/en/v2.115.0/api/inference/predictors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaab8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "lgb_model = sagemaker.model.Model(#est_xgb.image_uri, # XGBoostビルトインコンテナのURI\n",
    "                                  container_uri,\n",
    "                                  model_data=model_data, # ローカル学習で生成したモデルファイル\n",
    "                                  role=role,\n",
    "                                  predictor_cls=Predictor, # 推論するための識別子を指定\n",
    "                                  source_dir='./src_builtin_container_serve', # requirements.txt必要な場合\n",
    "                                  entry_point='inference.py' # source_dirを指定している場合、.pyファイルを指定する。\n",
    "                                  #entry_point='./src_builtin_container_serve/inference.py'\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5cf759",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_lgb_model = lgb_model.deploy(initial_instance_count=1,\n",
    "                                       instance_type='local', \n",
    "                                       serializer=sagemaker.serializers.CSVSerializer(), ### string形式でSageMakerに渡す（認識してもらう）\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0f6cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考：SageMaker SDK v1以前の場合\n",
    "#from sagemaker.predictor import RealTimePredictor\n",
    "#\n",
    "#lgb_model = sagemaker.model.Model(#est_xgb.image_uri, # XGBoostビルトインコンテナのURI\n",
    "#                                  container_uri,\n",
    "#                                  model_data=model_data, # ローカル学習で生成したモデルファイル\n",
    "#                                  role=role,\n",
    "#                                  predictor_cls=RealTimePredictor, # 推論するための識別子を指定\n",
    "#                                  source_dir='./src_builtin_container_serve', # requirements.txt必要な場合\n",
    "#                                  entry_point='inference.py' # source_dirを指定している場合、.pyファイルを指定する。\n",
    "#                                  #entry_point='./src_builtin_container_serve/inference.py'\n",
    "#                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c16bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor_lgb_model = lgb_model.deploy(initial_instance_count=1,\n",
    "#                                       instance_type='local', \n",
    "#                                       serializer=csv_serializer, ### string形式でSageMakerに渡す（認識してもらう）\n",
    "#                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f407a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd609d9",
   "metadata": {},
   "source": [
    "## 3-4.推論実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c937f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = predictor_lgb_model.predict(payload).decode('utf-8')\n",
    "print('=' * 20)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40af266",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(predicted))\n",
    "print('='*50)\n",
    "print(predicted)\n",
    "print('='*50)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d47f96",
   "metadata": {},
   "source": [
    "# (optional) 4.XGBoostコンテナで、LightGBMの推論を実施する\n",
    "\n",
    "XGBoostのビルトインコンテナでLightGBMの推論を行います。\n",
    "LightGBMはrequirements.txtでインストールします。\n",
    "\n",
    "ブログのパターン1に該当します。\n",
    "\n",
    "https://aws.amazon.com/jp/blogs/news/sagemaker-custom-containers-pattern-inference/\n",
    "\n",
    "\n",
    "\\<参考>LightGBMはSageMakerのビルトインアルゴリズムとして用意されています。\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/lightgbm.html    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb6145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_container_uri = sagemaker.image_uris.retrieve(\"xgboost\", region_name, \"1.5-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3691cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_container_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e5d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = sagemaker.model.Model(xgb_container_uri, # XGBoostビルトインコンテナのURI\n",
    "                                  model_data=model_data, # ローカル学習で生成したモデルファイル\n",
    "                                  role=role,\n",
    "                                  predictor_cls=Predictor, # 推論するための識別子を指定\n",
    "                                  source_dir='./src_builtin_container_serve', # requirements.txt必要な場合\n",
    "                                  entry_point='inference.py' # source_dirを指定している場合、.pyファイルを指定する。\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c186f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94b21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker stop $(docker ps -q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7b5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c7233",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_lgb_model = lgb_model.deploy(initial_instance_count=1,\n",
    "                                       instance_type='local', \n",
    "                                       serializer=sagemaker.serializers.CSVSerializer(), ### string形式でSageMakerに渡す（認識してもらう）\n",
    "                                       #deserializer=None, \n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35acd269",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = predictor_lgb_model.predict(payload).decode('utf-8')\n",
    "print('=' * 20)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d349584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e10c539",
   "metadata": {},
   "source": [
    "# END of Containts ======================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e12ca90",
   "metadata": {},
   "source": [
    "### 4-2-1.デプロイ\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase.deploy\n",
    "\n",
    "\n",
    "デプロイの際に、ソースコードを指定するにはどうしたらいいのか？\n",
    "\n",
    "https://www.youtube.com/watch?v=sngNd79GpmE&t=596s\n",
    "\n",
    "\n",
    "ポイント：あらためて、Estimatorを定義する必要がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a30006",
   "metadata": {},
   "source": [
    "### serve用のファイルは、.py かつ、作法に従う必要がある。\n",
    "\n",
    "MMSは.pyを扱うように設計されているため。\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fbcfcb",
   "metadata": {},
   "source": [
    "## エラー\n",
    "\n",
    "RuntimeError: Model /opt/ml/model/model.tar.gz cannot be loaded:\n",
    "\n",
    "\n",
    "6o0805unb3-algo-1-k8ugv | [2022-10-16 02:25:50 +0000] [19] [ERROR] Exception in worker process  \n",
    "6o0805unb3-algo-1-k8ugv | Traceback (most recent call last):  \n",
    "6o0805unb3-algo-1-k8ugv |   File \"/miniconda3/lib/python3.8/site-packages/sagemaker_xgboost_container/algorithm_mode/serve_utils.py\", line 175, in get_loaded_booster  \n",
    "6o0805unb3-algo-1-k8ugv |     booster = pkl.load(open(full_model_path, \"rb\"))  \n",
    "6o0805unb3-algo-1-k8ugv | _pickle.UnpicklingError: invalid load key, '\\x1f'.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92893f29",
   "metadata": {},
   "source": [
    "## 原因\n",
    "lightgbm-regression-model.txtなので、pklでは読み込めない。\n",
    "\n",
    "モデルロードする関数を上書きするには？？（そもそもこれがやりたい）\n",
    "\n",
    "https://github.com/aws/sagemaker-xgboost-container/blob/master/docker/1.5-1/final/Dockerfile.cpu\n",
    "\n",
    "# Set SageMaker entrypoints\n",
    "ENV SAGEMAKER_TRAINING_MODULE sagemaker_xgboost_container.training:main  \n",
    "ENV SAGEMAKER_SERVING_MODULE sagemaker_xgboost_container.serving:main  \n",
    "\n",
    "\n",
    "まず、serving.main()が実行される"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a54788",
   "metadata": {},
   "source": [
    "https://github.com/aws/sagemaker-xgboost-container/blob/master/src/sagemaker_xgboost_container/serving.py\n",
    "\n",
    "L143\n",
    "\n",
    "serving_env = env.ServingEnv()\n",
    "\n",
    "で、環境変数にパラメータが読み込まれる\n",
    "\n",
    "\n",
    "L147\n",
    "\n",
    "user_module = modules.import_module(serving_env.module_dir, serving_env.module_name)\n",
    "\n",
    "ここで、ユーザーのモジュールが読み込まれる。\n",
    "\n",
    "L18をみると、sagemaker_containers.beta.framework.modulesがモジュール。\n",
    "\n",
    "from sagemaker_containers.beta.framework import (\n",
    "    encoders,\n",
    "    env,\n",
    "    modules,\n",
    "    server,\n",
    "    transformer,\n",
    "    worker,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa51ab2",
   "metadata": {},
   "source": [
    "https://github.com/aws/sagemaker-containers/blob/master/src/sagemaker_containers/beta/framework/__init__.py\n",
    "\n",
    "sagemaker_containers.beta.frameworkはアーカイブされている。\n",
    "\n",
    "現在はこちら。initをみると\n",
    "\n",
    "https://github.com/aws/sagemaker-containers/blob/master/src/sagemaker_containers/_modules.py\n",
    "\n",
    "\n",
    "\n",
    "L258で、imortしている。\n",
    "\n",
    "module = importlib.import_module(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbed3663",
   "metadata": {},
   "source": [
    "def import_module(uri, name=DEFAULT_MODULE_NAME, cache=None):  # type: (str, str, bool) -> module\n",
    "\n",
    "とあるように、DEFAULT_MODULE_NAMEが読み込まれる\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00b8907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f064293f",
   "metadata": {},
   "source": [
    "\n",
    "https://github.com/aws/sagemaker-xgboost-container/blob/master/src/sagemaker_xgboost_container/serving.py\n",
    "\n",
    "L148,149: L147で読み込んだユーザーモジュールに上書きする\n",
    "\n",
    "user_module_transformer = _user_module_transformer(user_module)  \n",
    "user_module_transformer.initialize()  \n",
    "\n",
    "\n",
    "L116にあるように、model_fnなどのユーザー関数に上書きされる。\n",
    "\n",
    "\n",
    "def _user_module_transformer(user_module):  \n",
    "    model_fn = getattr(user_module, \"model_fn\", default_model_fn)  \n",
    "    input_fn = getattr(user_module, \"input_fn\", None)  \n",
    "    predict_fn = getattr(user_module, \"predict_fn\", None)  \n",
    "    output_fn = getattr(user_module, \"output_fn\", None)  \n",
    "    transform_fn = getattr(user_module, \"transform_fn\", None)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415a8d25",
   "metadata": {},
   "source": [
    "## model_fnを定義したファイルが、importされているか？\n",
    "\n",
    "いま、そもそも環境変数に正しく情報渡せていない気がする。\n",
    "\n",
    "\n",
    "https://github.com/aws/sagemaker-containers/blob/master/src/sagemaker_containers/_modules.py\n",
    "\n",
    "L237より、\n",
    "\n",
    "def import_module(uri, name=DEFAULT_MODULE_NAME, cache=None):  # type: (str, str, bool) -> module\n",
    "\n",
    "第二引数に指定する必要がある。\n",
    "\n",
    "これを呼ぶのは、\n",
    "\n",
    "\n",
    "https://github.com/aws/sagemaker-xgboost-container/blob/master/src/sagemaker_xgboost_container/serving.py\n",
    "\n",
    "L147\n",
    "\n",
    "user_module = modules.import_module(serving_env.module_dir, serving_env.module_name)\n",
    "\n",
    "serving_env.module_name である。指定できているのか？\n",
    "\n",
    "\n",
    "L143より\n",
    "\n",
    "serving_env = env.ServingEnv()\n",
    "\n",
    "これは、以下のファイル。\n",
    "\n",
    "https://github.com/aws/sagemaker-containers/blob/master/src/sagemaker_containers/_env.py\n",
    "\n",
    "L862\n",
    "\n",
    "class ServingEnv(_Env):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97003d51",
   "metadata": {},
   "source": [
    "https://github.com/aws/sagemaker-containers/blob/master/src/sagemaker_containers/_env.py\n",
    "\n",
    "L329には、\n",
    "\n",
    "class _Env(_mapping.MappingMixin):\n",
    "\n",
    "\n",
    "module_name = os.environ.get(_params.USER_PROGRAM_ENV, None)\n",
    "\n",
    "とある。\n",
    "\n",
    "\n",
    "L595\n",
    "\n",
    "TrainingEnvには、\n",
    "\n",
    "        # override base class attributes  \n",
    "        if self._module_name is None:  \n",
    "            self._module_name = str(sagemaker_hyperparameters.get(_params.USER_PROGRAM_PARAM, None))  \n",
    "        self._user_entry_point = self._user_entry_point or sagemaker_hyperparameters.get(  \n",
    "            _params.USER_PROGRAM_PARAM  \n",
    "        )  \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d812844",
   "metadata": {},
   "source": [
    "## USER_PROGRAM_ENVに設定できればいい？\n",
    "\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit/blob/master/src/sagemaker_inference/parameters.py\n",
    "\n",
    "\n",
    "L18\n",
    "\n",
    "USER_PROGRAM_ENV = \"SAGEMAKER_PROGRAM\"  # type: str\n",
    "\n",
    "SAGEMAKER_PROGRAMに設定できればいいようだ。\n",
    "\n",
    "ビルトインコンテナにはどうすれば設定できるのだろうか？？\n",
    "\n",
    "以下のYouTubeだと、boto3でEnvironment引数を使っている。\n",
    "\n",
    "https://youtu.be/sngNd79GpmE?t=780"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb4f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "951a0a5f",
   "metadata": {},
   "source": [
    "# デバッグのために、dockerイメージをプルして、中をみてみる。\n",
    "\n",
    "ビルトインコンテナの中身をみるには、どうすればいいのか？\n",
    "\n",
    "XGBoostの場合は、ローカルでbuildしていくようだ。\n",
    "\n",
    "https://github.com/aws/sagemaker-xgboost-container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c260dc",
   "metadata": {},
   "source": [
    "# コンテナの中に入って確認する方法\n",
    "コンソールを立ち上げて、以下の流れで実行する\n",
    "\n",
    "\n",
    "ディレクトリ移動\n",
    " $ cd sagemaker-xgboost-container/\n",
    " \n",
    "baseコンテナをビルド\n",
    " $ docker build -t xgboost-container-base:1.5-1-cpu-py3 -f docker/1.5-1/base/Dockerfile.cpu .\n",
    "\n",
    "finalコンテナをビルド\n",
    " $ docker build -t preprod-xgboost-container:1.5-1-cpu-py3 -f docker/1.5-1/final/Dockerfile.cpu .\n",
    "\n",
    "構築されたイメージを確認\n",
    "$ docker image ls\n",
    "\n",
    "中に入って確認（コンテナのタグもつけて指定すること）\n",
    "$ docker run -it preprod-xgboost-container:1.5-1-cpu-py3 /bin/bash\n",
    "\n",
    "$ docker run -it 354813040037.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-xgboost:1.5-1 /bin/bash  \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17450bb",
   "metadata": {},
   "source": [
    "# コンテナの中に入り、 command serveを実行してみる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f8db48",
   "metadata": {},
   "source": [
    "# モデル利用ならうまくいくのではないか？-> OK\n",
    "\n",
    "\n",
    "YouTubeのリンク先ソースより\n",
    "\n",
    "https://github.com/aws-samples/aws-ml-jp/blob/main/sagemaker/sagemaker-inference/inference-tutorial/1_sklearn.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96519af5",
   "metadata": {},
   "source": [
    "https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc5af4c",
   "metadata": {},
   "source": [
    "デプロイ\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f8b6c2",
   "metadata": {},
   "source": [
    "ValueError: Estimator is not associated with a training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8788488",
   "metadata": {},
   "source": [
    "# エラー　trainingjobとの紐付け\n",
    "\n",
    "https://stackoverflow.com/questions/63340328/how-to-define-a-sagemaker-estimator-object-using-a-pre-trained-model-and-then-de"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f6b49a",
   "metadata": {},
   "source": [
    "# END of Containts ==============="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab384ad",
   "metadata": {},
   "source": [
    "# 5.後片付け\n",
    "予期せぬ課金を防ぐために、以下のリソースを削除します。\n",
    "\n",
    "* SageMaker 推論エンドポイント\n",
    "* ECR\n",
    "* S3\n",
    "* SageMakerノートブックインスタンス"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec753b94",
   "metadata": {},
   "source": [
    "# 参考\n",
    "* SageMaker のtrainingジョブを理解する\n",
    "    * https://github.com/aws-samples/aws-ml-jp/tree/main/sagemaker/sagemaker-traning/tutorial\n",
    "* SageMaker-Pytorth training Toolkit\n",
    "    * https://github.com/aws/sagemaker-pytorch-training-toolkit/\n",
    "* SageMaker-Pytorch Inference Toolkit\n",
    "    * https://github.com/aws/sagemaker-pytorch-inference-toolkit\n",
    "* SageMaker Inference Toolkit\n",
    "    * https://docs.aws.amazon.com/sagemaker/latest/dg/amazon-sagemaker-toolkits.html\n",
    "    * https://github.com/aws/sagemaker-inference-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ecd0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30197734",
   "metadata": {},
   "source": [
    "# 解説\n",
    "これは、以下に該当する model_server.py の、start_model_server()が実行されます。\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit/blob/master/src/sagemaker_inference/model_server.py\n",
    "\n",
    "start_model_server()は、引数指定しない場合、inference-toolkitのハンドラサービスを利用します。\n",
    "\n",
    "DEFAULT_HANDLER_SERVICE = default_handler_service.__name__\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit/blob/master/src/sagemaker_inference/default_handler_service.py\n",
    "\n",
    "ハンドラサービスが、Transformer()を作り、そのなかで、推論ハンドラが作られています。\n",
    "\n",
    "DefaultHandlerService -> Transformer -> DefaultInferenceHandler\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit/blob/3774c1a0fb4408cfa95333b75d6e30a376bffa52/src/sagemaker_inference/transformer.py\n",
    "\n",
    "Transform()において利用される、inference-toolkitのDefaultInferenceHandler\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit/blob/master/src/sagemaker_inference/default_inference_handler.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de13c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./container_sminftoolkit/dockerd-entrypoint.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8613f66c",
   "metadata": {},
   "source": [
    "## 解説\n",
    "ハンドラサービスと推論ハンドラがある。\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit\n",
    "\n",
    "ハンドラサービスは、Inference toolkit のGitHubにある、以下に該当する。\n",
    "\n",
    "2.Implement a handler service that is executed by the model server.\n",
    "\n",
    "モデルの推論ハンドラは、以下に該当する。\n",
    "\n",
    "1.Implement an inference handler, which is responsible for loading the model and providing input, predict, and output functions. \n",
    "\n",
    "2.のハンドラサービスから、1.の推論ハンドラがロードされる。推論ハンドラはinference-toolkitで用意したものを使ってもよい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7015909d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
