{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ed979f2",
   "metadata": {},
   "source": [
    "# LightGBMの推論用カスタムコンテナを構築し、SageMakerによる推論の仕組みを深く理解する\n",
    "\n",
    "このノートブックでは、LightGBMがインストールされたカスタムコンテナ構築し、SageMaker Trainingジョブで学習後、推論を行います。\n",
    "カスタムコンテナの挙動を観察し、SageMakerの推論動作について理解を深めます。\n",
    "\n",
    "ノートブックは20分程度で実行できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79998d4",
   "metadata": {},
   "source": [
    "# 0.実行環境確認\n",
    "本ノートブックは、SageMakerノートブックインスタンス上で動作確認しています。\n",
    "* インスタンスタイプ：ml.t3.medium\n",
    "* カーネル：conda_python3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b2d75",
   "metadata": {},
   "source": [
    "## 0-1.pythonバージョン確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e8695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pythonのバージョン情報\n",
    "import sys\n",
    "sys.version # 3.8.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d0586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pythonのバージョン確認 (システムコマンド使用）\n",
    "!python -V # 3.8.12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4fa3ea",
   "metadata": {},
   "source": [
    "## 0-2.SageMakerSDKバージョン確認\n",
    "\n",
    "Amazon SageMaker Python SDKは、Amazon SageMaker上で機械学習されたモデルをトレーニングおよびデプロイするためのオープンソースライブラリです。\n",
    "\n",
    "このSDKを使用すると、一般的な深層学習フレームワーク、Amazonが提供するアルゴリズム、またはSageMaker互換のDockerイメージに組み込まれた独自のアルゴリズムを使ってモデルをトレーニングおよびデプロイすることができます。\n",
    "\n",
    "* ドキュメント : https://sagemaker.readthedocs.io/en/stable/\n",
    "* GitHub : https://github.com/aws/sagemaker-python-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bf3c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMakerSDK のバージョン確認\n",
    "import sagemaker\n",
    "print('Current SageMaker Python SDK Version ={0}'.format(sagemaker.__version__)) # 2.113.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076b541",
   "metadata": {},
   "source": [
    "# 1.データ準備\n",
    "\n",
    "学習、推論で利用するデータを準備します。\n",
    "\n",
    "scikit-learn付属の、ボストン住宅価格データセットを利用します。(注：バージョン1.2から除外されます）  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html\n",
    "\n",
    "以下のスクリプトを参考にしています。\n",
    "\n",
    "https://github.com/aws-samples/amazon-sagemaker-local-mode/blob/main/lightgbm_bring_your_own_container_local_training_and_serving/lightgbm_bring_your_own_container_local_training_and_serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4de339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__ # 1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e49c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.__version__ # 1.3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86597a5",
   "metadata": {},
   "source": [
    "## 1-1. データロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e8a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbdd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston() # 1.2でデータセットがなくすという警告が出ますが動作に影響ありません"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd29936b",
   "metadata": {},
   "source": [
    "## 1-2. 特徴量生成（Feature Engineering）\n",
    "本ノートブックでは実施しません。そのままデータを利用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54b18e2",
   "metadata": {},
   "source": [
    "## 1-3. データ分割\n",
    "学習用（train）、評価用（validation）、テスト用（test）にデータを分割します。  \n",
    "train:val:test = 3(60%):1(20%):1(20%)に分割します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71431eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=45)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=45)\n",
    "\n",
    "trainX = pd.DataFrame(X_train, columns=data.feature_names)\n",
    "trainX['target'] = y_train\n",
    "\n",
    "valX = pd.DataFrame(X_val, columns=data.feature_names)\n",
    "valX['target'] = y_val\n",
    "\n",
    "testX = pd.DataFrame(X_test, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be103082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "print(trainX.shape)\n",
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eee2ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "print(valX.shape)\n",
    "valX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "print(testX.shape)\n",
    "testX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacbd264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "y_test[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c078e0",
   "metadata": {},
   "source": [
    "## 1-4.データ保存\n",
    "ローカル、S3それぞれにデータを保存します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2310c103",
   "metadata": {},
   "source": [
    "### 1-4-1.ローカルへ保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff91b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリ作成\n",
    "from pathlib import Path\n",
    "\n",
    "Path('./data/train').mkdir(parents=True, exist_ok=True)\n",
    "Path('./data/valid').mkdir(parents=True, exist_ok=True)\n",
    "Path('./data/test').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4153037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ローカルへ保存\n",
    "local_train = './data/train/boston_train.csv'\n",
    "local_valid = './data/valid/boston_valid.csv'\n",
    "local_test = './data/test/boston_test.csv'\n",
    "\n",
    "trainX.to_csv(local_train, header=None, index=False)\n",
    "valX.to_csv(local_valid, header=None, index=False)\n",
    "testX.to_csv(local_test, header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2af7e4",
   "metadata": {},
   "source": [
    "### 1-4-2.S3へ保存\n",
    "\n",
    "一意のバケット作成のために、sgemaker.Session().default_bucket()を利用します。\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/utility/session.html#sagemaker.session.Session\n",
    "\n",
    "Session().default_bucket()を実行することで、\n",
    "\n",
    "sagemaker-\\<リージョン名>-\\<アカウントID> という名称のバケットが作成されます。\n",
    "\n",
    "https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/session.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62fccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "region_name = sagemaker.Session().boto_region_name\n",
    "account_id =  sagemaker.Session().account_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf785a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "print(bucket_name)\n",
    "print(region_name)\n",
    "print(account_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d62dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# バケット作成(SageMakerSDKのインポート時作成されています。他のバケット作成時に利用ください)\n",
    "#import boto3\n",
    "\n",
    "#s3_resource = boto3.resource('s3')\n",
    "#s3_resource.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': region_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8949026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3へ保存\n",
    "train_s3 = sagemaker.s3.S3Uploader.upload('./data/train/boston_train.csv', f's3://{bucket_name}/demo_lightgbm/train')\n",
    "valid_s3 = sagemaker.s3.S3Uploader.upload('./data/valid/boston_valid.csv', f's3://{bucket_name}/demo_lightgbm/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150210f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認:格納したS3のURIが返されています\n",
    "print(train_s3)\n",
    "print(valid_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a14082f",
   "metadata": {},
   "source": [
    "# 2.LightGBMカスタムコンテナの構築\n",
    "推論用のカスタムコンテナの作成には大きく分けて4つのパターンがあります。詳細は以下のブログを参考ください。\n",
    "\n",
    "https://aws.amazon.com/jp/blogs/news/sagemaker-custom-containers-pattern-inference/\n",
    "\n",
    "\n",
    "\\<参考>学習用カスタムコンテナの作成\n",
    "\n",
    "https://aws.amazon.com/jp/blogs/news/sagemaker-custom-containers-pattern-training/\n",
    "\n",
    "今回は、学習編で作成した、学習（学習編blogのパターン3）+推論（パターン4）用のカスタムコンテナを利用します。\n",
    "\n",
    "ベースイメージ(ubuntu:16.04) の他は、カスタマイズします。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a89ab7",
   "metadata": {},
   "source": [
    "## 2-1. Dockerfileの確認\n",
    "\n",
    "資材はこちらのノートブックを参考に準備しています。\n",
    "\n",
    "https://github.com/aws-samples/amazon-sagemaker-local-mode/tree/main/lightgbm_bring_your_own_container_local_training_and_serving/container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33031f25",
   "metadata": {},
   "source": [
    "まずは、Dockerfileを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cd7ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./container/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f6d0f",
   "metadata": {},
   "source": [
    "### 推論エンドポイント構築時のSageMakerの動作について\n",
    "SageMakerの推論エンドポイントのデプロイは、SageMaker SDKでは、deploy()メソッドで実行します。\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html\n",
    "\n",
    "その際に、SageMakerは以下のコマンドを実行します。\n",
    "\n",
    "docker run \\<Docker image> server\n",
    "\n",
    "今回のカスタムコンテナでは、 /opt/program に配置した serve スクリプトが実行されます。\n",
    "\n",
    "serveスクリプトを確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4e6a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize -l py ./container/lightgbm_regression/serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e137aa5",
   "metadata": {},
   "source": [
    "初めに、末尾の start_server() が実行され、start_server()では以下が行われます。\n",
    "\n",
    "* nginxの起動（Webサーバ/リバースプロキシの役割）\n",
    "    * nginx.confを読み込みます。\n",
    "* gunicornの起動（Applicationサーバの役割）\n",
    "    * gunicornの起動コマンド引数に'wsgi:app'とあるように、wsgiモジュールwsgi.pyの、appアプリケーションを読み込みます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08585a9",
   "metadata": {},
   "source": [
    "nginx.confを確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdaa30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./container/lightgbm_regression/nginx.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5866788",
   "metadata": {},
   "source": [
    "SageMakerから受け取った /ping と /invocations リクエストを上記で設定したgunicornに渡します。\n",
    "以下に記載があるように、ポート8080を利用する必要があります。\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html\n",
    "\n",
    "How Containers Serve Requests  \n",
    "Containers need to implement a web server that responds to /invocations and /ping on port 8080."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b59ca4f",
   "metadata": {},
   "source": [
    "次に、gunicornへのアプリケーションのキック用に使われるファイル wsgi.pyを確認します。\n",
    "\n",
    "predictor.py の、appを読み込んでいることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b508b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./container/lightgbm_regression/wsgi.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29e027a",
   "metadata": {},
   "source": [
    "predictor.py を確認します。\n",
    "\n",
    "flaskフレームワークを用いて、/ping、 /invocations に対する処理を実装していることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de331e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./container/lightgbm_regression/predictor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e1e803",
   "metadata": {},
   "source": [
    "## 2-2. dockerイメージの build & push\n",
    "上記で確認したカスタムコンテナをビルドします。\n",
    "\n",
    "build & pushには7分ほどかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350878c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-lightgbm-regression\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x lightgbm_regression/train\n",
    "chmod +x lightgbm_regression/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to ap-northeast-1 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-ap-northeast-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e213db",
   "metadata": {},
   "source": [
    "## 2-3. 学習前設定\n",
    "AWSコンソールでECRに移動し、作成したコンテナがあることを確認します。\n",
    "\n",
    "image URIを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7cff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "print(bucket_name)\n",
    "print(region_name)\n",
    "print(account_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae38e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imageURLの設定\n",
    "image_uri = f'{account_id}.dkr.ecr.{region_name}.amazonaws.com/sagemaker-lightgbm-regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56eff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eb8a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習で指定するLightGBMのハイパーパラメータを設定します。\n",
    "hyperparameters={'boosting_type': 'gbdt',\n",
    "                 'objective': 'regression',\n",
    "                 'num_leaves': 31,\n",
    "                 'learning_rate': 0.05,\n",
    "                 'feature_fraction': 0.9,\n",
    "                 'bagging_fraction': 0.8,\n",
    "                 'bagging_freq': 5,\n",
    "                 'verbose': 0\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43018a31",
   "metadata": {},
   "source": [
    "## 2-4.ローカル学習の実行\n",
    "まずはローカルモードでモデルの学習を行います。\n",
    "ローカルモードを利用することで、コンテナイメージのダウンロードや展開の手間を省くことができる、デバッグを行う場合に便利です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ローカルファイルのパスを設定（S3パス指定も可）\n",
    "train_location = 'file://'+local_train\n",
    "valid_location = 'file://'+local_valid\n",
    "\n",
    "print(train_location)\n",
    "print(valid_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbfc6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c354a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1297bb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4ef0ff",
   "metadata": {},
   "source": [
    "SageMakerのEstimatorを作成します。\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da7ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_lightgbm = Estimator(image_uri,\n",
    "                           role,\n",
    "                           instance_count=1,\n",
    "                           instance_type=\"local\",\n",
    "                           hyperparameters=hyperparameters\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6924cf6",
   "metadata": {},
   "source": [
    "fitメソッドで学習ジョブを発行します\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759dca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_lightgbm.fit({'train':train_location, 'validation': valid_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e320324",
   "metadata": {},
   "source": [
    "ローカルモードの学習結果についてもS3に保管されます。\n",
    "\n",
    "s3://sagemaker-< リージョン名 >-< アカウントID >/sagemaker-lightgbm-regression-yyyy-MM-dd-HH-mm-ss-fff/\n",
    "\n",
    "* model.tar.gz\n",
    "* output.tar.gz\n",
    "\n",
    "SageMaker Trainingジョブの詳細については、BlackBeltの解説もご参照ください。\n",
    "https://www.youtube.com/watch?v=byEawTm4O4E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d438a",
   "metadata": {},
   "source": [
    "## 2-5.ローカルデプロイ\n",
    "\n",
    "インプットデータの形式を指定するSerializerは、CSVSerializerとします。\n",
    "SerializerとDeserializerについて学ぶ場合は、study_serializer_deserializer.ipynb を参考にしてください。\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/v2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100f9ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事前準備：全コンテナ停止\n",
    "!docker stop $(docker ps -q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04852144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dbcdbe",
   "metadata": {},
   "source": [
    "起動中のコンテナイメージがないことを確認し、ローカルデプロイを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a6f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_predictor = local_lightgbm.deploy(1, 'local', serializer=sagemaker.serializers.CSVSerializer()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6a15a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1d502c",
   "metadata": {},
   "source": [
    "ローカルにコンテナイメージが展開されていることが確認できました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0390a5ad",
   "metadata": {},
   "source": [
    "## 2-6.ローカルエンドポイントで推論実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d4b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = local_predictor.predict(payload).decode('utf-8')\n",
    "print('=' * 20)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1419f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975e9f59",
   "metadata": {},
   "source": [
    "## 2-7.学習ジョブを発行\n",
    "次は、ローカルモードではなく、\n",
    "同じカスタムコンテナで、学習ジョブを実行します。\n",
    "\n",
    "Estimatorの引数instance_typeにインスタンスタイプを指定することで、学習ジョブが発行されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1a9b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "print(train_s3)\n",
    "print(valid_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_lightgbm = Estimator(image_uri,\n",
    "                         role,\n",
    "                         instance_count=1,\n",
    "                         instance_type=\"ml.m4.2xlarge\", # インスタンスタイプを指定\n",
    "                         hyperparameters=hyperparameters\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce26173",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_lightgbm.fit({'train':train_s3, 'validation': valid_s3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0964763",
   "metadata": {},
   "source": [
    "学習には3分ほど時間がかかります。\n",
    "\n",
    "Billable seconds: \\<秒数>\n",
    "が課金対象の時間となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0b87ee",
   "metadata": {},
   "source": [
    "## 2-8.エンドポイントにデプロイ\n",
    "\n",
    "学習ジョブで構築されたモデルをデプロイします。\n",
    "デプロイ時にSageMaker は \n",
    "\n",
    "docker run \\<image> serve\n",
    "\n",
    "を実行します。\n",
    "\n",
    "    \n",
    "デプロイには3分ほどかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea4683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sagemaker.predictor import csv_serializer # SageMaker SDK v1以前の使い方\n",
    "# https://sagemaker.readthedocs.io/en/stable/v2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e35cf",
   "metadata": {},
   "source": [
    "deployメソッドで、推論エンドポイントをデプロイします。\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase.deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1275b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor = est_lightgbm.deploy(1, 'ml.m4.xlarge', serializer=csv_serializer, wait=True) # SageMaker SDK v1以前の使い方\n",
    "predictor = est_lightgbm.deploy(1, 'ml.m4.xlarge', serializer=sagemaker.serializers.CSVSerializer(), wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f3e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = predictor.predict(payload).decode('utf-8')\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ccfb4",
   "metadata": {},
   "source": [
    "# 3.推論コードを外部ファイルとして指定できるようにする\n",
    "推論コードを外部から指定するために、SageMaker Inference Toolkitを導入します。以下のブログのパターン2に該当します。\n",
    "\n",
    "https://aws.amazon.com/jp/blogs/news/sagemaker-custom-containers-pattern-inference/\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit\n",
    "\n",
    "SageMaker Inference Toolkitは、MMS(Multi Model Server)の利用を前提としているため、MMSも導入します。\n",
    "\n",
    "前セクションではnginx, gunicorn, flaskで推論仕組みを構築しましたが、モデルサービングの仕組みはMMSを利用します。\n",
    "\n",
    "https://github.com/awslabs/multi-model-server/tree/master/docker\n",
    "\n",
    "* SageMaker-Inference-Toolkitと、Multi Model Serverを導入する\n",
    "* ビルトインコンテナ + requirements.txt, inference.pyを利用する\n",
    "\n",
    "MMSの利用については、以下のサンプルコードも参照ください。\n",
    "\n",
    "https://github.com/aws/amazon-sagemaker-examples/tree/main/advanced_functionality/multi_model_bring_your_own\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622126a4",
   "metadata": {},
   "source": [
    "## 3-1.Dockerfileの確認"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519415f3",
   "metadata": {},
   "source": [
    "まずは、利用するDockerfileを確認します。\n",
    "MMSに必要なJavaをインストールし、MMSとinference-toolkitをインストールしています。\n",
    "\n",
    "LightGBMはrequirements.txtでインストールを試みるため、Dockerfileには記載していません。（前セクションのようにDockerfileに記載することも可能）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2764761",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./container_sminftoolkit/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856899aa",
   "metadata": {},
   "source": [
    "## 3-2.エントリポイントを確認\n",
    "\n",
    "SageMakerSDKにてdeploy()を実行した際の\n",
    "\n",
    "docker run \\<image> server\n",
    "\n",
    "で実行される、ENTRYPOINTを確認します。\n",
    "\n",
    "dockerd-entrypoint.py が実行されることがわかります。このファイルを確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48157161",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./container_sminftoolkit/dockerd-entrypoint.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61579389",
   "metadata": {},
   "source": [
    "これは、以下に該当する model_server.py の、start_model_server()が実行されます。\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit/blob/master/src/sagemaker_inference/model_server.py\n",
    "\n",
    "その後の処理の流れはノートブックの末尾に記載します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7ab450",
   "metadata": {},
   "source": [
    "では、このDockerfileをbuildします。\n",
    "\n",
    "build&pushには3分ほどかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32045836",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "#algorithm_name=demo-sagemaker-multimodel\n",
    "algorithm_name=demo-sagemaker-inftoolkit\n",
    "\n",
    "#cd container\n",
    "cd container_sminftoolkit\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -q -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a613c6",
   "metadata": {},
   "source": [
    "## 3-3.ローカルにエンドポイントをデプロイ\n",
    "モデルは前のセクションで作成したLightGBMのモデルを利用します。\n",
    "\n",
    "* 推論ロジックを記載したファイル inference.py を指定する\n",
    "* LightGBMライブラリはrequirements.txtでインストールする"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73505882",
   "metadata": {},
   "source": [
    "推論ロジックを記載した inference.py を確認します。\n",
    "\n",
    "* model_fn : deploy()実行時にモデルロードのため利用されます\n",
    "* input_fn : 推論時に実行され、前処理を行います。\n",
    "* predict_fn : 推論時に実行され、推論を行います。\n",
    "* output_fn : 推論時に実行され、後処理を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b62ff82",
   "metadata": {},
   "source": [
    "model_fnにおいて、LightGBMのモデルが.txt形式なので、lgb.Booster(model_file='.txt')でモデルをロードします。\n",
    "\n",
    "出力ログから動作フローを追えるように、参考情報を多く出力しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52b62f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./src_builtin_container_serve/inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8532d5",
   "metadata": {},
   "source": [
    "次に requirements.txt を確認します。インストールする lightgbm のみ記載しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad90e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./src_builtin_container_serve/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646c3d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_uri = f'{account_id}.dkr.ecr.{region_name}.amazonaws.com/demo-sagemaker-inftoolkit:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d534977",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08aa9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.8の学習ジョブで構築したモデルを利用する\n",
    "#est_lightgbm.model_data\n",
    "\n",
    "### ローカル学習で構築したモデルを利用する場合\n",
    "model_data=local_lightgbm.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b0339",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d53f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#全コンテナ停止\n",
    "!docker stop $(docker ps -q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28436b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252f9091",
   "metadata": {},
   "source": [
    "predictor_clsには、SageMaker SDK v2のPredictorクラスを利用\n",
    "\n",
    "SageMaker SDK v1.72.0\n",
    "https://sagemaker.readthedocs.io/en/v1.72.0/api/inference/predictors.html\n",
    "\n",
    "SageMaker SDK v2.115\n",
    "https://sagemaker.readthedocs.io/en/v2.115.0/api/inference/predictors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faa5491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "lgb_model = sagemaker.model.Model(#est_xgb.image_uri, # XGBoostビルトインコンテナのURI\n",
    "                                  container_uri,\n",
    "                                  model_data=model_data, # ローカル学習で生成したモデルファイル\n",
    "                                  role=role,\n",
    "                                  predictor_cls=Predictor, # 推論するための識別子を指定\n",
    "                                  source_dir='./src_builtin_container_serve', # requirements.txt必要な場合\n",
    "                                  entry_point='inference.py' # source_dirを指定している場合、.pyファイルを指定する。\n",
    "                                  #entry_point='./src_builtin_container_serve/inference.py'\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40877de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_lgb_model = lgb_model.deploy(initial_instance_count=1,\n",
    "                                       instance_type='local', \n",
    "                                       serializer=sagemaker.serializers.CSVSerializer(), ### string形式でSageMakerに渡す（認識してもらう）\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2985c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考：SageMaker SDK v1以前の場合\n",
    "#from sagemaker.predictor import RealTimePredictor\n",
    "#\n",
    "#lgb_model = sagemaker.model.Model(#est_xgb.image_uri, # XGBoostビルトインコンテナのURI\n",
    "#                                  container_uri,\n",
    "#                                  model_data=model_data, # ローカル学習で生成したモデルファイル\n",
    "#                                  role=role,\n",
    "#                                  predictor_cls=RealTimePredictor, # 推論するための識別子を指定\n",
    "#                                  source_dir='./src_builtin_container_serve', # requirements.txt必要な場合\n",
    "#                                  entry_point='inference.py' # source_dirを指定している場合、.pyファイルを指定する。\n",
    "#                                  #entry_point='./src_builtin_container_serve/inference.py'\n",
    "#                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433afd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor_lgb_model = lgb_model.deploy(initial_instance_count=1,\n",
    "#                                       instance_type='local', \n",
    "#                                       serializer=csv_serializer, ### string形式でSageMakerに渡す（認識してもらう）\n",
    "#                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30036db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c2697",
   "metadata": {},
   "source": [
    "## 3-4.推論実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041cc0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = predictor_lgb_model.predict(payload).decode('utf-8')\n",
    "print('=' * 20)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfecd7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(predicted))\n",
    "print('='*50)\n",
    "print(predicted)\n",
    "print('='*50)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc986d56",
   "metadata": {},
   "source": [
    "# (optional) 4.XGBoostコンテナで、LightGBMの推論を実施する\n",
    "\n",
    "XGBoostのビルトインコンテナでLightGBMの推論を行います。\n",
    "LightGBMはrequirements.txtでインストールします。\n",
    "\n",
    "カスタムコンテナではなく、ビルトインコンテナの利用なので、ブログのパターンには該当しません。\n",
    "\n",
    "https://aws.amazon.com/jp/blogs/news/sagemaker-custom-containers-pattern-inference/\n",
    "\n",
    "\n",
    "\\<参考>LightGBMはSageMakerのビルトインアルゴリズムとして用意されています。\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/lightgbm.html    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54229e6f",
   "metadata": {},
   "source": [
    "## 4-1. 既存のモデルを利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f0e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_container_uri = sagemaker.image_uris.retrieve(\"xgboost\", region_name, \"1.5-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d629a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_container_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = sagemaker.model.Model(xgb_container_uri, # XGBoostビルトインコンテナのURI\n",
    "                                  model_data=model_data, # ローカル学習で生成したモデルファイル\n",
    "                                  role=role,\n",
    "                                  predictor_cls=Predictor, # 推論するための識別子を指定\n",
    "                                  source_dir='./src_builtin_container_serve', # requirements.txt必要な場合\n",
    "                                  entry_point='inference.py' # source_dirを指定している場合、.pyファイルを指定する。\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625eb1e0",
   "metadata": {},
   "source": [
    "## 4-2.ローカルにデプロイ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b30cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker stop $(docker ps -q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3976aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6b2590",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_lgb_model = lgb_model.deploy(initial_instance_count=1,\n",
    "                                       instance_type='local', \n",
    "                                       serializer=sagemaker.serializers.CSVSerializer(), ### string形式でSageMakerに渡す（認識してもらう）\n",
    "                                       #deserializer=None, \n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6d182",
   "metadata": {},
   "source": [
    "## 4-3.推論実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5255c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = predictor_lgb_model.predict(payload).decode('utf-8')\n",
    "print('=' * 20)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49113c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "print(type(predicted))\n",
    "print('='*50)\n",
    "print(predicted)\n",
    "print('='*50)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124b2aab",
   "metadata": {},
   "source": [
    "# 5.後片付け\n",
    "予期せぬ課金を防ぐために、以下のリソースを削除します。\n",
    "\n",
    "* SageMaker 推論エンドポイント\n",
    "* ECR\n",
    "* S3\n",
    "* SageMakerノートブックインスタンス"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e1a21b",
   "metadata": {},
   "source": [
    "# Tips\n",
    "* 外部指定する推論用ファイルは、.py である必要がある。また、関数名も決まっている。\n",
    "    * MMSは.pyを扱うように設計されているため。\n",
    "    * https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652bfa70",
   "metadata": {},
   "source": [
    "# 参考\n",
    "* SageMaker のtrainingジョブを理解する\n",
    "    * https://github.com/aws-samples/aws-ml-jp/tree/main/sagemaker/sagemaker-traning/tutorial\n",
    "* SageMaker-Pytorth training Toolkit\n",
    "    * https://github.com/aws/sagemaker-pytorch-training-toolkit/\n",
    "* SageMaker-Pytorch Inference Toolkit\n",
    "    * https://github.com/aws/sagemaker-pytorch-inference-toolkit\n",
    "* SageMaker Inference Toolkit\n",
    "    * https://docs.aws.amazon.com/sagemaker/latest/dg/amazon-sagemaker-toolkits.html\n",
    "    * https://github.com/aws/sagemaker-inference-toolkit\n",
    "* Amazon SageMaker におけるカスタムコンテナ実装パターン詳説 〜学習編〜\n",
    "    * https://aws.amazon.com/jp/blogs/news/sagemaker-custom-containers-pattern-training/\n",
    "* Amazon SageMaker におけるカスタムコンテナ実装パターン詳説 〜推論編〜\n",
    "    * https://aws.amazon.com/jp/blogs/news/sagemaker-custom-containers-pattern-inference/\n",
    "* Building your own algorithm container\n",
    "    * nginx  + gunicorn + flask で構成する推論コンテナについて説明しています\n",
    "    * https://github.com/aws/amazon-sagemaker-examples/blob/main/advanced_functionality/scikit_bring_your_own/scikit_bring_your_own.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e04018c",
   "metadata": {},
   "source": [
    "# 解説：start_model_server()後の挙動について\n",
    "3-2. で実行した、start_model_server()のその後の挙動について詳細を解説します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa7bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-2.で確認したファイル\n",
    "!pygmentize ./container_sminftoolkit/dockerd-entrypoint.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d17ba",
   "metadata": {},
   "source": [
    "これは、以下に該当する model_server.py の、start_model_server()が実行されます。\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit/blob/master/src/sagemaker_inference/model_server.py\n",
    "\n",
    "start_model_server()は、引数を指定しない場合、SageMaker Inference Toolkitのハンドラサービスを利用します。\n",
    "\n",
    "DEFAULT_HANDLER_SERVICE = default_handler_service.__name__\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit/blob/master/src/sagemaker_inference/default_handler_service.py\n",
    "\n",
    "    The handler service is responsible for defining an ``initialize`` and ``handle`` method.\n",
    "        - The ``handle`` method is invoked for all incoming inference requests to the model server.\n",
    "        - The ``initialize`` method is invoked at model server start up.\n",
    "\n",
    "データが入力されたときにhandle()が実行される。  \n",
    "モデルサーバーが起動した時に、initialize()が実行される。\n",
    "\n",
    "initialize()では、Transform()のvalidate_and_initialize()が実行され、ユーザー定義の関数が読み込まれる。\n",
    "\n",
    "inference-toolkitのTransformer()は以下\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit/blob/master/src/sagemaker_inference/transformer.py\n",
    "\n",
    "validate_and_initialize() -> _validate_user_module_and_set_functions() にて、ユーザー定義の関数が読み込まれる。  \n",
    "validate_and_initialize()内で、モデルのロードも実行される。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38de97a7",
   "metadata": {},
   "source": [
    "## DEFAULT_HANDLER_SERVICE がmulti-model-serverコマンドに読み込まれるまで\n",
    "start_model_server(handler_service=DEFAULT_HANDLER_SERVICE)　とありますが、handler_serviceはサーバー起動のコマンドmulti-model-serverにどのように渡されているのでしょうか？\n",
    "追ってみましょう\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit/blob/master/src/sagemaker_inference/model_server.py\n",
    "\n",
    "_create_model_server_config_file(env, handler_service_for_config)\n",
    "\n",
    "が実行されています。これは、configuration_properties にhander_serverなどを追記して、\n",
    "\n",
    "utils.write_file(MMS_CONFIG_FILE, configuration_properties)で、MMS_CONFIG_FILEに書き込みます。\n",
    "このMMS_CONFIG_FILEが、muti-model-serverコマンド実行時に引数として指定されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e6fa20",
   "metadata": {},
   "source": [
    "## ハンドラサービスと推論ハンドラについて\n",
    "ハンドラサービスと推論ハンドラがある。\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit\n",
    "\n",
    "ハンドラサービスは、SageMaker Inference Toolkit のGitHubにある以下に該当する。\n",
    "\n",
    "2.Implement a handler service that is executed by the model server.\n",
    "\n",
    "推論ハンドラは、以下に該当する。\n",
    "\n",
    "1.Implement an inference handler, which is responsible for loading the model and providing input, predict, and output functions. \n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit/blob/master/src/sagemaker_inference/default_inference_handler.py\n",
    "\n",
    "default_model_fn()などが定義されている。\n",
    "\n",
    "2.のハンドラサービスから、1.の推論ハンドラがロードされる。推論ハンドラはinference-toolkitで用意したものを使ってもよい。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
