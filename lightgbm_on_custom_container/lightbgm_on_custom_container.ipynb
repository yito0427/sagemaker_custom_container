{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "732af9fe",
   "metadata": {},
   "source": [
    "# LightGBMをカスタムコンテナで利用する手順を学び、SageMakerの動作を理解します\n",
    "\n",
    "2hを想定\n",
    "\n",
    "コンテンツ\n",
    "* カスタムコンテナ(ローカル学習、ローカル推論、学習ジョブ、推論ジョブ）\n",
    "* SageMaker Training Toolkit導入（コードを外出しにする）：ローカル学習、ローカル推論\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8002d5d9",
   "metadata": {},
   "source": [
    "## 環境\n",
    "本ノートブックは、SageMakerノートブックインスタンス上で動作確認しています。\n",
    "* インスタンスタイプ：ml.t3.medium\n",
    "* カーネル：conda_python3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d030fb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12386811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:59:51) \\n[GCC 9.4.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "#Pythonのバージョン情報\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0870430",
   "metadata": {},
   "source": [
    "'3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:59:51) \\n[GCC 9.4.0]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dd2a7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.12\n"
     ]
    }
   ],
   "source": [
    "# Pythonのバージョン確認 (システムコマンド使用\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d3799",
   "metadata": {},
   "source": [
    "Python 3.8.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcebd7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current SageMaker Python SDK Version =2.109.0\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "print('Current SageMaker Python SDK Version ={0}'.format(sagemaker.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d3d94",
   "metadata": {},
   "source": [
    "## ライブラリインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3372103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sample Python program that trains a simple LightGBM Regression model, and then performs inference.\n",
    "# This implementation will work on your local computer.\n",
    "#\n",
    "# Prerequisites:\n",
    "#   1. Install required Python packages:\n",
    "#       pip install boto3 sagemaker pandas scikit-learn\n",
    "#       pip install 'sagemaker[local]'\n",
    "#   2. Docker Desktop has to be installed on your computer, and running.\n",
    "#   3. Open terminal and run the following commands:\n",
    "#       docker build  -t sagemaker-lightgbm-regression-local container/.\n",
    "########################################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acc4968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.local import LocalSession\n",
    "from sagemaker.predictor import csv_serializer\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f49d2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = LocalSession()\n",
    "sagemaker_session.config = {'local': {'local_code': True}}\n",
    "\n",
    "# For local training a dummy role will be sufficient\n",
    "role = 'arn:aws:iam::111111111111:role/service-role/AmazonSageMaker-ExecutionRole-20200101T000001'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc088f4",
   "metadata": {},
   "source": [
    "# 1.データ準備\n",
    "\n",
    "https://github.com/aws-samples/amazon-sagemaker-local-mode/blob/main/lightgbm_bring_your_own_container_local_training_and_serving/lightgbm_bring_your_own_container_local_training_and_serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eb9d6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data = load_boston()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=45)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=45)\n",
    "\n",
    "trainX = pd.DataFrame(X_train, columns=data.feature_names)\n",
    "trainX['target'] = y_train\n",
    "\n",
    "valX = pd.DataFrame(X_val, columns=data.feature_names)\n",
    "valX['target'] = y_val\n",
    "\n",
    "testX = pd.DataFrame(X_test, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ff55b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path('./data/train').mkdir(parents=True, exist_ok=True)\n",
    "Path('./data/valid').mkdir(parents=True, exist_ok=True)\n",
    "Path('./data/test').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45fd7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_train = './data/train/boston_train.csv'\n",
    "local_valid = './data/valid/boston_valid.csv'\n",
    "local_test = './data/test/boston_test.csv'\n",
    "\n",
    "trainX.to_csv(local_train, header=None, index=False)\n",
    "valX.to_csv(local_valid, header=None, index=False)\n",
    "testX.to_csv(local_test, header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa983b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "422fceb4",
   "metadata": {},
   "source": [
    "# 2.カスタムコンテナ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc20374",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-lightgbm-regression\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x lightgbm_regression/train\n",
    "chmod +x lightgbm_regression/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bfde63",
   "metadata": {},
   "source": [
    "# ECRでpushしたコンテナのURIを確認\n",
    "\n",
    "AWSコンソールでECRに移動し、作成したコンテナがあることを確認します。\n",
    "\n",
    "image URIを取得し、以下にはりつけます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc8aa071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = 'sagemaker-lightgbm-regression-local'\n",
    "#image = '805433377179.dkr.ecr.us-west-2.amazonaws.com/sagemaker-lightgbm-regression:latest' # ビルドしたイメージのURI\n",
    "image = '429775515542.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-lightgbm-regression:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48abc750",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_lightgbm = Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"local\",\n",
    "    hyperparameters={'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a0f87bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_location = 'file://'+local_train\n",
    "valid_location = 'file://'+local_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8851f198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9be4295a",
   "metadata": {},
   "source": [
    "# ローカル学習\n",
    "ECRからビルドしたイメージを持ってきて、ローカルのdockerでビルドして、実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fc901c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating umbbb2deq3-algo-1-f0kmt ... \n",
      "Creating umbbb2deq3-algo-1-f0kmt ... done\n",
      "Attaching to umbbb2deq3-algo-1-f0kmt\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m Starting the training.\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m Reading hyperparameters data: /opt/ml/input/config/hyperparameters.json\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m hyperparameters_data: {'boosting_type': 'gbdt', 'objective': 'regression', 'num_leaves': '31', 'learning_rate': '0.05', 'feature_fraction': '0.9', 'bagging_fraction': '0.8', 'bagging_freq': '5', 'verbose': '0'}\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m Found train files: ['/opt/ml/input/data/train/boston_train.csv']\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m Found validation files: ['/opt/ml/input/data/validation/boston_valid.csv']\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m building training and validation datasets\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m Starting training...\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m /opt/conda/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m   _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000885 seconds.\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m You can set `force_row_wise=true` to remove the overhead.\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m And if memory is not enough, you can set `force_col_wise=true`.\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [1]\tvalid_0's l2: 84.4849\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m Training until validation scores don't improve for 5 rounds\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [2]\tvalid_0's l2: 78.6995\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [3]\tvalid_0's l2: 73.3733\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [4]\tvalid_0's l2: 68.4066\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [5]\tvalid_0's l2: 63.9675\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [6]\tvalid_0's l2: 60.4495\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [7]\tvalid_0's l2: 57.2702\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [8]\tvalid_0's l2: 54.3096\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [9]\tvalid_0's l2: 51.6438\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [10]\tvalid_0's l2: 49.4106\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [11]\tvalid_0's l2: 46.871\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [12]\tvalid_0's l2: 44.4878\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [13]\tvalid_0's l2: 42.2348\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [14]\tvalid_0's l2: 40.2703\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [15]\tvalid_0's l2: 38.4195\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [16]\tvalid_0's l2: 36.6089\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [17]\tvalid_0's l2: 34.9745\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [18]\tvalid_0's l2: 33.5774\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [19]\tvalid_0's l2: 32.1331\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [20]\tvalid_0's l2: 30.8945\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m Did not meet early stopping. Best iteration is:\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m [20]\tvalid_0's l2: 30.8945\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m saving model file to /opt/ml/model/lightgbm-regression-model.txt\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt |\u001b[0m Training complete.\n",
      "\u001b[36mumbbb2deq3-algo-1-f0kmt exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "local_lightgbm.fit({'train':train_location, 'validation': valid_location}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d376ca70",
   "metadata": {},
   "source": [
    "ローカルモードの学習結果は\n",
    "\n",
    "Amazon S3\n",
    "Buckets\n",
    "sagemaker-us-west-2-805433377179\n",
    "sagemaker-lightgbm-regression-2022-10-03-06-17-32-054/\n",
    "\n",
    "に出力されます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917591f2",
   "metadata": {},
   "source": [
    "### ローカルサービング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a19adfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to f8onwze1xo-algo-1-ixw9g\n",
      "\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m Starting the inference server with 2 workers.\n",
      "\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m [2022-10-04 04:10:34 +0000] [10] [INFO] Starting gunicorn 20.1.0\n",
      "\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m [2022-10-04 04:10:34 +0000] [10] [INFO] Listening at: unix:/tmp/gunicorn.sock (10)\n",
      "\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m [2022-10-04 04:10:34 +0000] [10] [INFO] Using worker: gevent\n",
      "\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m [2022-10-04 04:10:34 +0000] [12] [INFO] Booting worker with pid: 12\n",
      "\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m [2022-10-04 04:10:34 +0000] [13] [INFO] Booting worker with pid: 13\n",
      "!\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m 172.18.0.1 - - [04/Oct/2022:04:10:37 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"python-urllib3/1.26.8\"\n"
     ]
    }
   ],
   "source": [
    "local_predictor = local_lightgbm.deploy(1, 'local', serializer=csv_serializer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c8e30a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m Invoked with 102 records\n",
      "19.95642073217597\n",
      "27.844891841022335\n",
      "23.747437427003455\n",
      "21.961517177305176\n",
      "33.70952263893306\n",
      "16.546899933876215\n",
      "20.7577247308279\n",
      "21.58941351302627\n",
      "28.44096446328559\n",
      "21.573610198594977\n",
      "16.520022349295115\n",
      "18.56239893242527\n",
      "33.70952263893306\n",
      "21.66404760045202\n",
      "18.839854556333133\n",
      "20.524517944865078\n",
      "23.512192914502315\n",
      "19.720552829648888\n",
      "14.831841119971708\n",
      "25.48273874904075\n",
      "24.232639474441545\n",
      "21.624005932843115\n",
      "24.961489794296718\n",
      "31.737194191676068\n",
      "21.634052928440624\n",
      "28.40721160777621\n",
      "21.408363849719503\n",
      "14.831841119971708\n",
      "22.218594550645975\n",
      "21.174456098551236\n",
      "21.78791955089051\n",
      "14.831841119971708\n",
      "29.996695633096042\n",
      "22.44097524661187\n",
      "33.83316205414468\n",
      "26.41403196992683\n",
      "33.70952263893306\n",
      "17.366188662166092\n",
      "27.56686070285819\n",
      "30.785697489113854\n",
      "19.36938873496206\n",
      "20.70626548555591\n",
      "17.759853567831996\n",
      "27.888269821752413\n",
      "20.521395163186774\n",
      "14.831841119971708\n",
      "24.776417537973362\n",
      "24.965857100129327\n",
      "19.649289821764185\n",
      "21.026797620813866\n",
      "33.70952263893306\n",
      "22.770867837558004\n",
      "25.12436361101226\n",
      "32.04499227317663\n",
      "20.300871717805446\n",
      "25.993751032745912\n",
      "14.831841119971708\n",
      "17.55319877077615\n",
      "21.070286538617665\n",
      "21.122413297289743\n",
      "16.377053075082987\n",
      "15.568373592583868\n",
      "33.70952263893306\n",
      "27.61154020402463\n",
      "19.342761095149218\n",
      "17.9509721146777\n",
      "33.70952263893306\n",
      "33.83316205414468\n",
      "25.48273874904075\n",
      "20.660796015624964\n",
      "30.699461095863427\n",
      "21.035390723179418\n",
      "22.185819485247606\n",
      "19.29909952861762\n",
      "16.5747000607082\n",
      "23.912684065447934\n",
      "28.57571329880843\n",
      "16.236339853147257\n",
      "27.50109599287484\n",
      "15.753943396426372\n",
      "17.4887323059089\n",
      "16.546899933876215\n",
      "27.601367949672184\n",
      "27.83102844560462\n",
      "23.566264337152624\n",
      "27.50109599287484\n",
      "21.643847857886936\n",
      "18.787237415866525\n",
      "17.9186752451325\n",
      "14.831841119971708\n",
      "22.735042390270507\n",
      "18.93446150698524\n",
      "20.78281339932023\n",
      "15.124660622321342\n",
      "26.580072090826267\n",
      "33.83316205414468\n",
      "22.241689637239144\n",
      "18.003487732270226\n",
      "26.120941030113585\n",
      "21.857620352091608\n",
      "23.067030809188566\n",
      "31.381458114994132\n",
      "\n",
      "\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m 172.18.0.1 - - [04/Oct/2022:04:10:40 +0000] \"POST /invocations HTTP/1.1\" 200 1894 \"-\" \"python-urllib3/1.26.8\"\n"
     ]
    }
   ],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = local_predictor.predict(payload).decode('utf-8')\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14084bc",
   "metadata": {},
   "source": [
    "# 学習ジョブを発行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b24a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "060524da",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_lightgbm = Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.2xlarge\",\n",
    "    hyperparameters={'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "784a6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "bucket_name = '<bucket_name>' # input your bucket name\n",
    "bucket_name = 'demo-lgbm-container'\n",
    "\n",
    "train_s3 = sagemaker.s3.S3Uploader.upload('./data/train/boston_train.csv', f's3://{bucket_name}/demo_lightgbm/train')\n",
    "valid_s3 = sagemaker.s3.S3Uploader.upload('./data/valid/boston_valid.csv', f's3://{bucket_name}/demo_lightgbm/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d8ae48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-04 04:15:55 Starting - Starting the training job...\n",
      "2022-10-04 04:16:21 Starting - Preparing the instances for trainingProfilerReport-1664856955: InProgress\n",
      ".........\n",
      "2022-10-04 04:17:44 Downloading - Downloading input data\n",
      "2022-10-04 04:17:44 Training - Downloading the training image...\n",
      "2022-10-04 04:18:20 Training - Training image download completed. Training in progress..\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mReading hyperparameters data: /opt/ml/input/config/hyperparameters.json\u001b[0m\n",
      "\u001b[34mhyperparameters_data: {'bagging_fraction': '0.8', 'bagging_freq': '5', 'boosting_type': 'gbdt', 'feature_fraction': '0.9', 'learning_rate': '0.05', 'num_leaves': '31', 'objective': 'regression', 'verbose': '0'}\u001b[0m\n",
      "\u001b[34mFound train files: ['/opt/ml/input/data/train/boston_train.csv']\u001b[0m\n",
      "\u001b[34mFound validation files: ['/opt/ml/input/data/validation/boston_valid.csv']\u001b[0m\n",
      "\u001b[34mbuilding training and validation datasets\u001b[0m\n",
      "\u001b[34mStarting training...\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019846 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_row_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34mAnd if memory is not enough, you can set `force_col_wise=true`.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[1]#011valid_0's l2: 84.4849\u001b[0m\n",
      "\u001b[34mTraining until validation scores don't improve for 5 rounds\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[2]#011valid_0's l2: 78.6995\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[3]#011valid_0's l2: 73.3733\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[4]#011valid_0's l2: 68.4066\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[5]#011valid_0's l2: 63.9675\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[6]#011valid_0's l2: 60.4495\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[7]#011valid_0's l2: 57.2702\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[8]#011valid_0's l2: 54.3096\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[9]#011valid_0's l2: 51.6438\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[10]#011valid_0's l2: 49.4106\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[11]#011valid_0's l2: 46.871\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[12]#011valid_0's l2: 44.4878\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[13]#011valid_0's l2: 42.2348\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[14]#011valid_0's l2: 40.2703\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[15]#011valid_0's l2: 38.4195\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[16]#011valid_0's l2: 36.6089\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[17]#011valid_0's l2: 34.9745\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[18]#011valid_0's l2: 33.5774\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[19]#011valid_0's l2: 32.1331\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[20]#011valid_0's l2: 30.8945\u001b[0m\n",
      "\u001b[34mDid not meet early stopping. Best iteration is:\u001b[0m\n",
      "\u001b[34m[20]#011valid_0's l2: 30.8945\u001b[0m\n",
      "\u001b[34msaving model file to /opt/ml/model/lightgbm-regression-model.txt\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2022-10-04 04:19:20 Uploading - Uploading generated training model\n",
      "2022-10-04 04:19:20 Completed - Training job completed\n",
      "Training seconds: 111\n",
      "Billable seconds: 111\n"
     ]
    }
   ],
   "source": [
    "est_lightgbm.fit({'train':train_s3, 'validation': valid_s3}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b7f7c9",
   "metadata": {},
   "source": [
    "## エンドポイントにデプロイ\n",
    "waitしない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e432382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7b1a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = est_lightgbm.deploy(1, 'ml.m4.xlarge', serializer=csv_serializer, wait=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd7d1ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.95642073217597\n",
      "27.844891841022335\n",
      "23.747437427003455\n",
      "21.961517177305176\n",
      "33.70952263893306\n",
      "16.546899933876215\n",
      "20.7577247308279\n",
      "21.58941351302627\n",
      "28.44096446328559\n",
      "21.573610198594977\n",
      "16.520022349295115\n",
      "18.56239893242527\n",
      "33.70952263893306\n",
      "21.66404760045202\n",
      "18.839854556333133\n",
      "20.524517944865078\n",
      "23.512192914502315\n",
      "19.720552829648888\n",
      "14.831841119971708\n",
      "25.48273874904075\n",
      "24.232639474441545\n",
      "21.624005932843115\n",
      "24.961489794296718\n",
      "31.737194191676068\n",
      "21.634052928440624\n",
      "28.40721160777621\n",
      "21.408363849719503\n",
      "14.831841119971708\n",
      "22.218594550645975\n",
      "21.174456098551236\n",
      "21.78791955089051\n",
      "14.831841119971708\n",
      "29.996695633096042\n",
      "22.44097524661187\n",
      "33.83316205414468\n",
      "26.41403196992683\n",
      "33.70952263893306\n",
      "17.366188662166092\n",
      "27.56686070285819\n",
      "30.785697489113854\n",
      "19.36938873496206\n",
      "20.70626548555591\n",
      "17.759853567831996\n",
      "27.888269821752413\n",
      "20.521395163186774\n",
      "14.831841119971708\n",
      "24.776417537973362\n",
      "24.965857100129327\n",
      "19.649289821764185\n",
      "21.026797620813866\n",
      "33.70952263893306\n",
      "22.770867837558004\n",
      "25.12436361101226\n",
      "32.04499227317663\n",
      "20.300871717805446\n",
      "25.993751032745912\n",
      "14.831841119971708\n",
      "17.55319877077615\n",
      "21.070286538617665\n",
      "21.122413297289743\n",
      "16.377053075082987\n",
      "15.568373592583868\n",
      "33.70952263893306\n",
      "27.61154020402463\n",
      "19.342761095149218\n",
      "17.9509721146777\n",
      "33.70952263893306\n",
      "33.83316205414468\n",
      "25.48273874904075\n",
      "20.660796015624964\n",
      "30.699461095863427\n",
      "21.035390723179418\n",
      "22.185819485247606\n",
      "19.29909952861762\n",
      "16.5747000607082\n",
      "23.912684065447934\n",
      "28.57571329880843\n",
      "16.236339853147257\n",
      "27.50109599287484\n",
      "15.753943396426372\n",
      "17.4887323059089\n",
      "16.546899933876215\n",
      "27.601367949672184\n",
      "27.83102844560462\n",
      "23.566264337152624\n",
      "27.50109599287484\n",
      "21.643847857886936\n",
      "18.787237415866525\n",
      "17.9186752451325\n",
      "14.831841119971708\n",
      "22.735042390270507\n",
      "18.93446150698524\n",
      "20.78281339932023\n",
      "15.124660622321342\n",
      "26.580072090826267\n",
      "33.83316205414468\n",
      "22.241689637239144\n",
      "18.003487732270226\n",
      "26.120941030113585\n",
      "21.857620352091608\n",
      "23.067030809188566\n",
      "31.381458114994132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = predictor.predict(payload).decode('utf-8')\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c99595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dac7a656",
   "metadata": {},
   "source": [
    "### 学習スクリプトをローカルに保存して実行\n",
    "GitHubから実行したい場合も。\n",
    "\n",
    "SageMaker Training Toolkitが必要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c60b83",
   "metadata": {},
   "source": [
    "### カスタムコンテナ作成\n",
    "trainは含めないように注意しましょう。\n",
    "\n",
    "Dockerfileにて、\n",
    "・train を /opt/program/train と配置\n",
    "・カレントディレクトリを /opt/program に設定\n",
    "・SageMaker Training Toolkit が /opt/conda/bin/train にインストールされる\n",
    "・train を実行すると、カレントにある /opt/program/train が実行されてしまう。\n",
    "解決するには、\n",
    "・カレントディレクトリを 持ち込みのtrainがある場所にしない\n",
    "・train をそもそもコンテナに入れない（確実）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55f8cda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  19.97kB\n",
      "Step 1/14 : FROM ubuntu:16.04\n",
      " ---> b6f507652425\n",
      "Step 2/14 : MAINTAINER Amazon AI <sage-learner@amazon.com>\n",
      " ---> Using cache\n",
      " ---> b93522070e55\n",
      "Step 3/14 : ARG CONDA_DIR=/opt/conda\n",
      " ---> Using cache\n",
      " ---> 3c36d88c98af\n",
      "Step 4/14 : ENV PATH $CONDA_DIR/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> e3fd517f81e5\n",
      "Step 5/14 : RUN apt-get update &&     apt-get install -y --no-install-recommends         ca-certificates         cmake         build-essential         gcc         g++         git         nginx         wget &&     wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh &&     /bin/bash Miniconda3-latest-Linux-x86_64.sh -f -b -p $CONDA_DIR &&     export PATH=\"$CONDA_DIR/bin:$PATH\" &&     conda config --set always_yes yes --set changeps1 no &&     conda install -q -y numpy scipy scikit-learn pandas flask gevent gunicorn &&     git clone --recursive --branch stable --depth 1 https://github.com/Microsoft/LightGBM &&     cd LightGBM/python-package && python setup.py install &&     apt-get autoremove -y && apt-get clean &&     conda clean -a -y &&     rm -rf /usr/local/src/*\n",
      " ---> Using cache\n",
      " ---> 9e29882821e2\n",
      "Step 6/14 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 3b1139806651\n",
      "Step 7/14 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 22d79dd73b74\n",
      "Step 8/14 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 18d3c666f0fd\n",
      "Step 9/14 : COPY lightgbm_regression /opt/program\n",
      " ---> 734db6edc9a4\n",
      "Step 10/14 : ARG PIP=pip3\n",
      " ---> Running in 32f1c7747d7b\n",
      "Removing intermediate container 32f1c7747d7b\n",
      " ---> 62c77e656803\n",
      "Step 11/14 : RUN ${PIP} --no-cache-dir install --upgrade pip\n",
      " ---> Running in 053cada7a328\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (21.2.4)\n",
      "Collecting pip\n",
      "  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.2.4\n",
      "    Uninstalling pip-21.2.4:\n",
      "      Successfully uninstalled pip-21.2.4\n",
      "Successfully installed pip-22.2.2\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 053cada7a328\n",
      " ---> 80fb1cacb616\n",
      "Step 12/14 : RUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n",
      " ---> Running in 6b984a2dedea\n",
      "Removing intermediate container 6b984a2dedea\n",
      " ---> 589d18c73238\n",
      "Step 13/14 : RUN ${PIP} install --no-cache --upgrade     sagemaker-training\n",
      " ---> Running in 74757b2047a7\n",
      "Collecting sagemaker-training\n",
      "  Downloading sagemaker_training-4.2.9.tar.gz (55 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.7/55.7 kB 23.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from sagemaker-training) (1.21.5)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.24.85-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 199.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from sagemaker-training) (1.16.0)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (from sagemaker-training) (22.2.2)\n",
      "Collecting retrying>=1.3.3\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: gevent in /opt/conda/lib/python3.9/site-packages (from sagemaker-training) (21.8.0)\n",
      "Collecting inotify_simple==1.2.1\n",
      "  Downloading inotify_simple-1.2.1.tar.gz (7.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: werkzeug>=0.15.5 in /opt/conda/lib/python3.9/site-packages (from sagemaker-training) (2.0.3)\n",
      "Collecting paramiko>=2.4.2\n",
      "  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.9/212.9 kB 274.3 MB/s eta 0:00:00\n",
      "Collecting psutil>=5.6.7\n",
      "  Downloading psutil-5.9.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 281.9/281.9 kB 239.2 MB/s eta 0:00:00\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 276.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.2.2 in /opt/conda/lib/python3.9/site-packages (from sagemaker-training) (1.7.3)\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 305.2 MB/s eta 0:00:00\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-4.0.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (594 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 594.1/594.1 kB 288.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.4.2->sagemaker-training) (36.0.0)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 247.4 MB/s eta 0:00:00\n",
      "Collecting botocore<1.28.0,>=1.27.85\n",
      "  Downloading botocore-1.27.85-py3-none-any.whl (9.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.2/9.2 MB 203.0 MB/s eta 0:00:00\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: greenlet<2.0,>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from gevent->sagemaker-training) (1.1.1)\n",
      "Requirement already satisfied: zope.event in /opt/conda/lib/python3.9/site-packages (from gevent->sagemaker-training) (4.5.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from gevent->sagemaker-training) (61.2.0)\n",
      "Requirement already satisfied: zope.interface in /opt/conda/lib/python3.9/site-packages (from gevent->sagemaker-training) (5.4.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.9/site-packages (from botocore<1.28.0,>=1.27.85->boto3->sagemaker-training) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.9/site-packages (from botocore<1.28.0,>=1.27.85->boto3->sagemaker-training) (1.26.8)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.9/site-packages (from cryptography>=2.5->paramiko>=2.4.2->sagemaker-training) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.5->paramiko>=2.4.2->sagemaker-training) (2.21)\n",
      "Building wheels for collected packages: sagemaker-training, inotify_simple, retrying\n",
      "  Building wheel for sagemaker-training (setup.py): started\n",
      "  Building wheel for sagemaker-training (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-training: filename=sagemaker_training-4.2.9-cp39-cp39-linux_x86_64.whl size=73815 sha256=281aa61afbc9a0b9b0c22b25d3a34105810b28ba7b54ffc9d592b378649585b5\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-yw2x2dnf/wheels/24/83/bc/32181c9e0274582c67f7692c127f5ea67a7ed20f1b4c8ecf82\n",
      "  Building wheel for inotify_simple (setup.py): started\n",
      "  Building wheel for inotify_simple (setup.py): finished with status 'done'\n",
      "  Created wheel for inotify_simple: filename=inotify_simple-1.2.1-py3-none-any.whl size=8218 sha256=5be73178c75a4b312a40fbe42b32f7c25e5b13a08766f6842c8d1626f8da7381\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-yw2x2dnf/wheels/b6/4e/da/d0d3ad5cdf86b232168db1e8ea6bc5763a73468e7d78e2a4a7\n",
      "  Building wheel for retrying (setup.py): started\n",
      "  Building wheel for retrying (setup.py): finished with status 'done'\n",
      "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11447 sha256=c0d5b6814c209225a6de7140fb143df8f84296af0cb4b61e92f7a2c4e76fdc32\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-yw2x2dnf/wheels/ce/18/7f/e9527e3e66db1456194ac7f61eb3211068c409edceecff2d31\n",
      "Successfully built sagemaker-training inotify_simple retrying\n",
      "Installing collected packages: inotify_simple, retrying, psutil, protobuf, jmespath, bcrypt, pynacl, botocore, s3transfer, paramiko, boto3, sagemaker-training\n",
      "Successfully installed bcrypt-4.0.0 boto3-1.24.85 botocore-1.27.85 inotify_simple-1.2.1 jmespath-1.0.1 paramiko-2.11.0 protobuf-3.19.6 psutil-5.9.2 pynacl-1.5.0 retrying-1.3.3 s3transfer-0.6.0 sagemaker-training-4.2.9\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 74757b2047a7\n",
      " ---> 75e85a9ac744\n",
      "Step 14/14 : WORKDIR /opt/program\n",
      " ---> Running in fdd008161505\n",
      "Removing intermediate container fdd008161505\n",
      " ---> 538b11b141cb\n",
      "Successfully built 538b11b141cb\n",
      "Successfully tagged sagemaker-toolkit:latest\n",
      "The push refers to repository [429775515542.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-toolkit]\n",
      "139e7aef1745: Preparing\n",
      "8406600ae00f: Preparing\n",
      "a02d7b19fb3d: Preparing\n",
      "838fe4240d17: Preparing\n",
      "8fd7df5e5534: Preparing\n",
      "1251204ef8fc: Preparing\n",
      "47ef83afae74: Preparing\n",
      "df54c846128d: Preparing\n",
      "be96a3f634de: Preparing\n",
      "1251204ef8fc: Waiting\n",
      "47ef83afae74: Waiting\n",
      "df54c846128d: Waiting\n",
      "be96a3f634de: Waiting\n",
      "838fe4240d17: Pushed\n",
      "8406600ae00f: Pushed\n",
      "1251204ef8fc: Pushed\n",
      "47ef83afae74: Pushed\n",
      "a02d7b19fb3d: Pushed\n",
      "df54c846128d: Pushed\n",
      "139e7aef1745: Pushed\n",
      "be96a3f634de: Pushed\n",
      "8fd7df5e5534: Pushed\n",
      "latest: digest: sha256:c5a967b74d1b91b0e06545b606a53bfe856efc2a3dc53baa4e27d5219c614d12 size: 2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-toolkit\n",
    "\n",
    "#cd container\n",
    "cd container_smtrtoolkit ### 変更点\n",
    "\n",
    "#chmod +x lightgbm_regression/train\n",
    "chmod +x lightgbm_regression/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e039f7ed",
   "metadata": {},
   "source": [
    "## 学習(ローカル)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9024626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = '805433377179.dkr.ecr.us-west-2.amazonaws.com/sagemaker-lightgbm-toolkit:latest'\n",
    "image = '429775515542.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-toolkit:latest'\n",
    "#image = <input your own image URI>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffee52b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating m27alddto9-algo-1-5me20 ... \n",
      "Creating m27alddto9-algo-1-5me20 ... done\n",
      "Attaching to m27alddto9-algo-1-5me20\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m 2022-10-04 05:48:08,705 botocore.credentials INFO     Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m 2022-10-04 05:48:08,931 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m 2022-10-04 05:48:08,932 sagemaker-training-toolkit INFO     Failed to parse hyperparameter boosting_type value gbdt to Json.\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m Returning the value itself\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m 2022-10-04 05:48:08,932 sagemaker-training-toolkit INFO     Failed to parse hyperparameter objective value regression to Json.\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m Returning the value itself\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m 2022-10-04 05:48:08,945 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m 2022-10-04 05:48:08,949 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m 2022-10-04 05:48:08,949 sagemaker-training-toolkit INFO     Failed to parse hyperparameter boosting_type value gbdt to Json.\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m Returning the value itself\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m 2022-10-04 05:48:08,949 sagemaker-training-toolkit INFO     Failed to parse hyperparameter objective value regression to Json.\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m Returning the value itself\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m 2022-10-04 05:48:08,960 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m 2022-10-04 05:48:08,963 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m 2022-10-04 05:48:08,964 sagemaker-training-toolkit INFO     Failed to parse hyperparameter boosting_type value gbdt to Json.\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m Returning the value itself\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m 2022-10-04 05:48:08,964 sagemaker-training-toolkit INFO     Failed to parse hyperparameter objective value regression to Json.\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m Returning the value itself\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m 2022-10-04 05:48:08,974 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m 2022-10-04 05:48:08,975 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m \n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m Training Env:\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m \n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m {\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\"\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     },\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"current_host\": \"algo-1-5me20\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"current_instance_group\": \"homogeneousCluster\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"current_instance_group_hosts\": [],\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"current_instance_type\": \"local\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"distribution_hosts\": [\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         \"algo-1-5me20\"\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     ],\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"distribution_instance_groups\": [],\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"framework_module\": null,\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         \"algo-1-5me20\"\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     ],\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         \"boosting_type\": \"gbdt\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         \"objective\": \"regression\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         \"num_leaves\": 31,\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         \"learning_rate\": 0.05,\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         \"feature_fraction\": 0.9,\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         \"bagging_fraction\": 0.8,\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         \"bagging_freq\": 5,\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         \"verbose\": 0\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     },\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         \"train\": {\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         },\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         \"validation\": {\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         }\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     },\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"instance_groups\": [],\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"instance_groups_dict\": {},\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"is_hetero\": false,\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"is_modelparallel_enabled\": null,\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"job_name\": \"sagemaker-toolkit-2022-10-04-05-48-05-427\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"master_hostname\": \"algo-1-5me20\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-1-429775515542/sagemaker-toolkit-2022-10-04-05-48-05-427/source/sourcedir.tar.gz\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"module_name\": \"train_practice\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         \"current_host\": \"algo-1-5me20\",\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m             \"algo-1-5me20\"\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m         ]\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     },\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m     \"user_entry_point\": \"train_practice.py\"\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m }\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m \n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m Environment variables:\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m \n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_HOSTS=[\"algo-1-5me20\"]\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_HPS={\"bagging_fraction\":0.8,\"bagging_freq\":5,\"boosting_type\":\"gbdt\",\"feature_fraction\":0.9,\"learning_rate\":0.05,\"num_leaves\":31,\"objective\":\"regression\",\"verbose\":0}\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_USER_ENTRY_POINT=train_practice.py\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-5me20\",\"hosts\":[\"algo-1-5me20\"]}\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_CHANNELS=[\"train\",\"validation\"]\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_CURRENT_HOST=algo-1-5me20\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_CURRENT_INSTANCE_TYPE=local\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_CURRENT_INSTANCE_GROUP_HOSTS=[]\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_INSTANCE_GROUPS=[]\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_INSTANCE_GROUPS_DICT={}\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_IS_HETERO=false\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_MODULE_NAME=train_practice\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_FRAMEWORK_MODULE=\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-1-429775515542/sagemaker-toolkit-2022-10-04-05-48-05-427/source/sourcedir.tar.gz\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-5me20\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[],\"current_instance_type\":\"local\",\"distribution_hosts\":[\"algo-1-5me20\"],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1-5me20\"],\"hyperparameters\":{\"bagging_fraction\":0.8,\"bagging_freq\":5,\"boosting_type\":\"gbdt\",\"feature_fraction\":0.9,\"learning_rate\":0.05,\"num_leaves\":31,\"objective\":\"regression\",\"verbose\":0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[],\"instance_groups_dict\":{},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"sagemaker-toolkit-2022-10-04-05-48-05-427\",\"log_level\":20,\"master_hostname\":\"algo-1-5me20\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-1-429775515542/sagemaker-toolkit-2022-10-04-05-48-05-427/source/sourcedir.tar.gz\",\"module_name\":\"train_practice\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-5me20\",\"hosts\":[\"algo-1-5me20\"]},\"user_entry_point\":\"train_practice.py\"}\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_USER_ARGS=[\"--bagging_fraction\",\"0.8\",\"--bagging_freq\",\"5\",\"--boosting_type\",\"gbdt\",\"--feature_fraction\",\"0.9\",\"--learning_rate\",\"0.05\",\"--num_leaves\",\"31\",\"--objective\",\"regression\",\"--verbose\",\"0\"]\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_HP_BOOSTING_TYPE=gbdt\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_HP_OBJECTIVE=regression\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_HP_NUM_LEAVES=31\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_HP_LEARNING_RATE=0.05\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_HP_FEATURE_FRACTION=0.9\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_HP_BAGGING_FRACTION=0.8\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_HP_BAGGING_FREQ=5\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m SM_HP_VERBOSE=0\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m \n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m \n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m /opt/conda/bin/python train_practice.py --bagging_fraction 0.8 --bagging_freq 5 --boosting_type gbdt --feature_fraction 0.9 --learning_rate 0.05 --num_leaves 31 --objective regression --verbose 0\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m \n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m \n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m 2022-10-04 05:48:08,976 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m ===== congraturations! You understand how SageMaker Training Job Works!!! =====\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m Starting the training.\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m Reading hyperparameters data: /opt/ml/input/config/hyperparameters.json\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m hyperparameters_data: {'boosting_type': 'gbdt', 'objective': 'regression', 'num_leaves': '31', 'learning_rate': '0.05', 'feature_fraction': '0.9', 'bagging_fraction': '0.8', 'bagging_freq': '5', 'verbose': '0', 'sagemaker_submit_directory': '\"s3://sagemaker-ap-northeast-1-429775515542/sagemaker-toolkit-2022-10-04-05-48-05-427/source/sourcedir.tar.gz\"', 'sagemaker_program': '\"train_practice.py\"', 'sagemaker_container_log_level': '20', 'sagemaker_job_name': '\"sagemaker-toolkit-2022-10-04-05-48-05-427\"', 'sagemaker_region': '\"ap-northeast-1\"'}\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m Found train files: ['/opt/ml/input/data/train/boston_train.csv']\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m Found validation files: ['/opt/ml/input/data/validation/boston_valid.csv']\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m building training and validation datasets\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m Starting training...\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m /opt/conda/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m   _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000080 seconds.\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m You can set `force_row_wise=true` to remove the overhead.\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m And if memory is not enough, you can set `force_col_wise=true`.\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [1]\tvalid_0's l2: 84.4849\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m Training until validation scores don't improve for 5 rounds\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [2]\tvalid_0's l2: 78.6995\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [3]\tvalid_0's l2: 73.3733\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [4]\tvalid_0's l2: 68.4066\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [5]\tvalid_0's l2: 63.9675\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [6]\tvalid_0's l2: 60.4495\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [7]\tvalid_0's l2: 57.2702\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [8]\tvalid_0's l2: 54.3096\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [9]\tvalid_0's l2: 51.6438\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [10]\tvalid_0's l2: 49.4106\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [11]\tvalid_0's l2: 46.871\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [12]\tvalid_0's l2: 44.4878\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [13]\tvalid_0's l2: 42.2348\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [14]\tvalid_0's l2: 40.2703\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [15]\tvalid_0's l2: 38.4195\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [16]\tvalid_0's l2: 36.6089\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [17]\tvalid_0's l2: 34.9745\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [18]\tvalid_0's l2: 33.5774\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [19]\tvalid_0's l2: 32.1331\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [20]\tvalid_0's l2: 30.8945\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m Did not meet early stopping. Best iteration is:\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m [20]\tvalid_0's l2: 30.8945\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m saving model file to /opt/ml/model/lightgbm-regression-model.txt\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m Training complete.\n",
      "\u001b[36mm27alddto9-algo-1-5me20 |\u001b[0m 2022-10-04 05:48:10,338 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mm27alddto9-algo-1-5me20 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "est_lightgbm3 = Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    #instance_type=\"ml.m4.2xlarge\",\n",
    "    instance_type=\"local\",\n",
    "    hyperparameters={'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0},\n",
    "    #source_dir='./practice_src',\n",
    "    entry_point='./src/train_practice.py'\n",
    "    #entry_point='./practice_src/train_practice.sh'\n",
    "    )\n",
    "est_lightgbm3.fit({'train':train_s3, 'validation': valid_s3}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d4f048",
   "metadata": {},
   "source": [
    "## デプロイローカル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78411c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m 172.18.0.1 - - [04/Oct/2022:05:48:16 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"python-urllib3/1.26.8\"\n",
      "!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/local/image.py\", line 854, in run\n",
      "    _stream_output(self.process)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/local/image.py\", line 916, in _stream_output\n",
      "    raise RuntimeError(\"Process exited with code: %s\" % exit_code)\n",
      "RuntimeError: Process exited with code: 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/local/image.py\", line 859, in run\n",
      "    raise RuntimeError(msg)\n",
      "RuntimeError: Failed to run: ['docker-compose', '-f', '/tmp/tmp9zd_hh8c/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1\n"
     ]
    }
   ],
   "source": [
    "predictor3 = est_lightgbm3.deploy(1, 'local', serializer=csv_serializer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5ed159e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m Invoked with 102 records\n",
      "19.95642073217597\n",
      "27.844891841022335\n",
      "23.747437427003455\n",
      "21.961517177305176\n",
      "33.70952263893306\n",
      "16.546899933876215\n",
      "20.7577247308279\n",
      "21.58941351302627\n",
      "28.44096446328559\n",
      "21.573610198594977\n",
      "16.520022349295115\n",
      "18.56239893242527\n",
      "33.70952263893306\n",
      "21.66404760045202\n",
      "18.839854556333133\n",
      "20.524517944865078\n",
      "23.512192914502315\n",
      "19.720552829648888\n",
      "14.831841119971708\n",
      "25.48273874904075\n",
      "24.232639474441545\n",
      "21.624005932843115\n",
      "24.961489794296718\n",
      "31.737194191676068\n",
      "21.634052928440624\n",
      "28.40721160777621\n",
      "21.408363849719503\n",
      "14.831841119971708\n",
      "22.218594550645975\n",
      "21.174456098551236\n",
      "21.78791955089051\n",
      "14.831841119971708\n",
      "29.996695633096042\n",
      "22.44097524661187\n",
      "33.83316205414468\n",
      "26.41403196992683\n",
      "33.70952263893306\n",
      "17.366188662166092\n",
      "27.56686070285819\n",
      "30.785697489113854\n",
      "19.36938873496206\n",
      "20.70626548555591\n",
      "17.759853567831996\n",
      "27.888269821752413\n",
      "20.521395163186774\n",
      "14.831841119971708\n",
      "24.776417537973362\n",
      "24.965857100129327\n",
      "19.649289821764185\n",
      "21.026797620813866\n",
      "33.70952263893306\n",
      "22.770867837558004\n",
      "25.12436361101226\n",
      "32.04499227317663\n",
      "20.300871717805446\n",
      "25.993751032745912\n",
      "14.831841119971708\n",
      "17.55319877077615\n",
      "21.070286538617665\n",
      "21.122413297289743\n",
      "16.377053075082987\n",
      "15.568373592583868\n",
      "33.70952263893306\n",
      "27.61154020402463\n",
      "19.342761095149218\n",
      "17.9509721146777\n",
      "33.70952263893306\n",
      "33.83316205414468\n",
      "25.48273874904075\n",
      "20.660796015624964\n",
      "30.699461095863427\n",
      "21.035390723179418\n",
      "22.185819485247606\n",
      "19.29909952861762\n",
      "16.5747000607082\n",
      "23.912684065447934\n",
      "28.57571329880843\n",
      "16.236339853147257\n",
      "27.50109599287484\n",
      "15.753943396426372\n",
      "17.4887323059089\n",
      "16.546899933876215\n",
      "27.601367949672184\n",
      "27.83102844560462\n",
      "23.566264337152624\n",
      "27.50109599287484\n",
      "21.643847857886936\n",
      "18.787237415866525\n",
      "17.9186752451325\n",
      "14.831841119971708\n",
      "22.735042390270507\n",
      "18.93446150698524\n",
      "20.78281339932023\n",
      "15.124660622321342\n",
      "26.580072090826267\n",
      "33.83316205414468\n",
      "22.241689637239144\n",
      "18.003487732270226\n",
      "26.120941030113585\n",
      "21.857620352091608\n",
      "23.067030809188566\n",
      "31.381458114994132\n",
      "\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m 172.18.0.1 - - [04/Oct/2022:05:48:23 +0000] \"POST /invocations HTTP/1.1\" 200 1894 \"-\" \"python-urllib3/1.26.8\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = predictor3.predict(payload).decode('utf-8')\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2263041d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d37cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d01655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8915ff8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e24af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5127bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7f9bca7",
   "metadata": {},
   "source": [
    "# 参考\n",
    "\n",
    "\n",
    "SageMaker-Pytorth training Toolkit\n",
    "https://github.com/aws/sagemaker-pytorch-training-toolkit/\n",
    "\n",
    "\n",
    "SageMaker-Pytorch Inference Toolkit\n",
    "\n",
    "https://github.com/aws/sagemaker-pytorch-inference-toolkit\n",
    "\n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/73694705/what-is-the-difference-between-sagemaker-pytorch-training-toolkit-and-sagemaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af802b84",
   "metadata": {},
   "source": [
    "## 参考\n",
    "SageMaker のtrainingジョブを理解する\n",
    "\n",
    "https://github.com/aws-samples/aws-ml-jp/tree/main/sagemaker/sagemaker-traning/tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74184b1b",
   "metadata": {},
   "source": [
    "# Toolkitを入れず、train からtrain.shを実行\n",
    "\n",
    "ソースをS3に配置しなればならない\n",
    "\n",
    "\n",
    "fit()について\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase.fit\n",
    "\n",
    "datasetの指定は、S3のパスか、ローカルモードならfile://　つまりGitHubは不可"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634e6827",
   "metadata": {},
   "source": [
    "### SageMaker Traiing Toolkitについて\n",
    "\n",
    "https://github.com/aws/sagemaker-training-toolkit/blob/master/README.md\n",
    "\n",
    "inference toolkitもある。\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/amazon-sagemaker-toolkits.html\n",
    "\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51bb70",
   "metadata": {},
   "source": [
    "## （おまけ）カスタムコンテナを使わず、built-inコンテナのrequirement.txtにlightgbmを記載して実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa14518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"1.2-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96b0b67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'354813040037.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-xgboost:1.2-1'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d311965",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_lightgbm5 = Estimator(\n",
    "    #image,\n",
    "    container, # xgboostのbuilt-inコンテナ\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    #instance_type=\"ml.m4.2xlarge\",\n",
    "    instance_type=\"local\",\n",
    "    hyperparameters={'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0},\n",
    "    source_dir='./src_builtin_container',\n",
    "    entry_point='train_practice.py'\n",
    "    #entry_point='./practice_src/train_practice.sh'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bd2a10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Creating i5fghyfypp-algo-1-yfcz5 ... \n",
      "Creating i5fghyfypp-algo-1-yfcz5 ... done\n",
      "Attaching to i5fghyfypp-algo-1-yfcz5\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [2022-10-04 04:28:16.976 6a1e6e45f30e:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m INFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m INFO:sagemaker-containers:Failed to parse hyperparameter boosting_type value gbdt to Json.\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Returning the value itself\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m INFO:sagemaker-containers:Failed to parse hyperparameter objective value regression to Json.\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Returning the value itself\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m INFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m INFO:sagemaker_xgboost_container.training:Invoking user training script.\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m INFO:sagemaker-containers:Module train_practice does not provide a setup.py. \n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Generating setup.py\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m INFO:sagemaker-containers:Generating setup.cfg\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m INFO:sagemaker-containers:Generating MANIFEST.in\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m INFO:sagemaker-containers:Installing module with the following command:\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m /miniconda3/bin/python3 -m pip install . -r requirements.txt\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m \u001b[?25hCollecting lightgbm\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m   Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m \u001b[?25hRequirement already satisfied: scipy in /miniconda3/lib/python3.7/site-packages (from lightgbm->-r requirements.txt (line 1)) (1.5.3)\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Requirement already satisfied: wheel in /miniconda3/lib/python3.7/site-packages (from lightgbm->-r requirements.txt (line 1)) (0.35.1)\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Requirement already satisfied: scikit-learn!=0.22.0 in /miniconda3/lib/python3.7/site-packages (from lightgbm->-r requirements.txt (line 1)) (0.23.2)\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Requirement already satisfied: numpy in /miniconda3/lib/python3.7/site-packages (from lightgbm->-r requirements.txt (line 1)) (1.19.2)\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Requirement already satisfied: threadpoolctl>=2.0.0 in /miniconda3/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm->-r requirements.txt (line 1)) (3.1.0)\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Requirement already satisfied: joblib>=0.11 in /miniconda3/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm->-r requirements.txt (line 1)) (1.2.0)\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Building wheels for collected packages: train-practice\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m   Building wheel for train-practice (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m \u001b[?25h  Created wheel for train-practice: filename=train_practice-1.0.0-py2.py3-none-any.whl size=6511 sha256=84f8f8372a972ffa78e74efdba72eb6d1bb88489c3b82e1a0dced1a7aa084923\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-6na5_8le/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Successfully built train-practice\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Installing collected packages: train-practice, lightgbm\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Successfully installed lightgbm-3.3.2 train-practice-1.0.0\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m \u001b[0mINFO:sagemaker-containers:Failed to parse hyperparameter boosting_type value gbdt to Json.\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Returning the value itself\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m INFO:sagemaker-containers:Failed to parse hyperparameter objective value regression to Json.\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Returning the value itself\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m INFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m INFO:sagemaker-containers:Invoking user script\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m \n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Training Env:\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m \n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m {\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\"\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     },\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"current_host\": \"algo-1-yfcz5\",\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         \"algo-1-yfcz5\"\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     ],\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         \"boosting_type\": \"gbdt\",\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         \"objective\": \"regression\",\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         \"num_leaves\": 31,\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         \"learning_rate\": 0.05,\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         \"feature_fraction\": 0.9,\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         \"bagging_fraction\": 0.8,\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         \"bagging_freq\": 5,\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         \"verbose\": 0\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     },\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         \"train\": {\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         },\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         \"validation\": {\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         }\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     },\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"job_name\": \"sagemaker-xgboost-2022-10-04-04-26-27-912\",\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"master_hostname\": \"algo-1-yfcz5\",\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-1-429775515542/sagemaker-xgboost-2022-10-04-04-26-27-912/source/sourcedir.tar.gz\",\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"module_name\": \"train_practice\",\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         \"current_host\": \"algo-1-yfcz5\",\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m             \"algo-1-yfcz5\"\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m         ]\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     },\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m     \"user_entry_point\": \"train_practice.py\"\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m }\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m \n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Environment variables:\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m \n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_HOSTS=[\"algo-1-yfcz5\"]\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_HPS={\"bagging_fraction\":0.8,\"bagging_freq\":5,\"boosting_type\":\"gbdt\",\"feature_fraction\":0.9,\"learning_rate\":0.05,\"num_leaves\":31,\"objective\":\"regression\",\"verbose\":0}\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_USER_ENTRY_POINT=train_practice.py\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-yfcz5\",\"hosts\":[\"algo-1-yfcz5\"]}\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_CHANNELS=[\"train\",\"validation\"]\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_CURRENT_HOST=algo-1-yfcz5\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_MODULE_NAME=train_practice\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-1-429775515542/sagemaker-xgboost-2022-10-04-04-26-27-912/source/sourcedir.tar.gz\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-yfcz5\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1-yfcz5\"],\"hyperparameters\":{\"bagging_fraction\":0.8,\"bagging_freq\":5,\"boosting_type\":\"gbdt\",\"feature_fraction\":0.9,\"learning_rate\":0.05,\"num_leaves\":31,\"objective\":\"regression\",\"verbose\":0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2022-10-04-04-26-27-912\",\"log_level\":20,\"master_hostname\":\"algo-1-yfcz5\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-1-429775515542/sagemaker-xgboost-2022-10-04-04-26-27-912/source/sourcedir.tar.gz\",\"module_name\":\"train_practice\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-yfcz5\",\"hosts\":[\"algo-1-yfcz5\"]},\"user_entry_point\":\"train_practice.py\"}\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_USER_ARGS=[\"--bagging_fraction\",\"0.8\",\"--bagging_freq\",\"5\",\"--boosting_type\",\"gbdt\",\"--feature_fraction\",\"0.9\",\"--learning_rate\",\"0.05\",\"--num_leaves\",\"31\",\"--objective\",\"regression\",\"--verbose\",\"0\"]\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_HP_BOOSTING_TYPE=gbdt\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_HP_OBJECTIVE=regression\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_HP_NUM_LEAVES=31\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_HP_LEARNING_RATE=0.05\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_HP_FEATURE_FRACTION=0.9\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_HP_BAGGING_FRACTION=0.8\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_HP_BAGGING_FREQ=5\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m SM_HP_VERBOSE=0\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m PYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m \n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m \n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m /miniconda3/bin/python3 -m train_practice --bagging_fraction 0.8 --bagging_freq 5 --boosting_type gbdt --feature_fraction 0.9 --learning_rate 0.05 --num_leaves 31 --objective regression --verbose 0\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m \n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m \n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m ===== congraturations! You understand how SageMaker Training Job Works!!! =====\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Starting the training.\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Reading hyperparameters data: /opt/ml/input/config/hyperparameters.json\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m hyperparameters_data: {'boosting_type': 'gbdt', 'objective': 'regression', 'num_leaves': '31', 'learning_rate': '0.05', 'feature_fraction': '0.9', 'bagging_fraction': '0.8', 'bagging_freq': '5', 'verbose': '0', 'sagemaker_submit_directory': '\"s3://sagemaker-ap-northeast-1-429775515542/sagemaker-xgboost-2022-10-04-04-26-27-912/source/sourcedir.tar.gz\"', 'sagemaker_program': '\"train_practice.py\"', 'sagemaker_container_log_level': '20', 'sagemaker_job_name': '\"sagemaker-xgboost-2022-10-04-04-26-27-912\"', 'sagemaker_region': '\"ap-northeast-1\"'}\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Found train files: ['/opt/ml/input/data/train/boston_train.csv']\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Found validation files: ['/opt/ml/input/data/validation/boston_valid.csv']\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m building training and validation datasets\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Starting training...\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m /miniconda3/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m   _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m You can set `force_row_wise=true` to remove the overhead.\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m And if memory is not enough, you can set `force_col_wise=true`.\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [1]\tvalid_0's l2: 84.4849\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Training until validation scores don't improve for 5 rounds\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [2]\tvalid_0's l2: 78.6995\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [3]\tvalid_0's l2: 73.3733\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [4]\tvalid_0's l2: 68.4066\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [5]\tvalid_0's l2: 63.9675\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [6]\tvalid_0's l2: 60.4495\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [7]\tvalid_0's l2: 57.2702\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [8]\tvalid_0's l2: 54.3096\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [9]\tvalid_0's l2: 51.6438\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [10]\tvalid_0's l2: 49.4106\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [11]\tvalid_0's l2: 46.871\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [12]\tvalid_0's l2: 44.4878\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [13]\tvalid_0's l2: 42.2348\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [14]\tvalid_0's l2: 40.2703\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [15]\tvalid_0's l2: 38.4195\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [16]\tvalid_0's l2: 36.6089\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [17]\tvalid_0's l2: 34.9745\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [18]\tvalid_0's l2: 33.5774\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [19]\tvalid_0's l2: 32.1331\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [20]\tvalid_0's l2: 30.8945\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Did not meet early stopping. Best iteration is:\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m [20]\tvalid_0's l2: 30.8945\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m saving model file to /opt/ml/model/lightgbm-regression-model.txt\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 |\u001b[0m Training complete.\n",
      "\u001b[36mi5fghyfypp-algo-1-yfcz5 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "est_lightgbm5.fit({'train':train_s3, 'validation': valid_s3}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed6547",
   "metadata": {},
   "source": [
    "このコンテナでservingをするにはどうすればいいか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06cfa84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m 172.18.0.1 - - [04/Oct/2022:05:49:58 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"python-urllib3/1.26.8\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/local/image.py\", line 854, in run\n",
      "    _stream_output(self.process)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/local/image.py\", line 916, in _stream_output\n",
      "    raise RuntimeError(\"Process exited with code: %s\" % exit_code)\n",
      "RuntimeError: Process exited with code: 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/local/image.py\", line 859, in run\n",
      "    raise RuntimeError(msg)\n",
      "RuntimeError: Failed to run: ['docker-compose', '-f', '/tmp/tmp95mqnqdk/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1\n"
     ]
    }
   ],
   "source": [
    "predictor5 = est_lightgbm5.deploy(1, 'local', serializer=csv_serializer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09b79e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m Invoked with 102 records\n",
      "19.95642073217597\n",
      "27.844891841022335\n",
      "23.747437427003455\n",
      "21.961517177305176\n",
      "33.70952263893306\n",
      "16.546899933876215\n",
      "20.7577247308279\n",
      "21.58941351302627\n",
      "28.44096446328559\n",
      "21.573610198594977\n",
      "16.520022349295115\n",
      "18.56239893242527\n",
      "33.70952263893306\n",
      "21.66404760045202\n",
      "18.839854556333133\n",
      "20.524517944865078\n",
      "23.512192914502315\n",
      "19.720552829648888\n",
      "14.831841119971708\n",
      "25.48273874904075\n",
      "24.232639474441545\n",
      "21.624005932843115\n",
      "24.961489794296718\n",
      "31.737194191676068\n",
      "21.634052928440624\n",
      "28.40721160777621\n",
      "21.408363849719503\n",
      "14.831841119971708\n",
      "22.218594550645975\n",
      "21.174456098551236\n",
      "21.78791955089051\n",
      "14.831841119971708\n",
      "29.996695633096042\n",
      "22.44097524661187\n",
      "33.83316205414468\n",
      "26.41403196992683\n",
      "33.70952263893306\n",
      "17.366188662166092\n",
      "27.56686070285819\n",
      "30.785697489113854\n",
      "19.36938873496206\n",
      "20.70626548555591\n",
      "17.759853567831996\n",
      "27.888269821752413\n",
      "20.521395163186774\n",
      "14.831841119971708\n",
      "24.776417537973362\n",
      "24.965857100129327\n",
      "19.649289821764185\n",
      "21.026797620813866\n",
      "33.70952263893306\n",
      "22.770867837558004\n",
      "25.12436361101226\n",
      "32.04499227317663\n",
      "20.300871717805446\n",
      "25.993751032745912\n",
      "14.831841119971708\n",
      "17.55319877077615\n",
      "21.070286538617665\n",
      "21.122413297289743\n",
      "16.377053075082987\n",
      "15.568373592583868\n",
      "33.70952263893306\n",
      "27.61154020402463\n",
      "19.342761095149218\n",
      "17.9509721146777\n",
      "33.70952263893306\n",
      "33.83316205414468\n",
      "25.48273874904075\n",
      "20.660796015624964\n",
      "30.699461095863427\n",
      "21.035390723179418\n",
      "22.185819485247606\n",
      "19.29909952861762\n",
      "16.5747000607082\n",
      "23.912684065447934\n",
      "28.57571329880843\n",
      "16.236339853147257\n",
      "27.50109599287484\n",
      "15.753943396426372\n",
      "17.4887323059089\n",
      "16.546899933876215\n",
      "27.601367949672184\n",
      "27.83102844560462\n",
      "23.566264337152624\n",
      "27.50109599287484\n",
      "21.643847857886936\n",
      "18.787237415866525\n",
      "17.9186752451325\n",
      "14.831841119971708\n",
      "22.735042390270507\n",
      "18.93446150698524\n",
      "20.78281339932023\n",
      "15.124660622321342\n",
      "26.580072090826267\n",
      "33.83316205414468\n",
      "22.241689637239144\n",
      "18.003487732270226\n",
      "26.120941030113585\n",
      "21.857620352091608\n",
      "23.067030809188566\n",
      "31.381458114994132\n",
      "\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m 172.18.0.1 - - [04/Oct/2022:05:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 1894 \"-\" \"python-urllib3/1.26.8\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = predictor5.predict(payload).decode('utf-8')\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "94009098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m 172.18.0.1 - - [04/Oct/2022:05:53:02 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"python-urllib3/1.26.8\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/local/image.py\", line 854, in run\n",
      "    _stream_output(self.process)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/local/image.py\", line 916, in _stream_output\n",
      "    raise RuntimeError(\"Process exited with code: %s\" % exit_code)\n",
      "RuntimeError: Process exited with code: 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/local/image.py\", line 859, in run\n",
      "    raise RuntimeError(msg)\n",
      "RuntimeError: Failed to run: ['docker-compose', '-f', '/tmp/tmpf7485uip/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1\n"
     ]
    }
   ],
   "source": [
    "predictor6 = est_lightgbm5.deploy(1, 'ml.m4.xlarge', serializer=csv_serializer, wait=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90eb794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.95642073217597\n",
      "27.844891841022335\n",
      "23.747437427003455\n",
      "21.961517177305176\n",
      "33.70952263893306\n",
      "16.546899933876215\n",
      "20.7577247308279\n",
      "21.58941351302627\n",
      "28.44096446328559\n",
      "21.573610198594977\n",
      "16.520022349295115\n",
      "18.56239893242527\n",
      "33.70952263893306\n",
      "21.66404760045202\n",
      "18.839854556333133\n",
      "20.524517944865078\n",
      "23.512192914502315\n",
      "19.720552829648888\n",
      "14.831841119971708\n",
      "25.48273874904075\n",
      "24.232639474441545\n",
      "21.624005932843115\n",
      "24.961489794296718\n",
      "31.737194191676068\n",
      "21.634052928440624\n",
      "28.40721160777621\n",
      "21.408363849719503\n",
      "14.831841119971708\n",
      "22.218594550645975\n",
      "21.174456098551236\n",
      "21.78791955089051\n",
      "14.831841119971708\n",
      "29.996695633096042\n",
      "22.44097524661187\n",
      "33.83316205414468\n",
      "26.41403196992683\n",
      "33.70952263893306\n",
      "17.366188662166092\n",
      "27.56686070285819\n",
      "30.785697489113854\n",
      "19.36938873496206\n",
      "20.70626548555591\n",
      "17.759853567831996\n",
      "27.888269821752413\n",
      "20.521395163186774\n",
      "14.831841119971708\n",
      "24.776417537973362\n",
      "24.965857100129327\n",
      "19.649289821764185\n",
      "21.026797620813866\n",
      "33.70952263893306\n",
      "22.770867837558004\n",
      "25.12436361101226\n",
      "32.04499227317663\n",
      "20.300871717805446\n",
      "25.993751032745912\n",
      "14.831841119971708\n",
      "17.55319877077615\n",
      "21.070286538617665\n",
      "21.122413297289743\n",
      "16.377053075082987\n",
      "15.568373592583868\n",
      "33.70952263893306\n",
      "27.61154020402463\n",
      "19.342761095149218\n",
      "17.9509721146777\n",
      "33.70952263893306\n",
      "33.83316205414468\n",
      "25.48273874904075\n",
      "20.660796015624964\n",
      "30.699461095863427\n",
      "21.035390723179418\n",
      "22.185819485247606\n",
      "19.29909952861762\n",
      "16.5747000607082\n",
      "23.912684065447934\n",
      "28.57571329880843\n",
      "16.236339853147257\n",
      "27.50109599287484\n",
      "15.753943396426372\n",
      "17.4887323059089\n",
      "16.546899933876215\n",
      "27.601367949672184\n",
      "27.83102844560462\n",
      "23.566264337152624\n",
      "27.50109599287484\n",
      "21.643847857886936\n",
      "18.787237415866525\n",
      "17.9186752451325\n",
      "14.831841119971708\n",
      "22.735042390270507\n",
      "18.93446150698524\n",
      "20.78281339932023\n",
      "15.124660622321342\n",
      "26.580072090826267\n",
      "33.83316205414468\n",
      "22.241689637239144\n",
      "18.003487732270226\n",
      "26.120941030113585\n",
      "21.857620352091608\n",
      "23.067030809188566\n",
      "31.381458114994132\n",
      "\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m Invoked with 102 records\n",
      "\u001b[36mf8onwze1xo-algo-1-ixw9g |\u001b[0m 172.18.0.1 - - [04/Oct/2022:05:53:13 +0000] \"POST /invocations HTTP/1.1\" 200 1894 \"-\" \"python-urllib3/1.26.8\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = predictor6.predict(payload).decode('utf-8')\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0253b9",
   "metadata": {},
   "source": [
    "# End Of Containts ================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02433f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
