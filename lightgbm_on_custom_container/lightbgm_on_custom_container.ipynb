{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e1470b",
   "metadata": {},
   "source": [
    "# LightGBMをカスタムコンテナで利用する手順を学び、SageMakerの動作を理解します\n",
    "\n",
    "2hを想定\n",
    "\n",
    "コンテンツ\n",
    "* カスタムコンテナ(ローカル学習、ローカル推論、学習ジョブ、推論ジョブ）\n",
    "* SageMaker Training Toolkit導入（コードを外出しにする）：ローカル学習、ローカル推論\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cc6250",
   "metadata": {},
   "source": [
    "## 環境\n",
    "本ノートブックは、SageMakerノートブックインスタンス上で動作確認しています。\n",
    "* インスタンスタイプ：ml.t3.medium\n",
    "* カーネル：conda_python3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890fb0a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cca7b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:59:51) \\n[GCC 9.4.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "#Pythonのバージョン情報\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f720dafb",
   "metadata": {},
   "source": [
    "'3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:59:51) \\n[GCC 9.4.0]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e41ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.12\n"
     ]
    }
   ],
   "source": [
    "# Pythonのバージョン確認 (システムコマンド使用\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187bcf07",
   "metadata": {},
   "source": [
    "Python 3.8.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b40263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current SageMaker Python SDK Version =2.109.0\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "print('Current SageMaker Python SDK Version ={0}'.format(sagemaker.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f3db42",
   "metadata": {},
   "source": [
    "## ライブラリインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1cab0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sample Python program that trains a simple LightGBM Regression model, and then performs inference.\n",
    "# This implementation will work on your local computer.\n",
    "#\n",
    "# Prerequisites:\n",
    "#   1. Install required Python packages:\n",
    "#       pip install boto3 sagemaker pandas scikit-learn\n",
    "#       pip install 'sagemaker[local]'\n",
    "#   2. Docker Desktop has to be installed on your computer, and running.\n",
    "#   3. Open terminal and run the following commands:\n",
    "#       docker build  -t sagemaker-lightgbm-regression-local container/.\n",
    "########################################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a25ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.local import LocalSession\n",
    "from sagemaker.predictor import csv_serializer\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26b670bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = LocalSession()\n",
    "sagemaker_session.config = {'local': {'local_code': True}}\n",
    "\n",
    "# For local training a dummy role will be sufficient\n",
    "role = 'arn:aws:iam::111111111111:role/service-role/AmazonSageMaker-ExecutionRole-20200101T000001'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262964f",
   "metadata": {},
   "source": [
    "# 1.データ準備\n",
    "\n",
    "https://github.com/aws-samples/amazon-sagemaker-local-mode/blob/main/lightgbm_bring_your_own_container_local_training_and_serving/lightgbm_bring_your_own_container_local_training_and_serving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "698fe5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data = load_boston()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=45)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=45)\n",
    "\n",
    "trainX = pd.DataFrame(X_train, columns=data.feature_names)\n",
    "trainX['target'] = y_train\n",
    "\n",
    "valX = pd.DataFrame(X_val, columns=data.feature_names)\n",
    "valX['target'] = y_val\n",
    "\n",
    "testX = pd.DataFrame(X_test, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ab13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path('./data/train').mkdir(parents=True, exist_ok=True)\n",
    "Path('./data/valid').mkdir(parents=True, exist_ok=True)\n",
    "Path('./data/test').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fe8f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_train = './data/train/boston_train.csv'\n",
    "local_valid = './data/valid/boston_valid.csv'\n",
    "local_test = './data/test/boston_test.csv'\n",
    "\n",
    "trainX.to_csv(local_train, header=None, index=False)\n",
    "valX.to_csv(local_valid, header=None, index=False)\n",
    "testX.to_csv(local_test, header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c3be40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3a53b03",
   "metadata": {},
   "source": [
    "# 2.カスタムコンテナ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d542330",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-lightgbm-regression\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x lightgbm_regression/train\n",
    "chmod +x lightgbm_regression/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6935f52c",
   "metadata": {},
   "source": [
    "# ECRでpushしたコンテナのURIを確認\n",
    "\n",
    "AWSコンソールでECRに移動し、作成したコンテナがあることを確認します。\n",
    "\n",
    "image URIを取得し、以下にはりつけます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e6315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = 'sagemaker-lightgbm-regression-local'\n",
    "#image = '805433377179.dkr.ecr.us-west-2.amazonaws.com/sagemaker-lightgbm-regression:latest' # ビルドしたイメージのURI\n",
    "image = '429775515542.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-lightgbm-regression:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80093bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_lightgbm = Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"local\",\n",
    "    hyperparameters={'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49959fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_location = 'file://'+local_train\n",
    "valid_location = 'file://'+local_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4103e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "463ca65f",
   "metadata": {},
   "source": [
    "# ローカル学習\n",
    "ECRからビルドしたイメージを持ってきて、ローカルのdockerでビルドして、実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_lightgbm.fit({'train':train_location, 'validation': valid_location}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c3ff35",
   "metadata": {},
   "source": [
    "ローカルモードの学習結果は\n",
    "\n",
    "Amazon S3\n",
    "Buckets\n",
    "sagemaker-us-west-2-805433377179\n",
    "sagemaker-lightgbm-regression-2022-10-03-06-17-32-054/\n",
    "\n",
    "に出力されます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692d0d08",
   "metadata": {},
   "source": [
    "### ローカルサービング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_predictor = local_lightgbm.deploy(1, 'local', serializer=csv_serializer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ddd835",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = local_predictor.predict(payload).decode('utf-8')\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee7038",
   "metadata": {},
   "source": [
    "# 学習ジョブを発行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac72bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fceedc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_lightgbm = Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.2xlarge\",\n",
    "    hyperparameters={'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47baa4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "bucket_name = '<bucket_name>' # input your bucket name\n",
    "bucket_name = 'demo-lgbm-container'\n",
    "\n",
    "train_s3 = sagemaker.s3.S3Uploader.upload('./data/train/boston_train.csv', f's3://{bucket_name}/demo_lightgbm/train')\n",
    "valid_s3 = sagemaker.s3.S3Uploader.upload('./data/valid/boston_valid.csv', f's3://{bucket_name}/demo_lightgbm/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbc7965",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_lightgbm.fit({'train':train_s3, 'validation': valid_s3}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b03ca",
   "metadata": {},
   "source": [
    "## エンドポイントにデプロイ\n",
    "waitしない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc718c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c489dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = est_lightgbm.deploy(1, 'ml.m4.xlarge', serializer=csv_serializer, wait=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e9246",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = predictor.predict(payload).decode('utf-8')\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06372f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "076e7d4f",
   "metadata": {},
   "source": [
    "### 学習スクリプトをローカルに保存して実行\n",
    "GitHubから実行したい場合も。\n",
    "\n",
    "SageMaker Training Toolkitが必要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d3e017",
   "metadata": {},
   "source": [
    "### カスタムコンテナ作成\n",
    "trainは含めないように注意しましょう。\n",
    "\n",
    "Dockerfileにて、\n",
    "・train を /opt/program/train と配置\n",
    "・カレントディレクトリを /opt/program に設定\n",
    "・SageMaker Training Toolkit が /opt/conda/bin/train にインストールされる\n",
    "・train を実行すると、カレントにある /opt/program/train が実行されてしまう。\n",
    "解決するには、\n",
    "・カレントディレクトリを 持ち込みのtrainがある場所にしない\n",
    "・train をそもそもコンテナに入れない（確実）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b625aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-toolkit\n",
    "\n",
    "#cd container\n",
    "cd container_smtrtoolkit ### 変更点\n",
    "\n",
    "#chmod +x lightgbm_regression/train\n",
    "chmod +x lightgbm_regression/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c53d4a2",
   "metadata": {},
   "source": [
    "## 学習(ローカル)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4cf48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = '805433377179.dkr.ecr.us-west-2.amazonaws.com/sagemaker-lightgbm-toolkit:latest'\n",
    "image = '429775515542.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-toolkit:latest'\n",
    "#image = <input your own image URI>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d316f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_lightgbm3 = Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    #instance_type=\"ml.m4.2xlarge\",\n",
    "    instance_type=\"local\",\n",
    "    hyperparameters={'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0},\n",
    "    #source_dir='./practice_src',\n",
    "    entry_point='./src/train_practice.py'\n",
    "    #entry_point='./practice_src/train_practice.sh'\n",
    "    )\n",
    "est_lightgbm3.fit({'train':train_s3, 'validation': valid_s3}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f849830",
   "metadata": {},
   "source": [
    "## デプロイローカル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599cdd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor3 = est_lightgbm3.deploy(1, 'local', serializer=csv_serializer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56578900",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = predictor3.predict(payload).decode('utf-8')\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31425a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df07e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a640a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e2364a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0355395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4a48fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5c88802",
   "metadata": {},
   "source": [
    "# 参考\n",
    "\n",
    "\n",
    "SageMaker-Pytorth training Toolkit\n",
    "https://github.com/aws/sagemaker-pytorch-training-toolkit/\n",
    "\n",
    "\n",
    "SageMaker-Pytorch Inference Toolkit\n",
    "\n",
    "https://github.com/aws/sagemaker-pytorch-inference-toolkit\n",
    "\n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/73694705/what-is-the-difference-between-sagemaker-pytorch-training-toolkit-and-sagemaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a46cc0b",
   "metadata": {},
   "source": [
    "## 参考\n",
    "SageMaker のtrainingジョブを理解する\n",
    "\n",
    "https://github.com/aws-samples/aws-ml-jp/tree/main/sagemaker/sagemaker-traning/tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69964bc9",
   "metadata": {},
   "source": [
    "# Toolkitを入れず、train からtrain.shを実行\n",
    "\n",
    "ソースをS3に配置しなればならない\n",
    "\n",
    "\n",
    "fit()について\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase.fit\n",
    "\n",
    "datasetの指定は、S3のパスか、ローカルモードならfile://　つまりGitHubは不可"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460567ad",
   "metadata": {},
   "source": [
    "### SageMaker Traiing Toolkitについて\n",
    "\n",
    "https://github.com/aws/sagemaker-training-toolkit/blob/master/README.md\n",
    "\n",
    "inference toolkitもある。\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/amazon-sagemaker-toolkits.html\n",
    "\n",
    "\n",
    "https://github.com/aws/sagemaker-inference-toolkit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80030204",
   "metadata": {},
   "source": [
    "## （おまけ）カスタムコンテナを使わず、built-inコンテナのrequirement.txtにlightgbmを記載して実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c21b601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"1.2-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44171cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'354813040037.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-xgboost:1.2-1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc66f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_lightgbm5 = Estimator(\n",
    "    #image,\n",
    "    container, # xgboostのbuilt-inコンテナ\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    #instance_type=\"ml.m4.2xlarge\",\n",
    "    instance_type=\"local\",\n",
    "    hyperparameters={'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0},\n",
    "    source_dir='./src_builtin_container',\n",
    "    entry_point='train_practice.py'\n",
    "    #entry_point='./practice_src/train_practice.sh'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b60fa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Creating t4wm576s46-algo-1-f3maj ... \n",
      "Creating t4wm576s46-algo-1-f3maj ... done\n",
      "Attaching to t4wm576s46-algo-1-f3maj\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [2022-10-04 06:46:19.701 8830af5b423f:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m INFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m INFO:sagemaker-containers:Failed to parse hyperparameter boosting_type value gbdt to Json.\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Returning the value itself\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m INFO:sagemaker-containers:Failed to parse hyperparameter objective value regression to Json.\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Returning the value itself\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m INFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m INFO:sagemaker_xgboost_container.training:Invoking user training script.\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m INFO:sagemaker-containers:Module train_practice does not provide a setup.py. \n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Generating setup.py\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m INFO:sagemaker-containers:Generating setup.cfg\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m INFO:sagemaker-containers:Generating MANIFEST.in\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m INFO:sagemaker-containers:Installing module with the following command:\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m /miniconda3/bin/python3 -m pip install . -r requirements.txt\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m \u001b[?25hCollecting lightgbm\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m   Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0meta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m \u001b[?25hRequirement already satisfied: numpy in /miniconda3/lib/python3.7/site-packages (from lightgbm->-r requirements.txt (line 1)) (1.19.2)\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Requirement already satisfied: scipy in /miniconda3/lib/python3.7/site-packages (from lightgbm->-r requirements.txt (line 1)) (1.5.3)\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Requirement already satisfied: scikit-learn!=0.22.0 in /miniconda3/lib/python3.7/site-packages (from lightgbm->-r requirements.txt (line 1)) (0.23.2)\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Requirement already satisfied: wheel in /miniconda3/lib/python3.7/site-packages (from lightgbm->-r requirements.txt (line 1)) (0.35.1)\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Requirement already satisfied: threadpoolctl>=2.0.0 in /miniconda3/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm->-r requirements.txt (line 1)) (3.1.0)\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Requirement already satisfied: joblib>=0.11 in /miniconda3/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm->-r requirements.txt (line 1)) (1.2.0)\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Building wheels for collected packages: train-practice\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m   Building wheel for train-practice (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m \u001b[?25h  Created wheel for train-practice: filename=train_practice-1.0.0-py2.py3-none-any.whl size=6287 sha256=ee7b2ae04d41a8ced68c3060e5660e3f407ae6b8c5a71430d1aebd135a4c21f0\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-2_1ahcs4/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Successfully built train-practice\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Installing collected packages: train-practice, lightgbm\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Successfully installed lightgbm-3.3.2 train-practice-1.0.0\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m \u001b[0mINFO:sagemaker-containers:Failed to parse hyperparameter boosting_type value gbdt to Json.\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Returning the value itself\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m INFO:sagemaker-containers:Failed to parse hyperparameter objective value regression to Json.\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Returning the value itself\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m INFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m INFO:sagemaker-containers:Invoking user script\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m \n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Training Env:\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m \n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m {\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\"\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     },\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"current_host\": \"algo-1-f3maj\",\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         \"algo-1-f3maj\"\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     ],\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         \"boosting_type\": \"gbdt\",\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         \"objective\": \"regression\",\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         \"num_leaves\": 31,\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         \"learning_rate\": 0.05,\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         \"feature_fraction\": 0.9,\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         \"bagging_fraction\": 0.8,\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         \"bagging_freq\": 5,\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         \"verbose\": 0\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     },\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         \"train\": {\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         },\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         \"validation\": {\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         }\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     },\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"job_name\": \"sagemaker-xgboost-2022-10-04-06-44-49-631\",\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"master_hostname\": \"algo-1-f3maj\",\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-1-429775515542/sagemaker-xgboost-2022-10-04-06-44-49-631/source/sourcedir.tar.gz\",\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"module_name\": \"train_practice\",\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         \"current_host\": \"algo-1-f3maj\",\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m             \"algo-1-f3maj\"\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m         ]\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     },\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m     \"user_entry_point\": \"train_practice.py\"\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m }\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m \n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Environment variables:\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m \n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_HOSTS=[\"algo-1-f3maj\"]\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_HPS={\"bagging_fraction\":0.8,\"bagging_freq\":5,\"boosting_type\":\"gbdt\",\"feature_fraction\":0.9,\"learning_rate\":0.05,\"num_leaves\":31,\"objective\":\"regression\",\"verbose\":0}\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_USER_ENTRY_POINT=train_practice.py\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-f3maj\",\"hosts\":[\"algo-1-f3maj\"]}\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_CHANNELS=[\"train\",\"validation\"]\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_CURRENT_HOST=algo-1-f3maj\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_MODULE_NAME=train_practice\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-1-429775515542/sagemaker-xgboost-2022-10-04-06-44-49-631/source/sourcedir.tar.gz\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-f3maj\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1-f3maj\"],\"hyperparameters\":{\"bagging_fraction\":0.8,\"bagging_freq\":5,\"boosting_type\":\"gbdt\",\"feature_fraction\":0.9,\"learning_rate\":0.05,\"num_leaves\":31,\"objective\":\"regression\",\"verbose\":0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2022-10-04-06-44-49-631\",\"log_level\":20,\"master_hostname\":\"algo-1-f3maj\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-1-429775515542/sagemaker-xgboost-2022-10-04-06-44-49-631/source/sourcedir.tar.gz\",\"module_name\":\"train_practice\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-f3maj\",\"hosts\":[\"algo-1-f3maj\"]},\"user_entry_point\":\"train_practice.py\"}\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_USER_ARGS=[\"--bagging_fraction\",\"0.8\",\"--bagging_freq\",\"5\",\"--boosting_type\",\"gbdt\",\"--feature_fraction\",\"0.9\",\"--learning_rate\",\"0.05\",\"--num_leaves\",\"31\",\"--objective\",\"regression\",\"--verbose\",\"0\"]\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_HP_BOOSTING_TYPE=gbdt\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_HP_OBJECTIVE=regression\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_HP_NUM_LEAVES=31\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_HP_LEARNING_RATE=0.05\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_HP_FEATURE_FRACTION=0.9\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_HP_BAGGING_FRACTION=0.8\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_HP_BAGGING_FREQ=5\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m SM_HP_VERBOSE=0\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m PYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m \n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m \n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m /miniconda3/bin/python3 -m train_practice --bagging_fraction 0.8 --bagging_freq 5 --boosting_type gbdt --feature_fraction 0.9 --learning_rate 0.05 --num_leaves 31 --objective regression --verbose 0\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m \n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m \n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m ===== congraturations! You understand how SageMaker Training Job Works!!! =====\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Starting the training.\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Reading hyperparameters data: /opt/ml/input/config/hyperparameters.json\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m hyperparameters_data: {'boosting_type': 'gbdt', 'objective': 'regression', 'num_leaves': '31', 'learning_rate': '0.05', 'feature_fraction': '0.9', 'bagging_fraction': '0.8', 'bagging_freq': '5', 'verbose': '0', 'sagemaker_submit_directory': '\"s3://sagemaker-ap-northeast-1-429775515542/sagemaker-xgboost-2022-10-04-06-44-49-631/source/sourcedir.tar.gz\"', 'sagemaker_program': '\"train_practice.py\"', 'sagemaker_container_log_level': '20', 'sagemaker_job_name': '\"sagemaker-xgboost-2022-10-04-06-44-49-631\"', 'sagemaker_region': '\"ap-northeast-1\"'}\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Found train files: ['/opt/ml/input/data/train/boston_train.csv']\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Found validation files: ['/opt/ml/input/data/validation/boston_valid.csv']\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m building training and validation datasets\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Starting training...\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m /miniconda3/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m   _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m You can set `force_row_wise=true` to remove the overhead.\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m And if memory is not enough, you can set `force_col_wise=true`.\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [1]\tvalid_0's l2: 84.4849\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Training until validation scores don't improve for 5 rounds\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [2]\tvalid_0's l2: 78.6995\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [3]\tvalid_0's l2: 73.3733\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [4]\tvalid_0's l2: 68.4066\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [5]\tvalid_0's l2: 63.9675\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [6]\tvalid_0's l2: 60.4495\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [7]\tvalid_0's l2: 57.2702\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [8]\tvalid_0's l2: 54.3096\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [9]\tvalid_0's l2: 51.6438\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [10]\tvalid_0's l2: 49.4106\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [11]\tvalid_0's l2: 46.871\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [12]\tvalid_0's l2: 44.4878\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [13]\tvalid_0's l2: 42.2348\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [14]\tvalid_0's l2: 40.2703\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [15]\tvalid_0's l2: 38.4195\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [16]\tvalid_0's l2: 36.6089\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [17]\tvalid_0's l2: 34.9745\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [18]\tvalid_0's l2: 33.5774\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [19]\tvalid_0's l2: 32.1331\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [20]\tvalid_0's l2: 30.8945\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Did not meet early stopping. Best iteration is:\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m [20]\tvalid_0's l2: 30.8945\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m saving model file to /opt/ml/model/lightgbm-regression-model.txt\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj |\u001b[0m Training complete.\n",
      "\u001b[36mt4wm576s46-algo-1-f3maj exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "est_lightgbm5.fit({'train':train_s3, 'validation': valid_s3}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8226c808",
   "metadata": {},
   "source": [
    "このコンテナでservingをするにはどうすればいいか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af1894",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor5 = est_lightgbm5.deploy(1, 'local', serializer=csv_serializer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9525a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = predictor5.predict(payload).decode('utf-8')\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955f4d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12e2c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cb6a913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::429775515542:role/TeamRole'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45de1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_lightgbm7 = Estimator(\n",
    "    #image,\n",
    "    container, # xgboostのbuilt-inコンテナ\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.2xlarge\",\n",
    "    #instance_type=\"local\",\n",
    "    hyperparameters={'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0},\n",
    "    source_dir='./src_builtin_container',\n",
    "    entry_point='train_practice.py'\n",
    "    #entry_point='./practice_src/train_practice.sh'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9571e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-04 06:50:16 Starting - Starting the training job...\n",
      "2022-10-04 06:50:43 Starting - Preparing the instances for trainingProfilerReport-1664866216: InProgress\n",
      ".........\n",
      "2022-10-04 06:52:15 Downloading - Downloading input data...\n",
      "2022-10-04 06:52:35 Training - Downloading the training image......\n",
      "2022-10-04 06:53:36 Training - Training image download completed. Training in progress..\u001b[34m[2022-10-04 06:53:41.266 ip-10-0-192-26.ap-northeast-1.compute.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter boosting_type value gbdt to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value regression to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Invoking user training script.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Module train_practice does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Generating setup.cfg\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting lightgbm\n",
      "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 30.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /miniconda3/lib/python3.7/site-packages (from lightgbm->-r requirements.txt (line 1)) (1.19.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel in /miniconda3/lib/python3.7/site-packages (from lightgbm->-r requirements.txt (line 1)) (0.35.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn!=0.22.0 in /miniconda3/lib/python3.7/site-packages (from lightgbm->-r requirements.txt (line 1)) (0.23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /miniconda3/lib/python3.7/site-packages (from lightgbm->-r requirements.txt (line 1)) (1.5.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /miniconda3/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm->-r requirements.txt (line 1)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /miniconda3/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train-practice\n",
      "  Building wheel for train-practice (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for train-practice (setup.py): finished with status 'done'\n",
      "  Created wheel for train-practice: filename=train_practice-1.0.0-py2.py3-none-any.whl size=6287 sha256=9fa9f1a819a5de8d4d1def774aa3d9ca99504f71abc9677ea917451f9b09607d\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-qxor9s_n/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[34mSuccessfully built train-practice\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train-practice, lightgbm\u001b[0m\n",
      "\u001b[34mSuccessfully installed lightgbm-3.3.2 train-practice-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter boosting_type value gbdt to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value regression to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bagging_fraction\": 0.8,\n",
      "        \"bagging_freq\": 5,\n",
      "        \"boosting_type\": \"gbdt\",\n",
      "        \"feature_fraction\": 0.9,\n",
      "        \"learning_rate\": 0.05,\n",
      "        \"num_leaves\": 31,\n",
      "        \"objective\": \"regression\",\n",
      "        \"verbose\": 0\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-xgboost-2022-10-04-06-50-15-848\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-1-429775515542/sagemaker-xgboost-2022-10-04-06-50-15-848/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_practice\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m4.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m4.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_practice.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"bagging_fraction\":0.8,\"bagging_freq\":5,\"boosting_type\":\"gbdt\",\"feature_fraction\":0.9,\"learning_rate\":0.05,\"num_leaves\":31,\"objective\":\"regression\",\"verbose\":0}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_practice.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_practice\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-1-429775515542/sagemaker-xgboost-2022-10-04-06-50-15-848/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"bagging_fraction\":0.8,\"bagging_freq\":5,\"boosting_type\":\"gbdt\",\"feature_fraction\":0.9,\"learning_rate\":0.05,\"num_leaves\":31,\"objective\":\"regression\",\"verbose\":0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2022-10-04-06-50-15-848\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-1-429775515542/sagemaker-xgboost-2022-10-04-06-50-15-848/source/sourcedir.tar.gz\",\"module_name\":\"train_practice\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_practice.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--bagging_fraction\",\"0.8\",\"--bagging_freq\",\"5\",\"--boosting_type\",\"gbdt\",\"--feature_fraction\",\"0.9\",\"--learning_rate\",\"0.05\",\"--num_leaves\",\"31\",\"--objective\",\"regression\",\"--verbose\",\"0\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_BAGGING_FRACTION=0.8\u001b[0m\n",
      "\u001b[34mSM_HP_BAGGING_FREQ=5\u001b[0m\n",
      "\u001b[34mSM_HP_BOOSTING_TYPE=gbdt\u001b[0m\n",
      "\u001b[34mSM_HP_FEATURE_FRACTION=0.9\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.05\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_LEAVES=31\u001b[0m\n",
      "\u001b[34mSM_HP_OBJECTIVE=regression\u001b[0m\n",
      "\u001b[34mSM_HP_VERBOSE=0\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m train_practice --bagging_fraction 0.8 --bagging_freq 5 --boosting_type gbdt --feature_fraction 0.9 --learning_rate 0.05 --num_leaves 31 --objective regression --verbose 0\u001b[0m\n",
      "\u001b[34m===== congraturations! You understand how SageMaker Training Job Works!!! =====\u001b[0m\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mReading hyperparameters data: /opt/ml/input/config/hyperparameters.json\u001b[0m\n",
      "\u001b[34mhyperparameters_data: {'bagging_fraction': '0.8', 'bagging_freq': '5', 'boosting_type': 'gbdt', 'feature_fraction': '0.9', 'learning_rate': '0.05', 'num_leaves': '31', 'objective': 'regression', 'sagemaker_container_log_level': '20', 'sagemaker_job_name': '\"sagemaker-xgboost-2022-10-04-06-50-15-848\"', 'sagemaker_program': '\"train_practice.py\"', 'sagemaker_region': '\"ap-northeast-1\"', 'sagemaker_submit_directory': '\"s3://sagemaker-ap-northeast-1-429775515542/sagemaker-xgboost-2022-10-04-06-50-15-848/source/sourcedir.tar.gz\"', 'verbose': '0'}\u001b[0m\n",
      "\u001b[34mFound train files: ['/opt/ml/input/data/train/boston_train.csv']\u001b[0m\n",
      "\u001b[34mFound validation files: ['/opt/ml/input/data/validation/boston_valid.csv']\u001b[0m\n",
      "\u001b[34mbuilding training and validation datasets\u001b[0m\n",
      "\u001b[34mStarting training...\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_col_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[1]#011valid_0's l2: 84.4849\u001b[0m\n",
      "\u001b[34mTraining until validation scores don't improve for 5 rounds\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[2]#011valid_0's l2: 78.6995\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[3]#011valid_0's l2: 73.3733\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[4]#011valid_0's l2: 68.4066\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[5]#011valid_0's l2: 63.9675\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[6]#011valid_0's l2: 60.4495\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[7]#011valid_0's l2: 57.2702\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[8]#011valid_0's l2: 54.3096\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[9]#011valid_0's l2: 51.6438\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[10]#011valid_0's l2: 49.4106\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[11]#011valid_0's l2: 46.871\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[12]#011valid_0's l2: 44.4878\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[13]#011valid_0's l2: 42.2348\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[14]#011valid_0's l2: 40.2703\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[15]#011valid_0's l2: 38.4195\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[16]#011valid_0's l2: 36.6089\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[17]#011valid_0's l2: 34.9745\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[18]#011valid_0's l2: 33.5774\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[19]#011valid_0's l2: 32.1331\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[20]#011valid_0's l2: 30.8945\u001b[0m\n",
      "\u001b[34mDid not meet early stopping. Best iteration is:\u001b[0m\n",
      "\u001b[34m[20]#011valid_0's l2: 30.8945\u001b[0m\n",
      "\u001b[34msaving model file to /opt/ml/model/lightgbm-regression-model.txt\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2022-10-04 06:54:15 Uploading - Uploading generated training model\n",
      "2022-10-04 06:54:15 Completed - Training job completed\n",
      "Training seconds: 123\n",
      "Billable seconds: 123\n"
     ]
    }
   ],
   "source": [
    "est_lightgbm7.fit({'train':train_s3, 'validation': valid_s3}, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38e2b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor7 = est_lightgbm7.deploy(1, 'ml.m4.xlarge', serializer=csv_serializer, wait=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad1bd86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (502) from primary with message \"<html>\r\n<head><title>502 Bad Gateway</title></head>\r\n<body bgcolor=\"white\">\r\n<center><h1>502 Bad Gateway</h1></center>\r\n<hr><center>nginx/1.14.0 (Ubuntu)</center>\r\n</body>\r\n</html>\r\n\". See https://ap-northeast-1.console.aws.amazon.com/cloudwatch/home?region=ap-northeast-1#logEventViewer:group=/aws/sagemaker/Endpoints/sagemaker-xgboost-2022-10-04-06-54-29-314 in account 429775515542 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9775/3249764647.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    394\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (502) from primary with message \"<html>\r\n<head><title>502 Bad Gateway</title></head>\r\n<body bgcolor=\"white\">\r\n<center><h1>502 Bad Gateway</h1></center>\r\n<hr><center>nginx/1.14.0 (Ubuntu)</center>\r\n</body>\r\n</html>\r\n\". See https://ap-northeast-1.console.aws.amazon.com/cloudwatch/home?region=ap-northeast-1#logEventViewer:group=/aws/sagemaker/Endpoints/sagemaker-xgboost-2022-10-04-06-54-29-314 in account 429775515542 for more information."
     ]
    }
   ],
   "source": [
    "### 推論実行\n",
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predicted = predictor7.predict(payload).decode('utf-8')\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83742b20",
   "metadata": {},
   "source": [
    "ローカルモードの学習、エンドポイントdeployは不可\n",
    "\n",
    "* 学習ジョブ -> deploy endpoint\n",
    "* ローカル学習 -> local deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc76dcf",
   "metadata": {},
   "source": [
    "XGBoostビルトインコンテナでは、LGBMの推論を実行できないので、独自にserveを指定する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f7592b",
   "metadata": {},
   "source": [
    "# End Of Containts ================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ff22d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
